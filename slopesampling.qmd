---
title: "Slope-Based Stratified Sampling"
author:
  - name: Khant Min Naing
  - name: Ann Mei Yi Victoria Grace
date: 02-19-2024 
date-modified: "last-modified"
categories:
  - R
  - sf
  - gwmodel
output:
  distill::distill_article:
    code_folding: false
    toc: true
    self_contained: false
---

# Slope-Based Stratified Sampling

## 1.0 Import Packages

```{r}
pacman::p_load(sp, sf, st, spdep, raster, spatstat, tmap, devtools,vtable,ggplot2,egg, corrplot, patchwork, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary,vtable, sjPlot, sjmisc, sjlabelled, tableHTML, olsrr, car, blorr,ISLR, klaR,pROC)
```

## 2.0 Import Data

We will import datasets used for this sampling.

```{r}
valtellina <- read_sf(dsn = "./data/vector", layer = "valtellina")
train_grids_v4 <- read.csv("~/IS485-Landslide/data/aspatial/train_grid_v4.csv")
```

## 3.0 Slope Sampling

### 3.1 Calculating Quartiles

First, we will extract the **`Slope_Angle`** column from the **`train_grids_v4`** data frame and assigning it to the variable **`slope_angle`**.

Next we will calculate the quartiles of the **`slope_angle`** data such as minimum (0th percentile), first quartile (25th percentile), median (50th percentile), third quartile (75th percentile), and maximum (100th percentile). This helps us understand the distribution of slope angles in the data set.

The **`quantile`** function in R calculates the specified quantiles of a data set. The **`probs`** argument specifies the probabilities for which quantiles are required, and **`seq(0, 1, 1/4)`** generates a sequence of numbers from 0 to 1 in increments of 1/4.

```{r}
slope_angle <- train_grids_v4$Slope_Angle
quantile(slope_angle, probs = seq(0, 1, 1/4))
```

### 3.2 Subseting Dataset into Quartile-based Samples

Based on the quartile values that we have calculated, we will now subset the original dataset into four namely `sample_Q1`, `sample_Q2`, `sample_Q3` & `sample_Q4`.

-   For **`sample_Q1`**, we select all rows where **`Slope_Angle`** is less than 18.41368. This represents the first quartile of the data.

-   For **`sample_Q2`**, we select all rows in **`new_train`** where **`Slope_Angle`** is less than 30.34639.

-   For **`sample_Q3`**, we select all rows where **`Slope_Angle`** is less than 38.54599.

-   Finally, for **`sample_Q4`**, we select all rows where **`Slope_Angle`** is less than or equal to 82.91669.

Finally, I'm using the **`nrow`** function to count the number of rows in each subset. This gives us the number of sample size in each quartile.

```{r}
sample_Q1 <- subset(train_grids_v4,Slope_Angle < 18.41368)
new_train <- subset(train_grids_v4,Slope_Angle >= 18.41368)
sample_Q2 <- subset(new_train,Slope_Angle < 30.34639)
new_train <- subset(new_train,Slope_Angle >= 30.34639)
sample_Q3 <- subset(new_train,Slope_Angle < 38.54599)
new_train <- subset(new_train,Slope_Angle >= 38.54599)
sample_Q4 <- subset(new_train,Slope_Angle <= 82.91669)
nrow(sample_Q1)
nrow(sample_Q2)
nrow(sample_Q3)
nrow(sample_Q4)
```

### 3.3 Plotting Slope-Stratified Datasets

To understand the distribution of slope angle in each sample - **`sample_Q1`**, **`sample_Q2`**, **`sample_Q3`**, and **`sample_Q4`**, we will plot four histograms as below.

```{r}
ggplot(data=sample_Q1, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")

ggplot(data=sample_Q2, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")

ggplot(data=sample_Q3, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")

ggplot(data=sample_Q4, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")
```

### 3.4 Creating Correlation Matrix

Next, we will use the **`ggcorrmat`** function from the **`ggstatsplot`** package to create a correlation matrix for each dataset.

-   We set **`matrix.type`** to \"upper\", which means it will only show the upper triangle of the correlation matrix.

-   We set **`type`** to \"parametric\", which means it will calculating the correlations using a parametric method (Pearson\'s correlation).

-   We set **`k`** to 2, **`sig.level`** to 0.05, **`conf.level`** to 0.95, and **`bf.prior`** to 0.707. These are parameters for the statistical tests that **`ggcorrmat`** performs

```{r}
#| eval: false

set.seed(123)

ggcorrmat(
  data = sample_Q3[, 6:29],  
          matrix.type = "upper",
  type = "parametric",
  tr = 0.2,
  partial = FALSE,
  k = 2L,
  sig.level = 0.05,
  conf.level = 0.95,
  bf.prior = 0.707,
  ggcorrplot.args = list(
     tl.cex = 10,
     pch.cex = 5,
     lab_size = 3
  )) + 
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = "cm")
    )
  )
```

![Q1](images/Screenshot%202024-02-19%20at%203.12.02%20PM.png)

![Q2](images/Screenshot%202024-02-19%20at%203.13.20%20PM.png)

![Q3](images/Screenshot%202024-02-19%20at%203.15.40%20PM.png)

![Q4](images/Screenshot%202024-02-19%20at%203.10.01%20PM.png)

## 4.0 Logistic Regression Modelling

In this section, we will model a logistic regression model for each data sample.

Before wee build the model, we will need to split each data sample into training data and testing data. This is a common practice in machine learning and statistical modeling, where a model is trained on the training set and then evaluated on the test set. We use `sample` function to carry out test-train split with 7:3 ratio, resulting in four training sets (**`Q1_train`**, **`Q2_train`**, **`Q3_train`**, **`Q4_train`**) and four test sets (**`Q1_test`**, **`Q2_test`**, **`Q3_test`**, **`Q4_test`**).

```{r}
sample <- sample(c(TRUE, FALSE), nrow(sample_Q1), replace=TRUE, prob=c(0.70,0.30))
Q1_train  <- sample_Q1[sample, ]
Q1_test   <- sample_Q1[!sample, ]

sample <- sample(c(TRUE, FALSE), nrow(sample_Q2), replace=TRUE, prob=c(0.70,0.30))
Q2_train  <- sample_Q2[sample, ]
Q2_test   <- sample_Q2[!sample, ]

sample <- sample(c(TRUE, FALSE), nrow(sample_Q3), replace=TRUE, prob=c(0.70,0.30))
Q3_train  <- sample_Q3[sample, ]
Q3_test   <- sample_Q3[!sample, ]

sample <- sample(c(TRUE, FALSE), nrow(sample_Q4), replace=TRUE, prob=c(0.70,0.30))
Q4_train  <- sample_Q4[sample, ]
Q4_test   <- sample_Q4[!sample, ]
```

Once we have split the test and train for each data sample, we will now proceed to build a Logistic Regression (LR) model for each sampling dataset. We will fit the model using the **`glm`** function from **stats** package. It is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution.

### 4.1 Logistic Regression Model 1 (Slope Cut-off = 1st Quartile)

First LR model, `log_model_1` is fitted using `Q1_train` dataset with specifications as follows:

-   The model is predicting the **`Landslide`** variable based on a number of predictor variables, including **`Elevation`**, **`Slope_Angle`**, **`Aspect_North`**, **`Aspect_NorthEast`**, **`Aspect_East`**, **`Aspect_SouthEast`**, **`Aspect_South`**, **`Aspect_SouthWest`**, **`Aspect_West`**, **`Profile_Curvature`**, **`Plan_Curvature`**, **`Lithology_Metamorphic`**, **`Lithology_Sedimentary`**, **`Lithology_Plutonic`**, **`Lithology_Unconsolidated`**, **`Proximity_Settlement`**, **`Proximity_Stream`**, **`Proximity_Road`**, **`Proximity_Fault`**, **`Landuse_Vegetation`**, **`Precipitation`**, **`TWI`**, **`SPI`**, and **`STI`**.

-   The **`family`** argument is set to **`"binomial"`** to fit a binomial logistic regression model.

```{r}
log_model_1 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q1_train)
```

#### 4.1.1 Generating Model Summary

Once we have fitted the model, we will generate a summary of the model using `summary()` function. The model summary give us useful information about the model, including the coefficients of the predictor variables, the standard errors of these coefficients, and the statistical significance of each predictor.

```{r}
summary(log_model_1)
```

#### 4.1.2 Calculating Percentage of Deviance

Next, we will calculate the percentage of deviance explained by the model. The deviance is a measure of how well the model fits the data, with lower values indicating a better fit. The null deviance is the deviance of a model with no predictors, i.e., a model that only includes the intercept. So, this calculation gives me the percentage reduction in deviance when going from the null model to the current model.

```{r}
100*with(summary(log_model_1), 1 - deviance/null.deviance)
```

#### 4.1.3 Confusion Matrix

Next, we will generate a confusion matrix for the model predictions using `blr_confusion_matrix()` function from `blorr` package. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. The **`cutoff`** argument is set to 0.5, which means that predicted probabilities greater than or equal to 0.5 are classified as positive, and predicted probabilities less than 0.5 are classified as negative.

```{r}
blr_confusion_matrix(log_model_1, cutoff = 0.5)
```

#### 4.1.4 Ploting ROC Curve and Calculating AUC 

Finally, we will plot the ROC curve and calculate the AUC. The ROC curve is a plot of the true positive rate against the false positive rate for different cutoff values, and the AUC is the area under the ROC curve. These are common metrics for evaluating the performance of a binary classifier. The **`roc`** function from the **`pROC`** package is used to calculate the ROC curve, and the **`auc`** function is used to calculate the AUC.

```{r}
predicted <- predict(log_model_1, Q1_test[, 6:29], type="response")
roc_curve <- roc(Q1_test$Landslide, predicted)
plot(roc_curve, main = "ROC Curve (Model 1)")
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.2 Logistic Regression Model 2 (Slope Cut-off = 2nd Quartile)

```{r}
log_model_2 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q2_train)
```

#### 4.2.1 Generating Model Summary

```{r}
summary(log_model_2)
```

#### 4.2.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_2), 1 - deviance/null.deviance)
```

#### 4.2.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_2, cutoff = 0.5)
```

#### 4.2.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_2, Q2_test[, 6:29], type="response")
roc_curve <- roc(Q2_test$Landslide, predicted)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve (Model 2)")
abline(0, 1, lty = 2, col = "gray")  # Add a reference line for a random classifier
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.3 Logistic Regression Model 3 (Slope Cut-off = 3rd Quartile)

```{r}
log_model_3 <- glm(Landslide ~ Elevation + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q3_train)
```

#### 4.3.1 Generating Model Summary

```{r}
summary(log_model_3)
```

#### 4.3.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_3), 1 - deviance/null.deviance)
```

#### 4.3.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_3, cutoff = 0.5)
```

#### 4.3.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_3, Q3_test[, 6:29], type="response")
roc_curve <- roc(Q3_test$Landslide, predicted)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve (Model 3)")
abline(0, 1, lty = 2, col = "gray") 
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.4 Logistic Regression Model 4 (Slope Cut-off = 4th Quartile)

```{r}
log_model_4 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q4_train)
```

#### 4.4.1 Generating Model Summary

```{r}
summary(log_model_4)
```

#### 4.4.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_4), 1 - deviance/null.deviance)
```

#### 4.4.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_4, cutoff = 0.5)
```

#### 4.4.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_4, Q4_test[, 6:29], type="response")
roc_curve <- roc(Q4_test$Landslide, predicted)
plot(roc_curve, main = "ROC Curve (Model 4)")
abline(0, 1, lty = 2, col = "gray")  
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.5 Logistic Regression Model 5 (Slope Cut-off = 25)

```{r}
sample_Q5 <- subset(train_grids_v4,Slope_Angle < 25)
nrow(sample_Q5)

ggplot(data=sample_Q5, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e") +
  ggtitle("Slope Stratified Sampling (Cut-off 25)")

sample <- sample(c(TRUE, FALSE), nrow(sample_Q5), replace=TRUE, prob=c(0.70,0.30))
Q5_train  <- sample_Q5[sample, ]
Q5_test   <- sample_Q5[!sample, ]
```

```{r}
log_model_5 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q5_train)
```

#### 4.5.1 Generating Model Summary

```{r}
summary(log_model_5)
```

#### 4.5.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_5), 1 - deviance/null.deviance)
```

#### 4.5.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_5, cutoff = 0.5)
```

#### 4.5.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_5, Q5_test[, 6:29], type="response")
roc_curve <- roc(Q5_test$Landslide, predicted)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve (Model 5)")
abline(0, 1, lty = 2, col = "gray")  # Add a reference line for a random classifier
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.6 Logistic Regression Model 6 (Slope Cut-off = 20)

```{r}
sample_Q6 <- subset(train_grids_v4,Slope_Angle < 20)
nrow(sample_Q6)

ggplot(data=sample_Q6, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")+
  ggtitle("Slope Stratified Sampling (Cut-off 20)")

sample <- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.70,0.30))
Q6_train  <- sample_Q6[sample, ]
Q6_test   <- sample_Q6[!sample, ]
```

```{r}
log_model_6 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q6_train)
```

#### 4.6.1 Generating Model Summary

```{r}
summary(log_model_6)
```

#### 4.6.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_6), 1 - deviance/null.deviance)
```

#### 4.6.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_6, cutoff = 0.5)
```

#### 4.6.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_6, Q6_test[, 6:29], type="response")
roc_curve <- roc(Q6_test$Landslide, predicted)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve (Model 6)")
abline(0, 1, lty = 2, col = "gray")  # Add a reference line for a random classifier
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

### 4.7 Logistic Regression Model 7 (Slope Cut-off = 15)

```{r}
sample_Q7 <- subset(train_grids_v4,Slope_Angle < 15)
nrow(sample_Q7)

ggplot(data=sample_Q7, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=10, color="black", fill="#e9531e")+
  ggtitle("Slope Stratified Sampling (Cut-off 15)")


sample <- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.70,0.30))
Q7_train  <- sample_Q7[sample, ]
Q7_test   <- sample_Q7[!sample, ]
```

```{r}
log_model_7 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = Q7_train)
```

#### 4.7.1 Generating Model Summary

```{r}
summary(log_model_7)
```

#### 4.7.2 Calculating Percentage of Deviance

```{r}
100*with(summary(log_model_7), 1 - deviance/null.deviance)
```

#### 4.7.3 Confusion Matrix

```{r}
blr_confusion_matrix(log_model_7, cutoff = 0.5)
```

#### 4.7.4 Ploting ROC Curve and Calculating AUC 

```{r}
predicted <- predict(log_model_7, Q7_test[, 6:29], type="response")
roc_curve <- roc(Q7_test$Landslide, predicted)
# Plot the ROC curve
plot(roc_curve, main = "ROC Curve (Model 7)")
abline(0, 1, lty = 2, col = "gray")  # Add a reference line for a random classifier
auc_value <- auc(roc_curve)
cat("AUC:", auc_value, "\n")
```

## 5.0 Geographically Weighted Logistic Regression

Next, we will run Geographically Weighted Logistic Regression (GWLR) models using `sample_Q5` dataset and `GWmodel` package. In order to perform GWLR modelling in `GWmodel`, we will first need to convert *t*he datasets into a **SpatialPointsDataFrame**.

```{r}
sample_Q5.sf <- st_as_sf(sample_Q5,
                            coords = c("X", "Y"))
sample_Q5.sf <- st_set_crs(sample_Q5.sf, 32632)
sample_Q5.sp <- sample_Q5.sf %>% as_Spatial()

Q5_train.sf <- st_as_sf(Q5_train,
                            coords = c("X", "Y"))
Q5_train.sf <- st_set_crs(Q5_train.sf, 32632)
Q5_train.sp <- Q5_train.sf %>% as_Spatial()


Q5_test.sf <- st_as_sf(Q5_test,
                            coords = c("X", "Y"))
Q5_test.sf <- st_set_crs(Q5_test.sf, 32632)
Q5_test.sp <- Q5_test.sf %>% as_Spatial()
```

```{r}
#| eval: false
#| echo: false
Q7_train.sf <- st_as_sf(Q7_train,
                            coords = c("X", "Y"))
Q7_train.sf <- st_set_crs(Q7_train.sf, 32632)
Q7_train_sp <- Q7_train.sf %>% as_Spatial()
Q7_train_sp

Q7_test.sf <- st_as_sf(Q7_test,
                            coords = c("X", "Y"))
Q7_test.sf <- st_set_crs(Q7_test.sf, 32632)
Q7_test_sp <- Q7_test.sf %>% as_Spatial()
Q7_test_sp
```

We will make a quick plot to see the geographical distribution of landslide and non-landslide samples in `sample_Q5`.

```{r}

```

### 5.1 Calculating Adaptive Bandwidth

In this section, we will calculate the adaptive bandwidth for fitting a GWLE model using the **`bw.ggwr`** function from `GWmodel`.

Firstly, we will create a distance matrix to be used for calculating the bandwidth. The **`st_coordinates`** function is used to extract the coordinates from the **`Q5_train.sf`** spatial object. The **`gw.dist`** function is then used to calculate the distance matrix **`dist.test`** based on these coordinates.

```{r}
dist_mat <- st_coordinates(Q5_train.sf) 
dist.test <- gw.dist(dp.locat=dist_mat,p=2, theta=0, longlat=FALSE)
```

Now that, we have created the distance matrix, we will calculate the adaptive bandwidth value with specifications as below.

-   The **`family`** argument is set to **`"binomial"`**, indicating that a binomial distribution is assumed for the dependent variable.

-   The **`approach`** argument is set to **`"CV"`**, indicating that cross-validation is used for bandwidth selection.

-   The **`kernel`** argument is set to **`"gaussian"`**, indicating that a Gaussian kernel function is used.

-   The **`adaptive`** argument is set to **`TRUE`**, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors.

-   The **`p`** and **`theta`** arguments are set to **`2`** and **`0`** respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.

-   The **`longlat`** argument is set to **`FALSE`**, indicating that Euclidean distances are calculated.

-   Finally, the **`dMat`** argument is set to **`dist.test`**, which is the pre-specified distance matrix that we calculated earlier.

```{r}
#| eval: false
adaptive_bw <- bw.ggwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q5_train_sp, family = "binomial", approach="CV", kernel="gaussian",
       adaptive=TRUE, p=2, theta=0, longlat=F, dMat=dist.test)
```

![](images/Screenshot 2024-02-19 at 9.56.31 PM.png)

Based on the result, the optimal adaptive bandwidth value that yields the lowest CV score is **203** (with CV score = 1312.815). We will use this value in fitting GWLR model `gwlr`.

### 5.2 Building Geographically Weighted Logistic Regression Model

We will use `ggwr.basic()` function from `GWmodel` package to fit a GWLR model `gwlr` using the specifications below.

-   The **`bw`** argument is set to **`203`**, which is the optimal adaptive bandwidth value that yields the lowest CV score (1312.815). This value was determined in a previous step.

-   The **`family`** argument is set to **`"binomial"`**, indicating that a binomial distribution is assumed for the dependent variable. The **`kernel`** argument is set to **`"gaussian"`**, indicating that a Gaussian kernel function is used.

-   The **`adaptive`** argument is set to **`TRUE`**, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors. The **`cv`** argument is set to **`TRUE`**, indicating that cross-validation data will be calculated.

-   The **`tol`** argument is set to **`0.00001`**, which is the threshold that determines the convergence of the IRLS procedure.

-   The **`p`** and **`theta`** arguments are set to **`2`** and **`0`** respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.

-   The **`longlat`** argument is set to **`FALSE`**, indicating that Euclidean distances are calculated.

```{r}
#| eval: false

gwlr <- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q5_train_sp, regression.points = Q5_test_sp, bw= 203, family = "binomial", kernel = "gaussian", adaptive = TRUE, cv = T, tol = 0.00001, p = 2, theta = 0, longlat = FALSE)
```

### 5.3 Model Summary

```{r}
#| echo: false
gwlr <- read_rds("~/IS485-Landslide/data/rds/gwlr.rds")
gwlr.SDF <-read_rds("~/IS485-Landslide/data/rds/gwlr.adaptive.SDF.rds")
```

```{r}
gwlr
```

```{r}
gwlr$glms$coefficients
```

```{r}
#| eval: false
#| echo: false
tmap_mode("view")
tmap_options(check.and.fix = TRUE)+
tm_shape(valtellina)+
  tm_polygons()+
tm_shape(gwlr.res.sf) +  
  tm_dots(col= "gwlr.glms.residuals",
          alpha = 0.6,
          midpoint = NA )
```

```{r}
#| eval: false
#| echo: false
tmap_mode("view")
tmap_options(check.and.fix = TRUE)+
tm_shape(valtellina)+
  tm_polygons()+
tm_shape(gwlr.adaptive.sf) +  
  tm_dots(col= "Landuse_Vegetation.1",
          alpha = 0.6,
          midpoint = NA )
```

```{r}
#| eval: false
#| echo: false
tmap_mode("view")
tmap_options(check.and.fix = TRUE)+
tm_shape(valtellina)+
  tm_polygons()+
tm_shape(gwlr.adaptive.sf) +  
  tm_dots(col= "TWI.1",
          midpoint = NA )
```

```{r}
#| eval: false
#| echo: false
tmap_mode("view")
tmap_options(check.and.fix = TRUE)+
tm_shape(valtellina)+
  tm_polygons()+
tm_shape(gwlr.adaptive.sf) +  
  tm_dots(col= "Slope_Angle.1",
          palette = "Spectral",
          midpoint = NA )
```

```{r}
#| eval: false
#| echo: false
adaptive_bw <- bw.gwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q7_train_sp, approach="CV", kernel="gaussian",
       adaptive=TRUE, p=2, theta=0, longlat=F)
```

```{r}
#| eval: false
#| echo: false
gwlr_15 <- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q7_train_sp, regression.points = Q7_test_sp, bw= 127, family = "binomial", kernel = "gaussian", adaptive = TRUE, cv = T, tol = 0.00001, p = 2, theta = 0, longlat = FALSE)
```
