[
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data Preview",
    "section": "",
    "text": "Skipping install of 'patchwork' from a github remote, the SHA1 (d9437579) has not changed since last install.\n  Use `force = TRUE` to force installation\nIn this section, we set up the necessary R packages for data processing and exploratory spatial data analysis. The following packages are downloaded.\nlibrary(sp)\nlibrary(raster) \nlibrary(elevatr)\nlibrary(sf)\nlibrary(RColorBrewer)\nlibrary(classInt)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(paletteer)\nlibrary(cowplot)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(terra)\nlibrary(ggnewscale)\nIn this section, I will import the necessary datasets (both spatial and geospatial) into R environment.\nvaltellina &lt;- read_sf(dsn = \"data/vector\", layer = \"valtellina\")\nlandslides &lt;- read_sf(dsn = \"data/vector\", layer = \"landslide_inventory\")\nprecipitation &lt;-raster(\"data/raster/avgprecipitation_mm.tif\")\nelevation &lt;-raster(\"data/raster/elevation_m.tiff\")\ntwi &lt;-raster(\"data/raster/twi_.tif\")\nlithology &lt;- read_sf(dsn = \"data/vector\", layer = \"lithology_cat\")\nprofile_c &lt;- raster(\"data/raster/profile_curvature_cat.tif\")\nplan_c &lt;- raster(\"data/raster/plan_curvature_cat.tif\")\nslope &lt;- raster(\"data/raster/slope_degree.tif\")\ndistance_building &lt;- raster(\"data/raster/distance_to_building_m.tif\")\ndistance_roads &lt;-  raster(\"data/raster/distance_to_roads_m.tif\")\ndistance_river &lt;-  raster(\"data/raster/distance_to_river_m.tif\")\ndistance_faults &lt;-  raster(\"data/raster/distance_to_faults_m.tif\")\naspect &lt;- raster(\"data/raster/aspect_cat.tif\")\nhillshade &lt;- raster(\"data/raster/hillshade.tif\")\ncrs(valtellina)\n\n[1] \"PROJCRS[\\\"WGS 84 / UTM zone 32N\\\",\\n    BASEGEOGCRS[\\\"WGS 84\\\",\\n        DATUM[\\\"World Geodetic System 1984\\\",\\n            ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                LENGTHUNIT[\\\"metre\\\",1]]],\\n        PRIMEM[\\\"Greenwich\\\",0,\\n            ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n        ID[\\\"EPSG\\\",4326]],\\n    CONVERSION[\\\"UTM zone 32N\\\",\\n        METHOD[\\\"Transverse Mercator\\\",\\n            ID[\\\"EPSG\\\",9807]],\\n        PARAMETER[\\\"Latitude of natural origin\\\",0,\\n            ANGLEUNIT[\\\"Degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8801]],\\n        PARAMETER[\\\"Longitude of natural origin\\\",9,\\n            ANGLEUNIT[\\\"Degree\\\",0.0174532925199433],\\n            ID[\\\"EPSG\\\",8802]],\\n        PARAMETER[\\\"Scale factor at natural origin\\\",0.9996,\\n            SCALEUNIT[\\\"unity\\\",1],\\n            ID[\\\"EPSG\\\",8805]],\\n        PARAMETER[\\\"False easting\\\",500000,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8806]],\\n        PARAMETER[\\\"False northing\\\",0,\\n            LENGTHUNIT[\\\"metre\\\",1],\\n            ID[\\\"EPSG\\\",8807]]],\\n    CS[Cartesian,2],\\n        AXIS[\\\"(E)\\\",east,\\n            ORDER[1],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n        AXIS[\\\"(N)\\\",north,\\n            ORDER[2],\\n            LENGTHUNIT[\\\"metre\\\",1]],\\n    ID[\\\"EPSG\\\",32632]]\"\nSome Layers Required Cropping and Masking\ndistance_building_cropped = crop(distance_building, valtellina)\ndistance_building_final = mask(distance_building_cropped, valtellina)\ndistance_roads_cropped = crop(distance_roads, valtellina)\ndistance_roads_final = mask(distance_roads_cropped, valtellina)\ndistance_river_cropped = crop(distance_river, valtellina)\ndistance_river_final = mask(distance_river_cropped, valtellina)\ndistance_faults_cropped = crop(distance_faults, valtellina)\ndistance_faults_final = mask(distance_faults_cropped, valtellina)\nhillshade_cropped = crop(hillshade, valtellina)\nhillshade_final = mask(hillshade_cropped, valtellina)\n\nref = extent(distance_building_final)\ndistance_faults_final &lt;- setExtent(distance_faults_final, ref, keepres=FALSE, snap=FALSE)\nBefore creating thematic maps for each landslide parameter, a map is created to plot the study area of this project, Valtellina Valley in Italy using ggplot package.\nvaltellina_transformed &lt;- st_transform(valtellina, crs = \"+proj=merc\")\n\nggplot(data = valtellina_transformed) +\n  geom_sf()+\n  coord_sf(expand=FALSE)+\n  labs(x='Longitude',y='Latitude',\n       title=\"Study Area\",\n       subtitle='Valtellina Valley, Italy',\n       caption='Source: Zindi') +\n  cowplot::theme_cowplot()+\n  theme(panel.grid.major = element_line(color = gray(.5),\n                                        linetype = 'dashed',\n                                        linewidth = 0.1),\n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill=NA,color = 'black'),\n        panel.ontop = TRUE,\n        axis.title.x = element_text(size = 12), \n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10))\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using geospatial data, we need to ensure that data are projected using the appropriate and standard coordinate system. For this project, we use EPSG:32632 (WGS 84 / UTM zone 32N) for all the datasets.\nprecipitation &lt;- projectRaster(precipitation, crs = \"+proj=merc\")\nreclass_df &lt;- c(-Inf, -0.0001, 1,\n                -0.0001, 0.0001, 2,\n                0.0001, Inf, 3)\nreclass_df\nreclass_m &lt;- matrix(reclass_df,ncol = 3,byrow = TRUE)\n\nprofile_classifed &lt;- reclassify(profile_c,reclass_m)\nprofile_classifed_df &lt;- as.data.frame(profile_classifed,xy=TRUE)%&gt;%drop_na()\nprofile_codes &lt;- unique(profile_classifed_df[\"profile_curvature_cat\"])\nprofile_names &lt;-c(\"convex\", \"flat\", \"concave\")\nprofile_colors &lt;-c(\"#0d3d83\",\"#eff635\",\"#77d91d\")\n\nplan_classifed &lt;- reclassify(plan_c,reclass_m)\nplan_classifed_df &lt;- as.data.frame(plan_classifed,xy=TRUE)%&gt;%drop_na()\nplan_codes &lt;- unique(plan_classifed_df[\"plan_curvature_cat\"])\nplan_names &lt;-c(\"concave\", \"flat\", \"convex\")\nplan_colors &lt;-c(\"#77d91d\",\"#eff635\",\"#0d3d83\")\nBefore plotting the thematic maps with ggplot2, raster datasets are converted into data frames.\nprecipitation_df &lt;- as.data.frame(precipitation,xy=TRUE)%&gt;%drop_na()\ntail(precipitation_df)\n\n              x       y avgprecipitation_mm\n4726314 1060805 5751444           0.2868658\n4726315 1060843 5751444           0.2868658\n4726316 1060881 5751444           0.2868658\n4726317 1060919 5751444           0.2868658\n4726318 1060958 5751444           0.2868658\n4726319 1060996 5751444           0.2868658\n\nelevation_df &lt;- as.data.frame(elevation,xy=TRUE)%&gt;%drop_na()\ntwi_df &lt;- as.data.frame(twi,xy=TRUE)%&gt;%drop_na()\nlithology_df &lt;- as.data.frame(lithology,xy=TRUE)%&gt;%drop_na()\nprofile_c_df &lt;- as.data.frame(profile_c,xy=TRUE)%&gt;%drop_na()\nplan_c_df &lt;- as.data.frame(plan_c,xy=TRUE)%&gt;%drop_na()\nslope_df &lt;- as.data.frame(slope,xy=TRUE)%&gt;%drop_na()\ndistance_building_df &lt;- as.data.frame(distance_building_final,xy=TRUE)%&gt;%drop_na()\ndistance_roads_df &lt;- as.data.frame(distance_roads_final,xy=TRUE)%&gt;%drop_na()\ndistance_river_df &lt;- as.data.frame(distance_river_final,xy=TRUE)%&gt;%drop_na()\ndistance_faults_df &lt;- as.data.frame(distance_faults_final,xy=TRUE)%&gt;%drop_na()\nhillshade_df &lt;- as.data.frame(hillshade_final,xy=TRUE)%&gt;%drop_na()\nIn this session, we will plot the various parametric data we prepared and processed in previous session into thematic maps. We will use the following functions from ggplot2 to plot these maps."
  },
  {
    "objectID": "data.html#import",
    "href": "data.html#import",
    "title": "Data Preview",
    "section": "2.0 Import",
    "text": "2.0 Import"
  },
  {
    "objectID": "data.html#study-area",
    "href": "data.html#study-area",
    "title": "Data Preview",
    "section": "3.0 Study Area",
    "text": "3.0 Study Area"
  },
  {
    "objectID": "data.html#fixing-crs-references",
    "href": "data.html#fixing-crs-references",
    "title": "Data Preview",
    "section": "4.0 Fixing CRS References",
    "text": "4.0 Fixing CRS References"
  },
  {
    "objectID": "data.html#reclassify-data-values",
    "href": "data.html#reclassify-data-values",
    "title": "Data Preview",
    "section": "5.0 Reclassify Data Values",
    "text": "5.0 Reclassify Data Values"
  },
  {
    "objectID": "data.html#create-database",
    "href": "data.html#create-database",
    "title": "Data Preview",
    "section": "6.0 Create Database",
    "text": "6.0 Create Database"
  },
  {
    "objectID": "data.html#plot-with-ggplot2",
    "href": "data.html#plot-with-ggplot2",
    "title": "Data Preview",
    "section": "7.0 Plot with ggplot2",
    "text": "7.0 Plot with ggplot2"
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "",
    "section": "",
    "text": "Landslide susceptibility assessment is an emerging research area of both importance and urgency and several approaches and models have been explored in scientific literature. These models can be generally categorized into four categories: expert-based, physically-based, statistical and machine learning-based.\n\nPhysically-based models are of the highest utility in theory [d], but such models often face challenges and uncertainties for real-world application due to the limited availability of spatially differentiated geotechnical data.\nCompared to physically-based models, expert-based models are less data-intensive as they are developed with the expert knowledge of local interactions between landslide occurrences and its controlling factors (Steger et al., 2019). Due to its qualitative nature, expert-based models often lack objectivity and reproducibility, and are not commonly used in scientific research.\nStatistical landslide susceptibility modelling seeks to estimate the spatial likelihood or relative spatial probability of spatial units to coincide with future landslide occurrence (Steger et al., 2019). These models have been widely adopted for practical application due to their relatively lower input data demand (than physically based models) and quantitative modelling output (which expert-based models lack).\nMachine learning models have emerged as promising alternatives to statistical-driven models due to their flexibility and potential for high predictive accuracy.\n\nNevertheless, previous research has demonstrated that each model type has its unique strengths and limitations, and choosing an appropriate model depends largely on various factors, such as interpretability, generalizability, and the specific research objectives.\nOur study focuses on comparing the performance and applications of statistical and machine learning models in landslide susceptibility assessment.\n\nPrecition Task: The first part involves using both approaches to predict landslide susceptibility through binary classification (landslide presence/absence). We will explore and evaulate whether data mining and machine learning methods perform better than stati\nAnalytical Task: Subsequently, the explanatory variables will be evaluated through global and local statistical models to understand the influence and significance of different landslide predisposing factors. We will identify (i) landform properties and (ii) human-environment interaction factors affecting landslide susceptibility results. We will also examine whether susceptibility is geospatially independent.\n\nThe differentiation between spatial prediction tasks and analytical tasks provides comprehensive review of the model performance and applications.\n\n\n\n\n\nIn practice, relationships between variables may be nonstationary. However, traditional regression models assume that predictors and outcome variables are spatially homogeneous, or stationary.\nOrdinary least squares (OLS) linear regression is a standard global modelling technique that cannot detect nonstationarity, and thus using it may obscure regional variation in the relationships between predictors and the outcome variable.\nGWR extends the ordinary least-sqaures regression framework by allowing local rather than global parameters to be estimated. That is, we allow a continuous surface of parameter values, and measurements of this surface are taken at certain points to denote the spatial variability of the surface. Thus, GWR accounts for spatial variations in relationships might exist and provides a way in which they can be measured. \nSpatial Weights\nSpatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates. Formally, the weights express the neighbour structure between the observations as a n×n matrix, in which the elements wij of the matrix are the spatial weights."
  },
  {
    "objectID": "methodology.html#explanatory-and-predictive-landslide-susceptibility-modelling-using-statistical-and-machine-learning-techniques-case-study-of-valtellina-valley-italy",
    "href": "methodology.html#explanatory-and-predictive-landslide-susceptibility-modelling-using-statistical-and-machine-learning-techniques-case-study-of-valtellina-valley-italy",
    "title": "",
    "section": "",
    "text": "Landslide susceptibility assessment is an emerging research area of both importance and urgency and several approaches and models have been explored in scientific literature. These models can be generally categorized into four categories: expert-based, physically-based, statistical and machine learning-based.\n\nPhysically-based models are of the highest utility in theory [d], but such models often face challenges and uncertainties for real-world application due to the limited availability of spatially differentiated geotechnical data.\nCompared to physically-based models, expert-based models are less data-intensive as they are developed with the expert knowledge of local interactions between landslide occurrences and its controlling factors (Steger et al., 2019). Due to its qualitative nature, expert-based models often lack objectivity and reproducibility, and are not commonly used in scientific research.\nStatistical landslide susceptibility modelling seeks to estimate the spatial likelihood or relative spatial probability of spatial units to coincide with future landslide occurrence (Steger et al., 2019). These models have been widely adopted for practical application due to their relatively lower input data demand (than physically based models) and quantitative modelling output (which expert-based models lack).\nMachine learning models have emerged as promising alternatives to statistical-driven models due to their flexibility and potential for high predictive accuracy.\n\nNevertheless, previous research has demonstrated that each model type has its unique strengths and limitations, and choosing an appropriate model depends largely on various factors, such as interpretability, generalizability, and the specific research objectives.\nOur study focuses on comparing the performance and applications of statistical and machine learning models in landslide susceptibility assessment.\n\nPrecition Task: The first part involves using both approaches to predict landslide susceptibility through binary classification (landslide presence/absence). We will explore and evaulate whether data mining and machine learning methods perform better than stati\nAnalytical Task: Subsequently, the explanatory variables will be evaluated through global and local statistical models to understand the influence and significance of different landslide predisposing factors. We will identify (i) landform properties and (ii) human-environment interaction factors affecting landslide susceptibility results. We will also examine whether susceptibility is geospatially independent.\n\nThe differentiation between spatial prediction tasks and analytical tasks provides comprehensive review of the model performance and applications.\n\n\n\n\n\nIn practice, relationships between variables may be nonstationary. However, traditional regression models assume that predictors and outcome variables are spatially homogeneous, or stationary.\nOrdinary least squares (OLS) linear regression is a standard global modelling technique that cannot detect nonstationarity, and thus using it may obscure regional variation in the relationships between predictors and the outcome variable.\nGWR extends the ordinary least-sqaures regression framework by allowing local rather than global parameters to be estimated. That is, we allow a continuous surface of parameter values, and measurements of this surface are taken at certain points to denote the spatial variability of the surface. Thus, GWR accounts for spatial variations in relationships might exist and provides a way in which they can be measured. \nSpatial Weights\nSpatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates. Formally, the weights express the neighbour structure between the observations as a n×n matrix, in which the elements wij of the matrix are the spatial weights."
  },
  {
    "objectID": "methodology.html#strengths",
    "href": "methodology.html#strengths",
    "title": "",
    "section": "Strengths",
    "text": "Strengths\nUsing machine learning models like Frequency Ratio (FR) and Analytic Hierarchy Process (AHP) can facilitate the adoption of appropriate mitigation measures against landslides (Goswami et. al, 2023).\nML models have been favoured for its ability to solve nonlinear problems, improve predictive performance across various classifiers (Song et al., 2023) and capture non-linear relationships between variables (Achu et al., 2023).\nThe compounding effect of ML models is that they can combine the predictions of multiple ML techniques which can improve the robustness and reliability of landslide susceptibility maps (Achu et al., 2023)."
  },
  {
    "objectID": "methodology.html#concerns",
    "href": "methodology.html#concerns",
    "title": "",
    "section": "Concerns",
    "text": "Concerns\nDespite its strengths, the performance of machine learning models can be affected by sample imbalances when landslide samples are much smaller than non-landslide samples, which can cause low recall rates and decreased predictive ability for landslide samples.\nFurthermore, machine learning models are at risk of poorer performance when faced with new or unseen data that differs significantly from the training data.\n\nTemporal Differences: Training data collected at different time periods than the new data lead to variations in environmental conditions, demographics and other factors that can affect relationships (Yao et al., 2023).\nSpatial Differences: When training data is collected from a specific location, new data from a different region with different characteristics and landslide distributions can challenge established underlying relationships (Yao et al., 2023).\n\nParticularly in landslide identification, machine learning models are lacking in the identification of landslide types and digital terrain model dominant landslide identification using machine learning has not been explored.\n\n4.0 Research Design\n\n\n5.0 References\n\nCascini, L.: Applicability of landslide susceptibility and hazard zoning at different scales. Engineering Geology. 102, 164–177 (2008).\nFrattini, P., Crosta, G., Carrara, A.: Techniques for evaluating the performance of landslide susceptibility models. Engineering Geology. 111, 62–72 (2010).\nGuzzetti, F., Carrara, A., Cardinali, M., Reichenbach, P.: Landslide hazard evaluation: A review of current techniques and their application in a multi-scale study, Central Italy. Geomorphology. 31, 181–216 (1999).\nKuriakose, S.L., van Beek, L.P., van Westen, C.J.: Parameterizing a physically based shallow landslide model in a data poor region. Earth Surface Processes and Landforms. 34, 867–881 (2009).\nRuff, M., Czurda, K.: Landslide susceptibility analysis with a heuristic approach in the eastern alps (Vorarlberg, Austria). Geomorphology. 94, 314–324 (2008).\nSteger, S., Kofler, C.: Statistical Modeling of Landslides: Landslide Susceptibility and Beyond. In: Pourghasemi, H.R. and Gokceoglu, C. (eds.) Spatial modeling in GIS and R for earth and environmental sciences. pp. 519–546. Elsevier, Amsterdam, Netherlands (2019).\nvan Westen, C.J., Rengers, N. & Soeters, R. Use of Geomorphological Information in Indirect Landslide Susceptibility Assessment. Natural Hazards 30, 399–419 (2003)."
  },
  {
    "objectID": "data/vector/train_point.html",
    "href": "data/vector/train_point.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n                  0 0     false"
  },
  {
    "objectID": "slopesampling.html",
    "href": "slopesampling.html",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "pacman::p_load(sp, sf, st, spdep, terra, raster, spatstat, tmap, devtools,vtable,ggplot2, corrplot, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary, blorr, car, ISLR, klaR,pROC)\n\n\n\n\nWe will import datasets used for this sampling.\n\nvaltellina &lt;- read_sf(dsn = \"./data/vector\", layer = \"valtellina\")\ntrain_grids_v4 &lt;- read.csv(\"data/aspatial/train_grid_v4.csv\")\n\n\n\n\n\n\nFirst, we will extract the Slope_Angle column from the train_grids_v4 data frame and assigning it to the variable slope_angle.\nNext we will calculate the quartiles of the slope_angle data such as minimum (0th percentile), first quartile (25th percentile), median (50th percentile), third quartile (75th percentile), and maximum (100th percentile). This helps us understand the distribution of slope angles in the data set.\nThe quantile function in R calculates the specified quantiles of a data set. The probs argument specifies the probabilities for which quantiles are required, and seq(0, 1, 1/4) generates a sequence of numbers from 0 to 1 in increments of 1/4.\n\nslope_angle &lt;- train_grids_v4$Slope_Angle\nquantile(slope_angle, probs = seq(0, 1, 1/4))\n\n\n\n\nBased on the quartile values that we have calculated, we will now subset the original dataset into four namely sample_Q1, sample_Q2, sample_Q3 & sample_Q4.\n\nFor sample_Q1, we select all rows where Slope_Angle is less than 18.41368. This represents the first quartile of the data.\nFor sample_Q2, we select all rows in new_train where Slope_Angle is less than 30.34639.\nFor sample_Q3, we select all rows where Slope_Angle is less than 38.54599.\nFinally, for sample_Q4, we select all rows where Slope_Angle is less than or equal to 82.91669.\n\nFinally, I’m using the nrow function to count the number of rows in each subset. This gives us the number of sample size in each quartile.\n\nsample_Q1 &lt;- subset(train_grids_v4,Slope_Angle &lt; 18.41368)\nnew_train &lt;- subset(train_grids_v4,Slope_Angle &gt;= 18.41368)\nsample_Q2 &lt;- subset(new_train,Slope_Angle &lt; 30.34639)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 30.34639)\nsample_Q3 &lt;- subset(new_train,Slope_Angle &lt; 38.54599)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 38.54599)\nsample_Q4 &lt;- subset(new_train,Slope_Angle &lt;= 82.91669)\nnrow(sample_Q1)\nnrow(sample_Q2)\nnrow(sample_Q3)\nnrow(sample_Q4)\n\n\n\n\nTo understand the distribution of slope angle in each sample - sample_Q1, sample_Q2, sample_Q3, and sample_Q4, we will plot four histograms as below.\n\nggplot(data=sample_Q1, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q2, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q3, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q4, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\n\n\n\nNext, we will use the ggcorrmat function from the ggstatsplot package to create a correlation matrix for each dataset.\n\nWe set matrix.type to “upper”, which means it will only show the upper triangle of the correlation matrix.\nWe set type to “parametric”, which means it will calculating the correlations using a parametric method (Pearson’s correlation).\nWe set k to 2, sig.level to 0.05, conf.level to 0.95, and bf.prior to 0.707. These are parameters for the statistical tests that ggcorrmat performs\n\n\nset.seed(123)\n\nggcorrmat(\n  data = sample_Q6[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + \n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\n\n\nQ1\n\n\n\n\n\nQ2\n\n\n\n\n\nQ3\n\n\n\n\n\nQ4\n\n\n\n\n\n\nIn this section, we will model a logistic regression model for each data sample.\nBefore wee build the model, we will need to split each data sample into training data and testing data. This is a common practice in machine learning and statistical modeling, where a model is trained on the training set and then evaluated on the test set. We use sample function to carry out test-train split with 7:3 ratio, resulting in four training sets (Q1_train, Q2_train, Q3_train, Q4_train) and four test sets (Q1_test, Q2_test, Q3_test, Q4_test).\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q1), replace=TRUE, prob=c(0.70,0.30))\nQ1_train  &lt;- sample_Q1[sample, ]\nQ1_test   &lt;- sample_Q1[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q2), replace=TRUE, prob=c(0.70,0.30))\nQ2_train  &lt;- sample_Q2[sample, ]\nQ2_test   &lt;- sample_Q2[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q3), replace=TRUE, prob=c(0.70,0.30))\nQ3_train  &lt;- sample_Q3[sample, ]\nQ3_test   &lt;- sample_Q3[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q4), replace=TRUE, prob=c(0.70,0.30))\nQ4_train  &lt;- sample_Q4[sample, ]\nQ4_test   &lt;- sample_Q4[!sample, ]\n\nOnce we have split the test and train for each data sample, we will now proceed to build a Logistic Regression (LR) model for each sampling dataset. We will fit the model using the glm function from stats package. It is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution.\n\n\nFirst LR model, log_model_1 is fitted using Q1_train dataset with specifications as follows:\n\nThe model is predicting the Landslide variable based on a number of predictor variables, including Elevation, Slope_Angle, Aspect_North, Aspect_NorthEast, Aspect_East, Aspect_SouthEast, Aspect_South, Aspect_SouthWest, Aspect_West, Profile_Curvature, Plan_Curvature, Lithology_Metamorphic, Lithology_Sedimentary, Lithology_Plutonic, Lithology_Unconsolidated, Proximity_Settlement, Proximity_Stream, Proximity_Road, Proximity_Fault, Landuse_Vegetation, Precipitation, TWI, SPI, and STI.\nThe family argument is set to \"binomial\" to fit a binomial logistic regression model.\n\n\nlog_model_1 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q1_train)\n\n\n\nOnce we have fitted the model, we will generate a summary of the model using summary() function. The model summary give us useful information about the model, including the coefficients of the predictor variables, the standard errors of these coefficients, and the statistical significance of each predictor.\n\nsummary(log_model_1)\n\n\n\n\nNext, we will calculate the percentage of deviance explained by the model. The deviance is a measure of how well the model fits the data, with lower values indicating a better fit. The null deviance is the deviance of a model with no predictors, i.e., a model that only includes the intercept. So, this calculation gives me the percentage reduction in deviance when going from the null model to the current model.\n\n100*with(summary(log_model_1), 1 - deviance/null.deviance)\n\n\n\n\nNext, we will generate a confusion matrix for the model predictions using blr_confusion_matrix() function from blorr package. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. The cutoff argument is set to 0.5, which means that predicted probabilities greater than or equal to 0.5 are classified as positive, and predicted probabilities less than 0.5 are classified as negative.\n\nblr_confusion_matrix(log_model_1, cutoff = 0.5)\n\n\n\n\nFinally, we will plot the ROC curve and calculate the AUC. The ROC curve is a plot of the true positive rate against the false positive rate for different cutoff values, and the AUC is the area under the ROC curve. These are common metrics for evaluating the performance of a binary classifier. The roc function from the pROC package is used to calculate the ROC curve, and the auc function is used to calculate the AUC.\n\npredicted &lt;- predict(log_model_1, Q1_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q1_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 1)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_2 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q2_train)\n\n\n\n\nsummary(log_model_2)\n\n\n\n\n\n100*with(summary(log_model_2), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_2, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_2, Q2_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q2_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 2)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_3 &lt;- glm(Landslide ~ Elevation + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q3_train)\n\n\n\n\nsummary(log_model_3)\n\n\n\n\n\n100*with(summary(log_model_3), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_3, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_3, Q3_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q3_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 3)\")\nabline(0, 1, lty = 2, col = \"gray\") \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_4 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q4_train)\n\n\n\n\nsummary(log_model_4)\n\n\n\n\n\n100*with(summary(log_model_4), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_4, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_4, Q4_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q4_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 4)\")\nabline(0, 1, lty = 2, col = \"gray\")  \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nsample_Q5 &lt;- subset(train_grids_v4,Slope_Angle &lt; 25)\nnrow(sample_Q5)\n\nggplot(data=sample_Q5, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\") +\n  ggtitle(\"Slope Stratified Sampling (Cut-off 25)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q5), replace=TRUE, prob=c(0.70,0.30))\nQ5_train  &lt;- sample_Q5[sample, ]\nQ5_test   &lt;- sample_Q5[!sample, ]\n\n\nlog_model_5 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q5_train)\n\n\n\n\nsummary(log_model_5)\n\n\n\n\n\n100*with(summary(log_model_5), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_5, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_5, Q5_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q5_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 5)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q6 &lt;- subset(train_grids_v4,Slope_Angle &lt; 20)\nnrow(sample_Q6)\n\nggplot(data=sample_Q6, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 20)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.70,0.30))\nQ6_train  &lt;- sample_Q6[sample, ]\nQ6_test   &lt;- sample_Q6[!sample, ]\n\n\nlog_model_6 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q6_train)\n\n\n\n\nsummary(log_model_6)\n\n\n\n\n\n100*with(summary(log_model_6), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_6, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_6, Q6_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q6_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 6)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q7 &lt;- subset(train_grids_v4,Slope_Angle &lt; 15)\nnrow(sample_Q7)\n\nggplot(data=sample_Q7, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 15)\")\n\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.70,0.30))\nQ7_train  &lt;- sample_Q7[sample, ]\nQ7_test   &lt;- sample_Q7[!sample, ]\n\n\nlog_model_7 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = sample_Q7)\n\n\n\n\nsummary(log_model_7)\n\n\n\n\n\n100*with(summary(log_model_7), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_7, cutoff = 0.5)\n\n\nvif(log_model_7)\n\n\n\n\n\npredicted &lt;- predict(log_model_7, Q7_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q7_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 7)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(log_model_7)\n\n\nlog_model_7 %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\n\n\n\n\nlog_model_7_modified &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_SouthEast + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Road+ Landuse_Vegetation+Precipitation, family = \"binomial\", data = sample_Q7)\n\n\nsummary(log_model_7_modified)\n\n\nvif(log_model_7_modified)\n\n\n\n\n\n\nNext, we will run Geographically Weighted Logistic Regression (GWLR) models using sample_Q5 dataset and GWmodel package. In order to perform GWLR modelling in GWmodel, we will first need to convert the datasets into a SpatialPointsDataFrame.\n\n\n\nset.seed(123)\n# Model 6 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.20,0.80))\nQ6_fit  &lt;- sample_Q6[sample, ]\n\nQ6_fit.sf &lt;- st_as_sf(Q6_fit,\n                            coords = c(\"X\", \"Y\"))\nQ6_fit.sf &lt;- st_set_crs(Q6_fit.sf, 32632)\nQ6_fit.sp &lt;- Q6_fit.sf %&gt;% as_Spatial()\n\n# Model 7 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.20,0.80))\nQ7_fit  &lt;- sample_Q6[sample, ]\n\nQ7_fit.sf &lt;- st_as_sf(Q7_fit,\n                            coords = c(\"X\", \"Y\"))\nQ7_fit.sf &lt;- st_set_crs(Q7_fit.sf, 32632)\nQ7_fit.sp &lt;- Q7_fit.sf %&gt;% as_Spatial()\n\nwrite_rds(Q6_fit.sp, \"data/rds/Q6_fit.sp.rds\")\nwrite_rds(Q7_fit.sp, \"data/rds/Q7_fit.sp.rds\")\n\n\nQ6_fit.sp &lt;- read_rds(\"data/rds/Q6_fit.sp.rds\")\nQ7_fit.sp &lt;- read_rds(\"data/rds/Q7_fit.sp.rds\")\n\nWe will make a quick plot to see the geographical distribution of landslide and non-landslide samples in Q6_fit.sp & Q7_fit.sp.\n\nQ6_fit.sf$Landslide &lt;- as.factor(Q6_fit.sf$Landslide)\nQ7_fit.sf$Landslide &lt;- as.factor(Q7_fit.sf$Landslide)\n\n\n\n\nIn this section, we will calculate the adaptive bandwidth for fitting a GWLE model using the bw.ggwr function from GWmodel.\nFirstly, we will create a distance matrix to be used for calculating the bandwidth. The st_coordinates function is used to extract the coordinates from the Q5_train.sf spatial object. The gw.dist function is then used to calculate the distance matrix dist.test based on these coordinates.\n\n\n\ndist_mat &lt;- st_coordinates(Q6_fit.sf) \ndist.Q6 &lt;- gw.dist(dp.locat=dist_mat,p=2, theta=0, longlat=FALSE)\n\nNow that, we have created the distance matrix, we will calculate the adaptive bandwidth value with specifications as below.\n\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable.\nThe approach argument is set to \"CV\", indicating that cross-validation is used for bandwidth selection.\nThe kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\nFinally, the dMat argument is set to dist.test, which is the pre-specified distance matrix that we calculated earlier.\n\n\nadaptive_bw &lt;- bw.gwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, approach=\"CV\", kernel=\"gaussian\",\n       adaptive=TRUE, p=2, theta=0, longlat=F)\n\n\nBased on the result, the optimal adaptive bandwidth value that yields the lowest CV score is 203 (with CV score = 1312.815). We will use this value in fitting GWLR model gwlr.\n\n\n\n\nWe will use ggwr.basic() function from GWmodel package to fit a GWLR model gwlr using the specifications below.\n\nThe bw argument is set to 203, which is the optimal adaptive bandwidth value that yields the lowest CV score (1312.815). This value was determined in a previous step.\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable. The kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors. The cv argument is set to TRUE, indicating that cross-validation data will be calculated.\nThe tol argument is set to 0.00001, which is the threshold that determines the convergence of the IRLS procedure.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\n\n\ngwlr &lt;- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, bw= 100, family = \"binomial\", kernel = \"gaussian\", adaptive = TRUE, cv = T, p = 2, theta = 0, longlat = FALSE)\n\n\n\n\n\ngwlr\n\n\nregression.points &lt;- gwlr$SDF\n\n\n\n\n\nvaltellina_boundary &lt;- st_union(valtellina) %&gt;% st_sf()\nclass(valtellina_boundary)\n\n\n\nWe wish to predict the prices of properties continuously in space in Athens. To do that, we create a fine raster grid covering Athens and consider the centroids of the raster cells as the prediction locations. We create the raster grid with the rast() function of terra by specifying the region to be covered (map), and the number of rows and columns of the grid (nrows = 700, ncols = 1066). The prediction locations are the centroids of the raster cells and can be obtained with the xyFromCell() function of terra. Alternatively, we could create the grid using the st_make_grid() function of sf by specifying the number of grid cells in the horizontal and vertical directions or the cell size.\n\ngrid &lt;- rast(valtellina_boundary, nrows = 700, ncols = 1066)\nxy &lt;- xyFromCell(grid, 1:ncell(grid))\ncoop &lt;- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n              crs = st_crs(valtellina_boundary))\ncoop &lt;- st_filter(coop, valtellina_boundary)\nqtm(coop)\n\n\n\n\n\nWe can obtain predictions at each of the prediction locations as the values of the closest sampled locations. To do that, we can employ the Voronoi diagram (also known as Dirichlet or Thiessen diagram). The Voronoi diagram is created when a region with n points is partitioned into convex polygons such that each polygon contains exactly one generating point, and every point in a given polygon is closer to its generating point than to any other.\nGiven a set of points, we can create a Voronoi diagram with the voronoi() function of terra specifying the points as an object of class SpatVector of terra, and map to set the outer boundary of the Voronoi diagram. This returns a Voronoi diagram for the set of points assuming constant values in each of the polygons.\nThen, we can use the functions tm_shape() and tm_fill() of tmap to plot the values of the variable in each of the polygons indicating the name of the variable col = \"vble\", the palette palette = \"viridis\" and the level of transparency alpha = 0.6 (if the plot is interactive).\n\n# Voronoi\nv &lt;- voronoi(x = vect(regression.points), bnd = valtellina_boundary)\nplot(v)\npoints(vect(regression.points), cex = 0.5)\n\n# Prediction\nv &lt;- st_as_sf(v)\ntm_shape(v) +\n  tm_fill(col = \"Landuse_Vegetation\", palette = \"Spectral\")\n\n\nresp &lt;- st_intersection(v, coop)\nresp$pred &lt;- resp$Landuse_Vegetation\n\npred_voronoi &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nvoronoi_map &lt;- tm_shape(pred_voronoi) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Voronoi\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nvoronoi_map\n\n\n\n\nIn the IDW method, values at unsampled locations are estimated as the weighted average of values from the rest of locations with weights inversely proportional to the distance between the unsampled and the sampled locations.\nWe can apply the IDW method with the gstat() function of gstat and the following arguments:\n\nformula: vble ~ 1 to have an intercept only model,\nnmax: number of neighbors is set equal to the total number of locations,\nidp: inverse distance power is set to idp = 1 to have weights with β=1�=1.\n\nThen, we use the predict() function to obtain the predictions and tmap to show the results\n\npacman::p_load(gstat)\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points,\n             nmax = nrow(regression.points), # use all the neighbors locations\n             set = list(idp = 1)) # beta = 1 \n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_idw &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nidw_map &lt;- tm_shape(pred_idw) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"IDW\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nidw_map\n\n\n\n\nIn the nearest neighbors interpolation method, values at unsampled locations are estimated as the average of the values of the k closest sampled locations. Specifically,\nWe can compute predictions using nearest neighbors interpolation with the gstat() function of gstat. Here, we consider the number of closest sampled locations equal to 5 by setting nmax = 5. Unlike the IDW method, in the nearest neighbors approach locations further away from the location where we wish to predict are assigned the same weights. Therefore, the inverse distance power idp is set equal to zero so all the neighbors are equally weighted.\nThen, we use the predict() function to get predictions at unsampled locations given in coop.\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_nn &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nnn_map &lt;- tm_shape(pred_nn) + \n  tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Nearest Neighbour\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nnn_map\n\n\n\n\nPredictions can also be obtained using an ensemble approach that combines the predictions obtained with several spatial interpolation methods.\nHere, we use an ensemble approach to predict the price per square meter of apartments in Athens by combining the predictions of the three previous approaches (closest observation, IDW, nearest neighbors) using equal weights.\nThe predictions with the closest observation method are obtained using the Voronoi diagram as follows:\n\n# Closest observation (Voronoi)\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\n\nThe IDW approach can be applied with the gstat() function of gstat specifying nmax as the total number of locations and idp = 1.\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\n\nThe nearest neighbors method is applied with the gstat() function specifying nmax as the number of neighbors and with equal weights (idp = 0).\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\n\nFinally, the ensemble predictions are obtained by combining the predictions of these three methods with equal weights.\n\n# Ensemble (equal weights)\nweights &lt;- c(1/3, 1/3, 1/3)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\n\nWe create a map with the predictions by creating a raster with the predictions and using the tmap package.\n\nresp &lt;- data.frame(\nx = st_coordinates(coop)[, 1],\ny = st_coordinates(coop)[, 2],\npred = p4)\n\nresp &lt;- st_as_sf(resp, coords = c(\"x\", \"y\"), crs = st_crs(map))\n\npred_ensemble &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\n ensemble_map &lt;- tm_shape(pred_ensemble) + \n   tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n             midpoint = NA) +\n tm_layout(main.title = \"Ensemble\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n \n ensemble_map\n\n\ntmap_arrange(voronoi_map, idw_map, nn_map, ensemble_map)\n\n\nwriteRaster(pred_nn, \"~/IS485-Landslide/data/gwr_maps/landuse_nn.tif\", overwrite=TRUE)\nwriteRaster(pred_idw, \"~/IS485-Landslide/data/gwr_maps/landuse_idw.tif\", overwrite=TRUE)\nwriteRaster(pred_voronoi, \"~/IS485-Landslide/data/gwr_maps/landuse_voronoi.tif\", overwrite=TRUE)\nwriteRaster(pred_ensemble, \"~/IS485-Landslide/data/gwr_maps/landuse_ensemble.tif\", overwrite=TRUE)\n\n\n\n\nWe can assess the performance of each of the methods presented above using K-fold cross-validation and the root mean squared error (RMSE). First, we split the data in K parts. For each part, we use the remaining K−1 parts (training data) to fit the model and that part (testing data) to predict. We compute the RMSE by comparing the testing and predicted data in each of the K parts.\nNote that if K is equal to the number of observations n, this procedure is called leave-one-out cross-validation (LOOCV). That means that n separate data sets are trained on all of the data except one observation, and then prediction is made for that one observation.\nHere, we assess the performance of each of the methods previously employed to predict the prices of apartments in Athens. We create training and testing sets by using the dismo:kfold() function of the dismo package (Hijmans et al. 2022) to randomly assign the observations to K=5 groups of roughly equal size. For each group, we fit the model using the training data, and obtain predictions of the testing data. We calculate the RMSEs of each part and average the RMSEs to obtain a K-fold cross-validation estimate.\n\npacman::p_load(dismo)\n\n\nRMSE &lt;- function(observed, predicted) {\nsqrt(mean((observed - predicted)^2))\n}\n\n# Split data in 5 sets\nkf &lt;- dismo::kfold(nrow(regression.points), k = 5) # K-fold partitioning\n\n# Vectors to store the RMSE values obtained with each method\nrmse1 &lt;- rep(NA, 5) # Closest observation\nrmse2 &lt;- rep(NA, 5) # IDW\nrmse3 &lt;- rep(NA, 5) # Nearest neighbors\nrmse4 &lt;- rep(NA, 5) # Ensemble\n\n\nfor(k in 1:5) {\n# Split data in test and train\ntest &lt;- regression.points[kf == k, ]\ntrain &lt;- regression.points[kf != k, ]\n\n# Closest observation\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\nrmse1[k] &lt;- RMSE(test$Landuse_Vegetation, p1)\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\nrmse2[k] &lt;- RMSE(test$Landuse_Vegetation, p2)\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\nrmse3[k] &lt;- RMSE(test$Landuse_Vegetation, p3)\n\n# Ensemble (weights are inverse RMSE so lower RMSE higher weight)\nw &lt;- 1/c(rmse1[k], rmse2[k], rmse3[k])\nweights &lt;- w/sum(w)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\nrmse4[k] &lt;- RMSE(test$Landuse_Vegetation, p4)\n}\n\nThe RMSE values obtained in each of the 5 splits are shown below.\n\n# RMSE obtained for each of the 5 splits\ndata.frame(closest.obs = rmse1, IDW = rmse2,\n           nearest.neigh = rmse3, ensemble = rmse4)\n\nWe see the minimum average RMSE corresponds to the ensemble method.\n\n# Average RMSE over the 5 splits\ndata.frame(closest.obs = mean(rmse1), IDW = mean(rmse2),\n           nearest.neigh = mean(rmse3), ensemble = mean(rmse4))\n\n\n\n\n\n\nwrite.csv(sample_Q6, \"~/IS485-Landslide/data/aspatial/slope_20degree.csv\")\nwrite.csv(sample_Q7, \"~/IS485-Landslide/data/aspatial/slope_15degree.csv\")"
  },
  {
    "objectID": "slopesampling.html#import-packages",
    "href": "slopesampling.html#import-packages",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "pacman::p_load(sp, sf, st, spdep, terra, raster, spatstat, tmap, devtools,vtable,ggplot2, corrplot, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary, blorr, car, ISLR, klaR,pROC)"
  },
  {
    "objectID": "slopesampling.html#import-data",
    "href": "slopesampling.html#import-data",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "We will import datasets used for this sampling.\n\nvaltellina &lt;- read_sf(dsn = \"./data/vector\", layer = \"valtellina\")\ntrain_grids_v4 &lt;- read.csv(\"data/aspatial/train_grid_v4.csv\")"
  },
  {
    "objectID": "slopesampling.html#slope-sampling",
    "href": "slopesampling.html#slope-sampling",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "First, we will extract the Slope_Angle column from the train_grids_v4 data frame and assigning it to the variable slope_angle.\nNext we will calculate the quartiles of the slope_angle data such as minimum (0th percentile), first quartile (25th percentile), median (50th percentile), third quartile (75th percentile), and maximum (100th percentile). This helps us understand the distribution of slope angles in the data set.\nThe quantile function in R calculates the specified quantiles of a data set. The probs argument specifies the probabilities for which quantiles are required, and seq(0, 1, 1/4) generates a sequence of numbers from 0 to 1 in increments of 1/4.\n\nslope_angle &lt;- train_grids_v4$Slope_Angle\nquantile(slope_angle, probs = seq(0, 1, 1/4))\n\n\n\n\nBased on the quartile values that we have calculated, we will now subset the original dataset into four namely sample_Q1, sample_Q2, sample_Q3 & sample_Q4.\n\nFor sample_Q1, we select all rows where Slope_Angle is less than 18.41368. This represents the first quartile of the data.\nFor sample_Q2, we select all rows in new_train where Slope_Angle is less than 30.34639.\nFor sample_Q3, we select all rows where Slope_Angle is less than 38.54599.\nFinally, for sample_Q4, we select all rows where Slope_Angle is less than or equal to 82.91669.\n\nFinally, I’m using the nrow function to count the number of rows in each subset. This gives us the number of sample size in each quartile.\n\nsample_Q1 &lt;- subset(train_grids_v4,Slope_Angle &lt; 18.41368)\nnew_train &lt;- subset(train_grids_v4,Slope_Angle &gt;= 18.41368)\nsample_Q2 &lt;- subset(new_train,Slope_Angle &lt; 30.34639)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 30.34639)\nsample_Q3 &lt;- subset(new_train,Slope_Angle &lt; 38.54599)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 38.54599)\nsample_Q4 &lt;- subset(new_train,Slope_Angle &lt;= 82.91669)\nnrow(sample_Q1)\nnrow(sample_Q2)\nnrow(sample_Q3)\nnrow(sample_Q4)\n\n\n\n\nTo understand the distribution of slope angle in each sample - sample_Q1, sample_Q2, sample_Q3, and sample_Q4, we will plot four histograms as below.\n\nggplot(data=sample_Q1, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q2, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q3, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q4, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\n\n\n\nNext, we will use the ggcorrmat function from the ggstatsplot package to create a correlation matrix for each dataset.\n\nWe set matrix.type to “upper”, which means it will only show the upper triangle of the correlation matrix.\nWe set type to “parametric”, which means it will calculating the correlations using a parametric method (Pearson’s correlation).\nWe set k to 2, sig.level to 0.05, conf.level to 0.95, and bf.prior to 0.707. These are parameters for the statistical tests that ggcorrmat performs\n\n\nset.seed(123)\n\nggcorrmat(\n  data = sample_Q6[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + \n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\n\n\nQ1\n\n\n\n\n\nQ2\n\n\n\n\n\nQ3\n\n\n\n\n\nQ4"
  },
  {
    "objectID": "slopesampling.html#logistic-regression-modelling",
    "href": "slopesampling.html#logistic-regression-modelling",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "In this section, we will model a logistic regression model for each data sample.\nBefore wee build the model, we will need to split each data sample into training data and testing data. This is a common practice in machine learning and statistical modeling, where a model is trained on the training set and then evaluated on the test set. We use sample function to carry out test-train split with 7:3 ratio, resulting in four training sets (Q1_train, Q2_train, Q3_train, Q4_train) and four test sets (Q1_test, Q2_test, Q3_test, Q4_test).\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q1), replace=TRUE, prob=c(0.70,0.30))\nQ1_train  &lt;- sample_Q1[sample, ]\nQ1_test   &lt;- sample_Q1[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q2), replace=TRUE, prob=c(0.70,0.30))\nQ2_train  &lt;- sample_Q2[sample, ]\nQ2_test   &lt;- sample_Q2[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q3), replace=TRUE, prob=c(0.70,0.30))\nQ3_train  &lt;- sample_Q3[sample, ]\nQ3_test   &lt;- sample_Q3[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q4), replace=TRUE, prob=c(0.70,0.30))\nQ4_train  &lt;- sample_Q4[sample, ]\nQ4_test   &lt;- sample_Q4[!sample, ]\n\nOnce we have split the test and train for each data sample, we will now proceed to build a Logistic Regression (LR) model for each sampling dataset. We will fit the model using the glm function from stats package. It is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution.\n\n\nFirst LR model, log_model_1 is fitted using Q1_train dataset with specifications as follows:\n\nThe model is predicting the Landslide variable based on a number of predictor variables, including Elevation, Slope_Angle, Aspect_North, Aspect_NorthEast, Aspect_East, Aspect_SouthEast, Aspect_South, Aspect_SouthWest, Aspect_West, Profile_Curvature, Plan_Curvature, Lithology_Metamorphic, Lithology_Sedimentary, Lithology_Plutonic, Lithology_Unconsolidated, Proximity_Settlement, Proximity_Stream, Proximity_Road, Proximity_Fault, Landuse_Vegetation, Precipitation, TWI, SPI, and STI.\nThe family argument is set to \"binomial\" to fit a binomial logistic regression model.\n\n\nlog_model_1 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q1_train)\n\n\n\nOnce we have fitted the model, we will generate a summary of the model using summary() function. The model summary give us useful information about the model, including the coefficients of the predictor variables, the standard errors of these coefficients, and the statistical significance of each predictor.\n\nsummary(log_model_1)\n\n\n\n\nNext, we will calculate the percentage of deviance explained by the model. The deviance is a measure of how well the model fits the data, with lower values indicating a better fit. The null deviance is the deviance of a model with no predictors, i.e., a model that only includes the intercept. So, this calculation gives me the percentage reduction in deviance when going from the null model to the current model.\n\n100*with(summary(log_model_1), 1 - deviance/null.deviance)\n\n\n\n\nNext, we will generate a confusion matrix for the model predictions using blr_confusion_matrix() function from blorr package. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. The cutoff argument is set to 0.5, which means that predicted probabilities greater than or equal to 0.5 are classified as positive, and predicted probabilities less than 0.5 are classified as negative.\n\nblr_confusion_matrix(log_model_1, cutoff = 0.5)\n\n\n\n\nFinally, we will plot the ROC curve and calculate the AUC. The ROC curve is a plot of the true positive rate against the false positive rate for different cutoff values, and the AUC is the area under the ROC curve. These are common metrics for evaluating the performance of a binary classifier. The roc function from the pROC package is used to calculate the ROC curve, and the auc function is used to calculate the AUC.\n\npredicted &lt;- predict(log_model_1, Q1_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q1_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 1)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_2 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q2_train)\n\n\n\n\nsummary(log_model_2)\n\n\n\n\n\n100*with(summary(log_model_2), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_2, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_2, Q2_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q2_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 2)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_3 &lt;- glm(Landslide ~ Elevation + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q3_train)\n\n\n\n\nsummary(log_model_3)\n\n\n\n\n\n100*with(summary(log_model_3), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_3, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_3, Q3_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q3_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 3)\")\nabline(0, 1, lty = 2, col = \"gray\") \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_4 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q4_train)\n\n\n\n\nsummary(log_model_4)\n\n\n\n\n\n100*with(summary(log_model_4), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_4, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_4, Q4_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q4_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 4)\")\nabline(0, 1, lty = 2, col = \"gray\")  \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nsample_Q5 &lt;- subset(train_grids_v4,Slope_Angle &lt; 25)\nnrow(sample_Q5)\n\nggplot(data=sample_Q5, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\") +\n  ggtitle(\"Slope Stratified Sampling (Cut-off 25)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q5), replace=TRUE, prob=c(0.70,0.30))\nQ5_train  &lt;- sample_Q5[sample, ]\nQ5_test   &lt;- sample_Q5[!sample, ]\n\n\nlog_model_5 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q5_train)\n\n\n\n\nsummary(log_model_5)\n\n\n\n\n\n100*with(summary(log_model_5), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_5, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_5, Q5_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q5_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 5)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q6 &lt;- subset(train_grids_v4,Slope_Angle &lt; 20)\nnrow(sample_Q6)\n\nggplot(data=sample_Q6, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 20)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.70,0.30))\nQ6_train  &lt;- sample_Q6[sample, ]\nQ6_test   &lt;- sample_Q6[!sample, ]\n\n\nlog_model_6 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q6_train)\n\n\n\n\nsummary(log_model_6)\n\n\n\n\n\n100*with(summary(log_model_6), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_6, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_6, Q6_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q6_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 6)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q7 &lt;- subset(train_grids_v4,Slope_Angle &lt; 15)\nnrow(sample_Q7)\n\nggplot(data=sample_Q7, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 15)\")\n\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.70,0.30))\nQ7_train  &lt;- sample_Q7[sample, ]\nQ7_test   &lt;- sample_Q7[!sample, ]\n\n\nlog_model_7 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = sample_Q7)\n\n\n\n\nsummary(log_model_7)\n\n\n\n\n\n100*with(summary(log_model_7), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_7, cutoff = 0.5)\n\n\nvif(log_model_7)\n\n\n\n\n\npredicted &lt;- predict(log_model_7, Q7_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q7_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 7)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(log_model_7)\n\n\nlog_model_7 %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\n\n\n\n\nlog_model_7_modified &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_SouthEast + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Road+ Landuse_Vegetation+Precipitation, family = \"binomial\", data = sample_Q7)\n\n\nsummary(log_model_7_modified)\n\n\nvif(log_model_7_modified)"
  },
  {
    "objectID": "slopesampling.html#geographically-weighted-logistic-regression",
    "href": "slopesampling.html#geographically-weighted-logistic-regression",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "Next, we will run Geographically Weighted Logistic Regression (GWLR) models using sample_Q5 dataset and GWmodel package. In order to perform GWLR modelling in GWmodel, we will first need to convert the datasets into a SpatialPointsDataFrame.\n\n\n\nset.seed(123)\n# Model 6 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.20,0.80))\nQ6_fit  &lt;- sample_Q6[sample, ]\n\nQ6_fit.sf &lt;- st_as_sf(Q6_fit,\n                            coords = c(\"X\", \"Y\"))\nQ6_fit.sf &lt;- st_set_crs(Q6_fit.sf, 32632)\nQ6_fit.sp &lt;- Q6_fit.sf %&gt;% as_Spatial()\n\n# Model 7 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.20,0.80))\nQ7_fit  &lt;- sample_Q6[sample, ]\n\nQ7_fit.sf &lt;- st_as_sf(Q7_fit,\n                            coords = c(\"X\", \"Y\"))\nQ7_fit.sf &lt;- st_set_crs(Q7_fit.sf, 32632)\nQ7_fit.sp &lt;- Q7_fit.sf %&gt;% as_Spatial()\n\nwrite_rds(Q6_fit.sp, \"data/rds/Q6_fit.sp.rds\")\nwrite_rds(Q7_fit.sp, \"data/rds/Q7_fit.sp.rds\")\n\n\nQ6_fit.sp &lt;- read_rds(\"data/rds/Q6_fit.sp.rds\")\nQ7_fit.sp &lt;- read_rds(\"data/rds/Q7_fit.sp.rds\")\n\nWe will make a quick plot to see the geographical distribution of landslide and non-landslide samples in Q6_fit.sp & Q7_fit.sp.\n\nQ6_fit.sf$Landslide &lt;- as.factor(Q6_fit.sf$Landslide)\nQ7_fit.sf$Landslide &lt;- as.factor(Q7_fit.sf$Landslide)\n\n\n\n\nIn this section, we will calculate the adaptive bandwidth for fitting a GWLE model using the bw.ggwr function from GWmodel.\nFirstly, we will create a distance matrix to be used for calculating the bandwidth. The st_coordinates function is used to extract the coordinates from the Q5_train.sf spatial object. The gw.dist function is then used to calculate the distance matrix dist.test based on these coordinates.\n\n\n\ndist_mat &lt;- st_coordinates(Q6_fit.sf) \ndist.Q6 &lt;- gw.dist(dp.locat=dist_mat,p=2, theta=0, longlat=FALSE)\n\nNow that, we have created the distance matrix, we will calculate the adaptive bandwidth value with specifications as below.\n\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable.\nThe approach argument is set to \"CV\", indicating that cross-validation is used for bandwidth selection.\nThe kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\nFinally, the dMat argument is set to dist.test, which is the pre-specified distance matrix that we calculated earlier.\n\n\nadaptive_bw &lt;- bw.gwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, approach=\"CV\", kernel=\"gaussian\",\n       adaptive=TRUE, p=2, theta=0, longlat=F)\n\n\nBased on the result, the optimal adaptive bandwidth value that yields the lowest CV score is 203 (with CV score = 1312.815). We will use this value in fitting GWLR model gwlr.\n\n\n\n\nWe will use ggwr.basic() function from GWmodel package to fit a GWLR model gwlr using the specifications below.\n\nThe bw argument is set to 203, which is the optimal adaptive bandwidth value that yields the lowest CV score (1312.815). This value was determined in a previous step.\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable. The kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors. The cv argument is set to TRUE, indicating that cross-validation data will be calculated.\nThe tol argument is set to 0.00001, which is the threshold that determines the convergence of the IRLS procedure.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\n\n\ngwlr &lt;- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, bw= 100, family = \"binomial\", kernel = \"gaussian\", adaptive = TRUE, cv = T, p = 2, theta = 0, longlat = FALSE)\n\n\n\n\n\ngwlr\n\n\nregression.points &lt;- gwlr$SDF\n\n\n\n\n\nvaltellina_boundary &lt;- st_union(valtellina) %&gt;% st_sf()\nclass(valtellina_boundary)\n\n\n\nWe wish to predict the prices of properties continuously in space in Athens. To do that, we create a fine raster grid covering Athens and consider the centroids of the raster cells as the prediction locations. We create the raster grid with the rast() function of terra by specifying the region to be covered (map), and the number of rows and columns of the grid (nrows = 700, ncols = 1066). The prediction locations are the centroids of the raster cells and can be obtained with the xyFromCell() function of terra. Alternatively, we could create the grid using the st_make_grid() function of sf by specifying the number of grid cells in the horizontal and vertical directions or the cell size.\n\ngrid &lt;- rast(valtellina_boundary, nrows = 700, ncols = 1066)\nxy &lt;- xyFromCell(grid, 1:ncell(grid))\ncoop &lt;- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n              crs = st_crs(valtellina_boundary))\ncoop &lt;- st_filter(coop, valtellina_boundary)\nqtm(coop)\n\n\n\n\n\nWe can obtain predictions at each of the prediction locations as the values of the closest sampled locations. To do that, we can employ the Voronoi diagram (also known as Dirichlet or Thiessen diagram). The Voronoi diagram is created when a region with n points is partitioned into convex polygons such that each polygon contains exactly one generating point, and every point in a given polygon is closer to its generating point than to any other.\nGiven a set of points, we can create a Voronoi diagram with the voronoi() function of terra specifying the points as an object of class SpatVector of terra, and map to set the outer boundary of the Voronoi diagram. This returns a Voronoi diagram for the set of points assuming constant values in each of the polygons.\nThen, we can use the functions tm_shape() and tm_fill() of tmap to plot the values of the variable in each of the polygons indicating the name of the variable col = \"vble\", the palette palette = \"viridis\" and the level of transparency alpha = 0.6 (if the plot is interactive).\n\n# Voronoi\nv &lt;- voronoi(x = vect(regression.points), bnd = valtellina_boundary)\nplot(v)\npoints(vect(regression.points), cex = 0.5)\n\n# Prediction\nv &lt;- st_as_sf(v)\ntm_shape(v) +\n  tm_fill(col = \"Landuse_Vegetation\", palette = \"Spectral\")\n\n\nresp &lt;- st_intersection(v, coop)\nresp$pred &lt;- resp$Landuse_Vegetation\n\npred_voronoi &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nvoronoi_map &lt;- tm_shape(pred_voronoi) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Voronoi\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nvoronoi_map\n\n\n\n\nIn the IDW method, values at unsampled locations are estimated as the weighted average of values from the rest of locations with weights inversely proportional to the distance between the unsampled and the sampled locations.\nWe can apply the IDW method with the gstat() function of gstat and the following arguments:\n\nformula: vble ~ 1 to have an intercept only model,\nnmax: number of neighbors is set equal to the total number of locations,\nidp: inverse distance power is set to idp = 1 to have weights with β=1�=1.\n\nThen, we use the predict() function to obtain the predictions and tmap to show the results\n\npacman::p_load(gstat)\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points,\n             nmax = nrow(regression.points), # use all the neighbors locations\n             set = list(idp = 1)) # beta = 1 \n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_idw &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nidw_map &lt;- tm_shape(pred_idw) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"IDW\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nidw_map\n\n\n\n\nIn the nearest neighbors interpolation method, values at unsampled locations are estimated as the average of the values of the k closest sampled locations. Specifically,\nWe can compute predictions using nearest neighbors interpolation with the gstat() function of gstat. Here, we consider the number of closest sampled locations equal to 5 by setting nmax = 5. Unlike the IDW method, in the nearest neighbors approach locations further away from the location where we wish to predict are assigned the same weights. Therefore, the inverse distance power idp is set equal to zero so all the neighbors are equally weighted.\nThen, we use the predict() function to get predictions at unsampled locations given in coop.\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_nn &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nnn_map &lt;- tm_shape(pred_nn) + \n  tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Nearest Neighbour\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nnn_map\n\n\n\n\nPredictions can also be obtained using an ensemble approach that combines the predictions obtained with several spatial interpolation methods.\nHere, we use an ensemble approach to predict the price per square meter of apartments in Athens by combining the predictions of the three previous approaches (closest observation, IDW, nearest neighbors) using equal weights.\nThe predictions with the closest observation method are obtained using the Voronoi diagram as follows:\n\n# Closest observation (Voronoi)\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\n\nThe IDW approach can be applied with the gstat() function of gstat specifying nmax as the total number of locations and idp = 1.\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\n\nThe nearest neighbors method is applied with the gstat() function specifying nmax as the number of neighbors and with equal weights (idp = 0).\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\n\nFinally, the ensemble predictions are obtained by combining the predictions of these three methods with equal weights.\n\n# Ensemble (equal weights)\nweights &lt;- c(1/3, 1/3, 1/3)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\n\nWe create a map with the predictions by creating a raster with the predictions and using the tmap package.\n\nresp &lt;- data.frame(\nx = st_coordinates(coop)[, 1],\ny = st_coordinates(coop)[, 2],\npred = p4)\n\nresp &lt;- st_as_sf(resp, coords = c(\"x\", \"y\"), crs = st_crs(map))\n\npred_ensemble &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\n ensemble_map &lt;- tm_shape(pred_ensemble) + \n   tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n             midpoint = NA) +\n tm_layout(main.title = \"Ensemble\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n \n ensemble_map\n\n\ntmap_arrange(voronoi_map, idw_map, nn_map, ensemble_map)\n\n\nwriteRaster(pred_nn, \"~/IS485-Landslide/data/gwr_maps/landuse_nn.tif\", overwrite=TRUE)\nwriteRaster(pred_idw, \"~/IS485-Landslide/data/gwr_maps/landuse_idw.tif\", overwrite=TRUE)\nwriteRaster(pred_voronoi, \"~/IS485-Landslide/data/gwr_maps/landuse_voronoi.tif\", overwrite=TRUE)\nwriteRaster(pred_ensemble, \"~/IS485-Landslide/data/gwr_maps/landuse_ensemble.tif\", overwrite=TRUE)\n\n\n\n\nWe can assess the performance of each of the methods presented above using K-fold cross-validation and the root mean squared error (RMSE). First, we split the data in K parts. For each part, we use the remaining K−1 parts (training data) to fit the model and that part (testing data) to predict. We compute the RMSE by comparing the testing and predicted data in each of the K parts.\nNote that if K is equal to the number of observations n, this procedure is called leave-one-out cross-validation (LOOCV). That means that n separate data sets are trained on all of the data except one observation, and then prediction is made for that one observation.\nHere, we assess the performance of each of the methods previously employed to predict the prices of apartments in Athens. We create training and testing sets by using the dismo:kfold() function of the dismo package (Hijmans et al. 2022) to randomly assign the observations to K=5 groups of roughly equal size. For each group, we fit the model using the training data, and obtain predictions of the testing data. We calculate the RMSEs of each part and average the RMSEs to obtain a K-fold cross-validation estimate.\n\npacman::p_load(dismo)\n\n\nRMSE &lt;- function(observed, predicted) {\nsqrt(mean((observed - predicted)^2))\n}\n\n# Split data in 5 sets\nkf &lt;- dismo::kfold(nrow(regression.points), k = 5) # K-fold partitioning\n\n# Vectors to store the RMSE values obtained with each method\nrmse1 &lt;- rep(NA, 5) # Closest observation\nrmse2 &lt;- rep(NA, 5) # IDW\nrmse3 &lt;- rep(NA, 5) # Nearest neighbors\nrmse4 &lt;- rep(NA, 5) # Ensemble\n\n\nfor(k in 1:5) {\n# Split data in test and train\ntest &lt;- regression.points[kf == k, ]\ntrain &lt;- regression.points[kf != k, ]\n\n# Closest observation\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\nrmse1[k] &lt;- RMSE(test$Landuse_Vegetation, p1)\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\nrmse2[k] &lt;- RMSE(test$Landuse_Vegetation, p2)\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\nrmse3[k] &lt;- RMSE(test$Landuse_Vegetation, p3)\n\n# Ensemble (weights are inverse RMSE so lower RMSE higher weight)\nw &lt;- 1/c(rmse1[k], rmse2[k], rmse3[k])\nweights &lt;- w/sum(w)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\nrmse4[k] &lt;- RMSE(test$Landuse_Vegetation, p4)\n}\n\nThe RMSE values obtained in each of the 5 splits are shown below.\n\n# RMSE obtained for each of the 5 splits\ndata.frame(closest.obs = rmse1, IDW = rmse2,\n           nearest.neigh = rmse3, ensemble = rmse4)\n\nWe see the minimum average RMSE corresponds to the ensemble method.\n\n# Average RMSE over the 5 splits\ndata.frame(closest.obs = mean(rmse1), IDW = mean(rmse2),\n           nearest.neigh = mean(rmse3), ensemble = mean(rmse4))"
  },
  {
    "objectID": "slopesampling.html#page-break",
    "href": "slopesampling.html#page-break",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "write.csv(sample_Q6, \"~/IS485-Landslide/data/aspatial/slope_20degree.csv\")\nwrite.csv(sample_Q7, \"~/IS485-Landslide/data/aspatial/slope_15degree.csv\")"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Is There a Space in Landslide Susceptibility Modelling: A Case Study of Valtellina Valley, Northern Italy",
    "section": "",
    "text": "Introduction\n\nLandslides refer to the geomorphic phenomenon of slope failure and mass movement in mountainous regions due to eroding and depositing sediment. In the span of the last five decades, the frequency of landslide events has increased tenfold [1]. Landslides are complex geomorphic phenomena and are driven by tectonic, climatic and/or human activities [2]. Landslides pose a frequent threat to critical infrastructure and urban communities worldwide, causing increasingly costly damage and massive displacement that hampers urban development [3-6].\nExtensive engineering prevention works such as concrete surfacing, terracing [7] and slope modification [8] are typical, successful landslide risk mitigations for more gradually sloped areas. However, implementing these works on steeper terrains incurs greater costs due to the complexity of these modifications. Slope geometry alterations, complex drainage systems installations, and reinforcing internal structures for a single high-risk site easily cost millions [8]. With the implementation of landslide susceptibility maps and assessments, tiering areas according to their instability levels could supplement in urban planning decisions and the prioritization of the highest-risk areas which kickstart the formulation of preventive measures and site suitability assessments for new developments [9].\nIn this study, global and local versions of statistical and machine learning techniques explore the explanatory factors influencing landslide susceptibility and the prediction of susceptibility areas within our study area. Two statistical models – Logistic Regression (LR) and Geographically Weighted Logistic Regression (GWLR) models and two machine learning models – Random Forest (RF) and Geographically Weighted Random Forest (GWRF) are fitted and developed in this study. Landslide occurrences are closely related to the characteristics of the environment and the explanatory variables of landslides are unlikely to have an equal and constant contribution to their occurrences [10] over the entire study area. When working with spatial datasets, conventional modelling approaches such as LR and RF attempt to treat observations as independent values and usually produce parameter estimates and predictions which do not consider spatial aspects such as spatial dependency and spatial heterogeneity. Using models that are not calibrated to model underlying spatial structures is likely to produce results with less ground-realistic inferences [11] and overlook local variations or structures. This study aims to draw a comparative case study between these global models and their spatial and local derivate models, analysing how global models can be calibrated into local derivates to account for spatial relationship as well as to improve the model outcomes.\n\nReferences\n\n\nCendrero, A., Forte, L.M., Remondo, J., Cuesta‐Albertos, J.A.: Anthropocene Geomorphic Change. climate or human activities? Earth’s Future. 8, (2020)\nFroude, M.J., Petley, D.N.: Global fatal landslide occurrence from 2004 to 2016. Natural Hazards and Earth System Sciences. 18, 2161–2181 (2018)\nAleotti, P., Chowdhury, R.: Landslide hazard assessment: Summary review and new perspectives. Bulletin of Engineering Geology and the Environment. 58, 21–44 (1999)\nBudimir, M.E., Atkinson, P.M., Lewis, H.G.: A systematic review of landslide probability mapping using logistic regression. Landslides. 12, 419–436 (2015)\nWang, H., Zhang, L., Yin, K., Luo, H., Li, J.: Landslide identification using machine learning. Geoscience Frontiers. 12, 351–364 (2021)\nZulkafli, S.A., Abd Majid, N., Rainis, R.: Spatial analysis on the variances of landslide factors using geographically weighted logistic regression in Penang Island, Malaysia. Sustainability. 15, 852 (2023)\nShrestha, A.B., Ezee, G.C., Adhikary, R.P., Rai, S.K.: Resource Manual on Flash Flood Risk Management; module 3 - structural measures. (2012)\nPopescu, M.E., Sasahara, K.: Engineering measures for landslide disaster mitigation. Landslides – Disaster Risk Reduction. 609–631 (2009)\nRegmi, N.R., Giardino, J.R., McDonald, E.V., Vitek, J.D.: A comparison of logistic regressionbased models of susceptibility to landslides in western Colorado, USA. Landslides. 11, 247–262 (2013)\nAchu, A.L., Aju, C.D., Di Napoli, M., Prakash, P., Gopinath, G., Shaji, E., Chandra, V.: Machinelearning based landslide susceptibility modelling with emphasis on uncertainty analysis. Geoscience Frontiers. 14, 101657 (2023)\nLiu, X., Kounadi, O., Zurita-Milla, R.: Incorporating Spatial Autocorrelation in Machine Learning Models Using Spatial Lag and Eigenvector Spatial Filtering Features. ISPRS Int. J. Geo-Inf. 11, (2022)"
  },
  {
    "objectID": "explanatorymodelling.html",
    "href": "explanatorymodelling.html",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "",
    "text": "Landslide susceptibility modelling is emerging field of research that aims to identify the contributing factors of landslides and predict areas that are most susceptible. These studies serve as a valuable decision-support tool, helping us identify the areas at highest risk and implement preventive measures accordingly. In this research project, we aims to demonstrate the potential contribution of spatial non-stationarity in landslide susceptibility modelling. Particuarly, two statistical model frameworks are employed to model explanatory landslide susceptibility.\n\nLogistic Regression (stats package)\nGeographically Weighted Logistic Regression (GWmodel package)\n\nThe modelling will start with the parametric tests and analyses associated with the fundamental concepts and theories of these frameworks. This is followed by model training, validation, and evaluation. Subsequently, measures of variable coefficients as well as target outcome estimates are extracted and interpolated to discuss the model results, culminating in the creation of the landslide susceptibility map."
  },
  {
    "objectID": "explanatorymodelling.html#checking-data-class",
    "href": "explanatorymodelling.html#checking-data-class",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "3.1 Checking Data Class",
    "text": "3.1 Checking Data Class\nFirst, we need to check the class of our datasets to ensure they are suitable for spatial analysis in R.\n\nclass(valtellina)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\nclass(train_grids_v4)\n\n[1] \"data.frame\"\n\n\nFrom the results, we find that valtellina is already an sf object, which is suitable for spatial analysis in R. However, we find that train_grids_v4 is a data.frame."
  },
  {
    "objectID": "explanatorymodelling.html#transforming-data-to-simple-feature-objects",
    "href": "explanatorymodelling.html#transforming-data-to-simple-feature-objects",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "3.2 Transforming Data to Simple Feature Objects",
    "text": "3.2 Transforming Data to Simple Feature Objects\nTo facilitate spatial data manipulation in R, we will convert it to a simple features (sf) object. The st_as_sf function from the sf package is used for this conversion. The X and Y columns in train_grids_v4 provide the XY-coordinates for each data observation.\n\ntrain_grid_v4.sf &lt;- st_as_sf(train_grids_v4,\n                            coords = c(\"X\", \"Y\"))\n\nTo ensure accurate spatial analysis, it’s crucial that our spatial data is in the correct coordinate reference system (CRS). Different CRSs can lead to different results. Therefore, we will set the CRS of train_grid_v4.sf to WGS 84 / UTM zone 32N (EPSG code 32632), which is suitable for accurate distance and area calculations.\nThe code chunk below sets the CRS for train_grid_v4.sf\n\ntrain_grid_v4.sf &lt;- st_set_crs(train_grid_v4.sf, 32632) \n\nBy setting the appropriate CRS, we ensure that our spatial data is in a projected system suitable for accurate distance and area calculations. This is a crucial step in preparing our data for further spatial analysis."
  },
  {
    "objectID": "explanatorymodelling.html#summary-statistics",
    "href": "explanatorymodelling.html#summary-statistics",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "4.1 Summary Statistics",
    "text": "4.1 Summary Statistics\nFirst, we calculate the summary statistics of the train_grids_v4 data frame using the st() function. This will provide us with a general understanding of the dataset’s characteristics.\n\nst(train_grids_v4)\n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nStd. Dev.\nMin\nPctl. 25\nPctl. 75\nMax\n\n\n\n\nTrain_ID\n50563\n25282\n14596\n1\n12642\n37922\n50563\n\n\nGrid_ID\n50563\n7258576\n4280699\n154\n3455206\n11141722\n14724829\n\n\nX\n50563\n573312\n27325\n519097\n550687\n594547\n624487\n\n\nY\n50563\n5129116\n17040\n5095541\n5115266\n5143076\n5164991\n\n\nLandslide\n50563\n0.83\n0.38\n0\n1\n1\n1\n\n\nElevation\n50563\n1913\n677\n0\n1509\n2420\n3924\n\n\nSlope_Angle\n50563\n29\n15\n0\n18\n39\n83\n\n\nAspect_North\n50563\n0.061\n0.24\n0\n0\n0\n1\n\n\nAspect_NorthEast\n50563\n0.12\n0.32\n0\n0\n0\n1\n\n\nAspect_East\n50563\n0.14\n0.34\n0\n0\n0\n1\n\n\nAspect_SouthEast\n50563\n0.15\n0.35\n0\n0\n0\n1\n\n\nAspect_South\n50563\n0.16\n0.36\n0\n0\n0\n1\n\n\nAspect_SouthWest\n50563\n0.15\n0.36\n0\n0\n0\n1\n\n\nAspect_West\n50563\n0.13\n0.34\n0\n0\n0\n1\n\n\nProfile_Curvature\n50563\n-0.00043\n0.0012\n-0.0066\n-0.0011\n0.00022\n0.0079\n\n\nPlan_Curvature\n50563\n-0.00019\n0.0011\n-0.0056\n-0.00071\n0.00032\n0.0068\n\n\nLithology_Metamorphic\n50563\n0.42\n0.49\n0\n0\n1\n1\n\n\nLithology_Sedimentary\n50563\n0.24\n0.42\n0\n0\n0\n1\n\n\nLithology_Plutonic\n50563\n0.057\n0.23\n0\n0\n0\n1\n\n\nLithology_Unconsolidated\n50563\n0.29\n0.45\n0\n0\n1\n1\n\n\nProximity_Settlement\n50563\n904\n764\n0\n328\n1288\n5600\n\n\nProximity_Stream\n50563\n12\n12\n0\n3.1\n17\n97\n\n\nProximity_Road\n50563\n26\n22\n0\n6.3\n40\n125\n\n\nProximity_Fault\n50563\n828\n1032\n0\n199\n1012\n7746\n\n\nLanduse_Vegetation\n50563\n0.51\n0.5\n0\n0\n1\n1\n\n\nPrecipitation\n50563\n0.15\n0.048\n0\n0.13\n0.17\n0.29\n\n\nTWI\n50563\n7.5\n2.3\n3.7\n6\n8.3\n23\n\n\nSPI\n50563\n0.0065\n0.029\n0\n0.00024\n0.0032\n1.4\n\n\nSTI\n50563\n7.7\n27\n0\n0\n5.8\n877"
  },
  {
    "objectID": "explanatorymodelling.html#correlation-matrix",
    "href": "explanatorymodelling.html#correlation-matrix",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "4.2 Correlation Matrix",
    "text": "4.2 Correlation Matrix\nBefore building a logistic regression model, it’s important to ensure that the independent variables used are not highly correlated with each other. If highly correlated independent variables are used in building a regression model, the quality of the model will be compromised.\nPearson’s correlation is a commonly used correlation coefficient to calculate and visualize the relationships between the independent variables. It measures the linear relationship between the two variables and takes values between -1 and 1; -1 means a total negative linear correlation, 0 means no correlation, and 1 means a total positive correlation. Pearson’s correlation can be calculated using the formula:\n\\[\nr = \\frac{\\sum{(x_i - \\bar{x})(y_i - \\bar{y})}}{\\sqrt{\\sum{(x_i - \\bar{x})^2(y_i - \\bar{y})^2}}}\n\\]\nWe use ggcorrmat to create the correlation matrix. This function from the ggstatsplot package allows us to visualize the correlation matrix in a more aesthetically pleasing and informative manner.\n\nset.seed(123)\n## producing the correlation matrix\nggcorrmat(\n  data = train_grids_v4[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + ## modification outside `{ggstatsplot}` using `{ggplot2}` functions\n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\nThe use of color intensity and symbols (X for non-significant correlations) makes it easy to identify strong, weak, or non-existent correlations quickly. The colors range from green (positive correlation) through white (no correlation) to orange (negative correlation). An “X” mark is placed on cells where the correlation is not statistically significant at p &lt; 0.05 after adjustment for multiple comparisons using Holm’s method. This helps in distinguishing meaningful relationships from random associations.\n\n\n\n\n\n\nObservation\n\n\n\nThe maximum correlation coefficient area is observed at 0.55 for pair between elevation and distance to settlement and at 0.49 for pair between elevation and distance to road as well as SPI and STI. Modern civilisation is built on lower elevations and accounts for the moderate coefficients. Other factors exhibit a range of low to moderate correlations. Overall, no factors among those selected for this study exhibit high positive correlation."
  },
  {
    "objectID": "explanatorymodelling.html#fitting-logistic-regression-model-1",
    "href": "explanatorymodelling.html#fitting-logistic-regression-model-1",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.1 Fitting Logistic Regression Model 1",
    "text": "5.1 Fitting Logistic Regression Model 1\nThe glm function fits generalized linear models, a class of models that includes logistic regression. The syntax of the glm function is similar to that of lm, except that we must pass the argument family = binomial in order to tell R to run a logistic regression rather than some other type of generalized linear model.\nUnder general logistic regression, all variables are considered first. We use the glm function to fit a basic LR model (LR 1) with all the variables.\n\nset.seed(1234)\n\nlandslide.lr &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = train_grids_v4)\n\n\n5.1.1 Printing Model Summary\nWe can print the summary of the model to understand the coefficients, standard errors, and significance levels of the variables. The summary function from the base package in R is used for this purpose.\n\nsum_lr &lt;- summary(landslide.lr)\nsum_lr\n\n\nCall:\nglm(formula = Landslide ~ Elevation + Slope_Angle + Aspect_North + \n    Aspect_NorthEast + Aspect_East + Aspect_SouthEast + Aspect_South + \n    Aspect_SouthWest + Aspect_West + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Sedimentary + Lithology_Plutonic + \n    Lithology_Unconsolidated + Proximity_Settlement + Proximity_Stream + \n    Proximity_Road + Proximity_Fault + Landuse_Vegetation + Precipitation + \n    TWI + SPI + STI, family = \"binomial\", data = train_grids_v4)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.243e+00  1.893e-01 -11.847  &lt; 2e-16 ***\nElevation                 5.790e-05  3.517e-05   1.646 0.099718 .  \nSlope_Angle               1.706e-01  1.954e-03  87.343  &lt; 2e-16 ***\nAspect_North             -3.510e-02  8.618e-02  -0.407 0.683821    \nAspect_NorthEast         -2.225e-01  7.213e-02  -3.084 0.002041 ** \nAspect_East              -1.617e-01  7.128e-02  -2.268 0.023321 *  \nAspect_SouthEast         -2.401e-01  6.917e-02  -3.472 0.000517 ***\nAspect_South             -1.812e-01  6.829e-02  -2.653 0.007975 ** \nAspect_SouthWest         -4.600e-02  6.949e-02  -0.662 0.508031    \nAspect_West              -4.762e-02  7.108e-02  -0.670 0.502869    \nProfile_Curvature        -6.228e+02  1.777e+01 -35.052  &lt; 2e-16 ***\nPlan_Curvature           -5.890e+02  2.009e+01 -29.320  &lt; 2e-16 ***\nLithology_Metamorphic     1.109e+00  9.629e-02  11.522  &lt; 2e-16 ***\nLithology_Sedimentary     1.577e+00  1.005e-01  15.687  &lt; 2e-16 ***\nLithology_Plutonic       -3.030e-02  8.847e-02  -0.343 0.731946    \nLithology_Unconsolidated  1.499e+00  9.792e-02  15.312  &lt; 2e-16 ***\nProximity_Settlement      4.360e-05  2.970e-05   1.468 0.142100    \nProximity_Stream         -6.250e-03  1.593e-03  -3.924 8.72e-05 ***\nProximity_Road           -2.343e-03  1.026e-03  -2.283 0.022445 *  \nProximity_Fault          -1.315e-04  1.615e-05  -8.146 3.77e-16 ***\nLanduse_Vegetation        6.692e-01  4.060e-02  16.483  &lt; 2e-16 ***\nPrecipitation            -3.469e+00  4.229e-01  -8.202 2.37e-16 ***\nTWI                      -1.067e-01  9.637e-03 -11.067  &lt; 2e-16 ***\nSPI                       1.191e+00  7.010e-01   1.699 0.089396 .  \nSTI                      -5.287e-04  7.677e-04  -0.689 0.491022    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 22929  on 50538  degrees of freedom\nAIC: 22979\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n\n5.1.2 Calculating Percentage of Deviance Explained\nIn Generalized Linear Models (GLMs), deviance is a measure of goodness of fit. Specifically, deviance is a measure of the discrepancy between the data and the model’s predictions. The null deviance shows how well the response variable is predicted by a model that includes only the intercept (no predictors). The model’s deviance shows how well the response variable is predicted by the model.\nIn mathematical terms, the percentage of deviance explained is calculated as:\n\\[\n\\text{Percentage of Deviance Explained} = \\left(1 - \\frac{D_{\\text{model}}}{D_{\\text{null}}} \\right) \\times 100\n\\]\nBelow is the code chunk used to calculate the percentage of deviance using the following steps\n\nCalculate the total deviance, which is the null deviance.\nSubtract the model’s deviance from the null deviance. This gives the amount of deviance explained by the model.\nDivide the explained deviance by the null deviance and multiply by 100 to get the percentage.\n\n\npd &lt;- 100*with(summary(landslide.lr), 1 - deviance/null.deviance)\npd\n\n[1] 50.89114\n\n\n\n\n5.1.2 Computing Confidence Intervals\nWe calculate the confidence intervals for the coefficients of the variables in our model. The confint function from the stats package in R is used for this purpose.\n\nconfint(landslide.lr)\n\nWaiting for profiling to be done...\n\n\n                                 2.5 %        97.5 %\n(Intercept)              -2.614798e+00 -1.872528e+00\nElevation                -1.100535e-05  1.268617e-04\nSlope_Angle               1.668213e-01  1.744792e-01\nAspect_North             -2.036349e-01  1.342130e-01\nAspect_NorthEast         -3.639457e-01 -8.116805e-02\nAspect_East              -3.014909e-01 -2.205432e-02\nAspect_SouthEast         -3.758587e-01 -1.047178e-01\nAspect_South             -3.152073e-01 -4.749895e-02\nAspect_SouthWest         -1.823284e-01  9.008984e-02\nAspect_West              -1.870295e-01  9.162142e-02\nProfile_Curvature        -6.577535e+02 -5.880979e+02\nPlan_Curvature           -6.284441e+02 -5.496984e+02\nLithology_Metamorphic     9.214128e-01  1.298931e+00\nLithology_Sedimentary     1.380869e+00  1.775060e+00\nLithology_Plutonic       -2.039839e-01  1.428812e-01\nLithology_Unconsolidated  1.308214e+00  1.692127e+00\nProximity_Settlement     -1.450154e-05  1.019138e-04\nProximity_Stream         -9.364838e-03 -3.120470e-03\nProximity_Road           -4.349682e-03 -3.261896e-04\nProximity_Fault          -1.631453e-04 -9.983405e-05\nLanduse_Vegetation        5.897524e-01  7.489057e-01\nPrecipitation            -4.298446e+00 -2.640479e+00\nTWI                      -1.256194e-01 -8.783854e-02\nSPI                      -1.375593e-01  2.613875e+00\nSTI                      -2.021054e-03  9.886275e-04\n\n\n\n\n5.1.3 Validating Logistic Regression Model 1\nIn this step, we validate the logistic regression model that we built in the previous step. Validation is a crucial part of the modeling process because it helps us understand how well our model performs on unseen data.\nWe use the blr_confusion_matrix function from the blr package in R to create a confusion matrix for our model. A confusion matrix is a table that is often used to describe the performance of a classification model on a set of data for which the true values are known.\nThe cutoff argument in the blr_confusion_matrix function is used to decide the threshold for classifying a probability into a binary outcome. In this case, we set the cutoff to 0.5, which means that if the predicted probability is greater than or equal to 0.5, the outcome is classified as 1 (landslide), otherwise it is classified as 0 (no landslide).\n\ncm &lt;- blr_confusion_matrix(landslide.lr, cutoff = 0.5)\ncm\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0  6548  1292\n         1  2235 40488\n\n                Accuracy : 0.9302 \n     No Information Rate : 0.1737 \n\n                   Kappa : 0.7462 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.9691 \n             Specificity : 0.7455 \n          Pos Pred Value : 0.9477 \n          Neg Pred Value : 0.8352 \n              Prevalence : 0.8263 \n          Detection Rate : 0.8007 \n    Detection Prevalence : 0.8449 \n       Balanced Accuracy : 0.8573 \n               Precision : 0.9477 \n                  Recall : 0.9691 \n\n        'Positive' Class : 1\n\n\nThe output cm is the confusion matrix for our logistic regression model. It shows the number of true positives, true negatives, false positives, and false negatives. This information can be used to calculate various performance metrics such as accuracy, precision, recall, and F1 score."
  },
  {
    "objectID": "explanatorymodelling.html#curse-of-multicollinearity",
    "href": "explanatorymodelling.html#curse-of-multicollinearity",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.2 Curse of Multicollinearity",
    "text": "5.2 Curse of Multicollinearity\nRegression models are sensitive to multicollinearity. Multicollinearity arises when two or more explanatory variables in a regression model display moderate or high correlation among each other. The presence of multicollinearity makes it difficult to assess the individual importance and significance of a predictor. Subsequently, variance inflation factor (VIF) and tolerance (TOL) values are calculated to further evaluate landslide variables. VIF is a statistical measure used in regression analysis to observe the increase in variance of the regression coefficient estimates due to multicollinearity. Mathematically, VIF can be calculated using the formula:\n\\[\nVIF = \\frac{1}{1 - R_j^2} = \\frac{1}{TOL}\n\\]\n\n5.2.1 Calculate Variance Inflation Factor (VIF)\nWe use the multicollinearity function from the performance package to calculate the VIF.\n\nvif &lt;- multicollinearity(landslide.lr)\nvif\n\n# Check for Multicollinearity\n\nLow Correlation\n\n                 Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n            Elevation 2.36 [2.33, 2.40]         1.54      0.42     [0.42, 0.43]\n          Slope_Angle 1.69 [1.67, 1.71]         1.30      0.59     [0.58, 0.60]\n         Aspect_North 1.50 [1.48, 1.52]         1.22      0.67     [0.66, 0.68]\n     Aspect_NorthEast 1.91 [1.88, 1.93]         1.38      0.52     [0.52, 0.53]\n          Aspect_East 1.95 [1.93, 1.98]         1.40      0.51     [0.51, 0.52]\n     Aspect_SouthEast 2.09 [2.07, 2.12]         1.45      0.48     [0.47, 0.48]\n         Aspect_South 2.15 [2.12, 2.17]         1.46      0.47     [0.46, 0.47]\n     Aspect_SouthWest 2.03 [2.00, 2.05]         1.42      0.49     [0.49, 0.50]\n          Aspect_West 1.93 [1.90, 1.95]         1.39      0.52     [0.51, 0.53]\n    Profile_Curvature 1.42 [1.41, 1.44]         1.19      0.70     [0.70, 0.71]\n       Plan_Curvature 1.49 [1.47, 1.51]         1.22      0.67     [0.66, 0.68]\n   Lithology_Plutonic 1.91 [1.89, 1.94]         1.38      0.52     [0.52, 0.53]\n Proximity_Settlement 1.79 [1.77, 1.81]         1.34      0.56     [0.55, 0.57]\n     Proximity_Stream 1.29 [1.28, 1.31]         1.14      0.77     [0.76, 0.78]\n       Proximity_Road 1.82 [1.80, 1.84]         1.35      0.55     [0.54, 0.56]\n      Proximity_Fault 1.06 [1.05, 1.07]         1.03      0.94     [0.94, 0.95]\n   Landuse_Vegetation 1.39 [1.37, 1.40]         1.18      0.72     [0.71, 0.73]\n        Precipitation 1.30 [1.28, 1.31]         1.14      0.77     [0.76, 0.78]\n                  TWI 2.20 [2.17, 2.23]         1.48      0.45     [0.45, 0.46]\n                  SPI 1.31 [1.29, 1.32]         1.14      0.76     [0.76, 0.77]\n                  STI 1.31 [1.29, 1.32]         1.14      0.76     [0.76, 0.77]\n\nModerate Correlation\n\n                     Term  VIF   VIF 95% CI Increased SE Tolerance\n    Lithology_Metamorphic 7.44 [7.32, 7.57]         2.73      0.13\n    Lithology_Sedimentary 5.13 [5.05, 5.21]         2.27      0.19\n Lithology_Unconsolidated 7.69 [7.56, 7.81]         2.77      0.13\n Tolerance 95% CI\n     [0.13, 0.14]\n     [0.19, 0.20]\n     [0.13, 0.13]\n\n\n\nplot(vif)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\nThere are currently no established criteria for identifying the extent of variance inflation factors that result in poorly estimated coefficients. A frequently used benchmark for VIF in numerous regression studies is VIF ≥ 5. Values ≥ 5 indicate significant multicollinearity and may necessitate further investigation or actions.\n\n\n\n\n\n\nObservation\n\n\n\nResults of multicollinearity test between explanatory landslide factors are presented in Table 2. Three lithological categories – metamorphic, sedimentary and unconsolidated shows high VIF values of 7.85, 5.98 and 9.42 respectively, indicating moderate multicollinearity.\n\n\n\n\n5.2.2 Remove Variable with High Multicollinearity\nTo avoid potential issues in subsequent modelling results, the variable with the highest VIF value, lithology (unconsolidated) is removed from the dataset.\n\ntrain_grids_v4 &lt;- subset(train_grids_v4, select = -Lithology_Unconsolidated)\n\nWe then fit the logistic regression model again without the Lithology_Unconsolidated variable.\n\nlandslide.lr &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = train_grids_v4)\n\nWe can plot the VIF values again to check if the multicollinearity problem has been resolved.\n\nplot(multicollinearity(landslide.lr))\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAll the VIF values after the removal are less than 2.27 and TOL values are all above 0.44, indicating that there is no more collinearity problem observed among factors."
  },
  {
    "objectID": "explanatorymodelling.html#stepwise-selection",
    "href": "explanatorymodelling.html#stepwise-selection",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.3 Stepwise Selection",
    "text": "5.3 Stepwise Selection\nIn the initial model, all the independent variables are included. However, including too many variables in a model can lead to overfitting. Overfitting is a modeling error that occurs when a function is too closely aligned to a limited set of data points. An overfitted model may result in an algorithm that is excessively complex, such as one involving a function that has too many parameters relative to the number of observations. A model that has been overfitted will generally have poor predictive performance, as it can exaggerate minor fluctuations in the data.\nThe goal of this step is to create a more parsimonious model, which means we aim to include a limited number of independent variables (between 5 and 15) that are all statistically significant, without sacrificing too much on the model’s performance.\nTo achieve this, we employ a stepwise variable selection procedure. Stepwise selection is a method of fitting regression models in which the choice of predictive variables is carried out by an automatic procedure. In each step, a variable is considered for addition to or subtraction from the set of explanatory variables based on some prespecified criterion.\nWe use the blr_step_aic_both() function from the blr package in R for this purpose. This function performs both forward and backward stepwise variable selection based on the Akaike Information Criterion (AIC). The AIC is a measure of the relative quality of a statistical model for a given set of data. It provides a means for model selection by comparing different models and choosing the one that minimizes the information loss.\n\nstepwise_1 &lt;- blr_step_aic_both(landslide.lr)\n\nWe then load the results of the stepwise selection process to see which variables were selected.\n\nstepwise1\n\n\n                             Stepwise Summary                             \n------------------------------------------------------------------------\nVariable                  Method        AIC          BIC       Deviance  \n------------------------------------------------------------------------\nSlope_Angle              addition    27757.416    27775.078    27753.416 \nProfile_Curvature        addition    25065.141    25091.634    25059.141 \nPlan_Curvature           addition    24303.970    24339.294    24295.970 \nLanduse_Vegetation       addition    23891.260    23935.415    23881.260 \nLithology_Plutonic       addition    23677.727    23730.713    23665.727 \nPrecipitation            addition    23539.203    23601.020    23525.203 \nProximity_Fault          addition    23430.433    23501.081    23414.433 \nTWI                      addition    23337.014    23416.493    23319.014 \nLithology_Sedimentary    addition    23278.363    23366.672    23258.363 \nLithology_Metamorphic    addition    23256.786    23353.927    23234.786 \nProximity_Stream         addition    23245.816    23351.788    23221.816 \nAspect_SouthEast         addition    23237.365    23352.167    23211.365 \nProximity_Road           addition    23231.794    23355.428    23203.794 \nAspect_South             addition    23226.738    23359.203    23196.738 \nAspect_NorthEast         addition    23220.038    23361.333    23188.038 \nAspect_East              addition    23216.825    23366.952    23182.825 \nProximity_Settlement     addition    23214.504    23373.462    23178.504 \nSPI                      addition    23213.794    23381.582    23175.794 \n------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nObservation\n\n\n\n17 explanatory variables have been selected in this stepwise selection process. This is a significant reduction from the initial model, which should help to mitigate the risk of overfitting.\n\n\nWe can also plot the AIC values for the different models considered during the stepwise selection process. This helps us visualize how the AIC changes as different variables are added or removed from the model.\n\nplot(stepwise1)\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nIn our first stepwise selection, Slope_Angle has the highest AIC value followed by Profile_Curvature. This suggests that these variables contribute the most information to the model, and removing them would result in the greatest loss of information."
  },
  {
    "objectID": "explanatorymodelling.html#fitting-logistic-regression-model-2",
    "href": "explanatorymodelling.html#fitting-logistic-regression-model-2",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.4 Fitting Logistic Regression Model 2",
    "text": "5.4 Fitting Logistic Regression Model 2\nIn this step, we recalibrate the first model we fitted landslide.lr by updating the logistic regression with the selected variables from stepwise selection.\n\nset.seed(1234)\n\nlandslide.lr2 &lt;- glm(Landslide ~ Slope_Angle + Profile_Curvature +\n                       Plan_Curvature + Landuse_Vegetation +\n                       Lithology_Plutonic + Precipitation +\n                       Proximity_Fault + TWI + Lithology_Sedimentary +\n                       Lithology_Metamorphic +  Proximity_Stream +\n                       Aspect_SouthEast + Proximity_Road + Aspect_South +\n                       Aspect_NorthEast + Aspect_East +\n                       Proximity_Settlement + SPI , family = \"binomial\",\n                       data = train_grids_v4)\n\n\n5.4.1 Printing Model Summary\nWe can print the summary of the LR Model 2 to understand the coefficients, standard errors, and significance levels of the variables.\n\nsum_lr2 &lt;- summary(landslide.lr2)\nsum_lr2\n\n\nCall:\nglm(formula = Landslide ~ Slope_Angle + Profile_Curvature + Plan_Curvature + \n    Landuse_Vegetation + Lithology_Plutonic + Precipitation + \n    Proximity_Fault + TWI + Lithology_Sedimentary + Lithology_Metamorphic + \n    Proximity_Stream + Aspect_SouthEast + Proximity_Road + Aspect_South + \n    Aspect_NorthEast + Aspect_East + Proximity_Settlement + SPI, \n    family = \"binomial\", data = train_grids_v4)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -7.474e-01  1.298e-01  -5.760 8.41e-09 ***\nSlope_Angle            1.677e-01  1.926e-03  87.068  &lt; 2e-16 ***\nProfile_Curvature     -6.246e+02  1.758e+01 -35.525  &lt; 2e-16 ***\nPlan_Curvature        -5.873e+02  1.991e+01 -29.502  &lt; 2e-16 ***\nLanduse_Vegetation     6.894e-01  3.922e-02  17.576  &lt; 2e-16 ***\nLithology_Plutonic    -9.078e-01  7.297e-02 -12.440  &lt; 2e-16 ***\nPrecipitation         -3.645e+00  4.056e-01  -8.987  &lt; 2e-16 ***\nProximity_Fault       -1.499e-04  1.588e-05  -9.439  &lt; 2e-16 ***\nTWI                   -1.022e-01  9.412e-03 -10.862  &lt; 2e-16 ***\nLithology_Sedimentary  2.519e-01  4.969e-02   5.069 3.99e-07 ***\nLithology_Metamorphic -2.087e-01  4.129e-02  -5.053 4.35e-07 ***\nProximity_Stream      -6.511e-03  1.576e-03  -4.130 3.63e-05 ***\nAspect_SouthEast      -2.323e-01  5.103e-02  -4.553 5.29e-06 ***\nProximity_Road        -3.106e-03  9.311e-04  -3.335 0.000852 ***\nAspect_South          -1.801e-01  4.996e-02  -3.604 0.000314 ***\nAspect_NorthEast      -1.885e-01  5.546e-02  -3.399 0.000676 ***\nAspect_East           -1.245e-01  5.412e-02  -2.301 0.021413 *  \nProximity_Settlement   6.046e-05  2.895e-05   2.088 0.036780 *  \nSPI                    9.713e-01  6.048e-01   1.606 0.108268    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 23176  on 50544  degrees of freedom\nAIC: 23214\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n\n5.4.2 Calculating Percentage of Deviance Explained\nNext, we calculate the percentage of deviance to understand how well LR Model 2 fits the data.\n\npd2 &lt;- 100*with(summary(landslide.lr2), 1 - deviance/null.deviance)\npd2\n\n[1] 50.36347\n\n\n\n\n5.4.3 Computing Confidence Intervals\nWe calculate the confidence intervals for the coefficients of the variables in LR Model 2.\n\nconfint(landslide.lr2)\n\nWaiting for profiling to be done...\n\n\n                              2.5 %        97.5 %\n(Intercept)           -1.001625e+00 -4.929632e-01\nSlope_Angle            1.639444e-01  1.714946e-01\nProfile_Curvature     -6.591626e+02 -5.902387e+02\nPlan_Curvature        -6.264255e+02 -5.483871e+02\nLanduse_Vegetation     6.126197e-01  7.663724e-01\nLithology_Plutonic    -1.050818e+00 -7.647598e-01\nPrecipitation         -4.441027e+00 -2.850854e+00\nProximity_Fault       -1.809778e-04 -1.187190e-04\nTWI                   -1.207567e-01 -8.385932e-02\nLithology_Sedimentary  1.546190e-01  3.494003e-01\nLithology_Metamorphic -2.896727e-01 -1.277921e-01\nProximity_Stream      -9.594447e-03 -3.414206e-03\nAspect_SouthEast      -3.322339e-01 -1.321840e-01\nProximity_Road        -4.927678e-03 -1.277477e-03\nAspect_South          -2.778823e-01 -8.201456e-02\nAspect_NorthEast      -2.970017e-01 -7.957527e-02\nAspect_East           -2.303521e-01 -1.819932e-02\nProximity_Settlement   3.799190e-06  1.173025e-04\nSPI                   -1.796589e-01  2.193795e+00\n\n\n\n\n\n\n\n\nObservation\n\n\n\nLR Model 2 is still overfitting and AIC of 23157 is very high.\n\n\n\n\n5.4.4 Validating Logistic Regression Model 2\nAgian, we use the blr_confusion_matrix function from the blr package in R to create a confusion matrix for LR Model 2.\n\ncm2 &lt;- blr_confusion_matrix(landslide.lr2, cutoff = 0.5)\n\ncm2\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0  6431  1254\n         1  2352 40526\n\n                Accuracy : 0.9287 \n     No Information Rate : 0.1737 \n\n                   Kappa : 0.7387 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.9700 \n             Specificity : 0.7322 \n          Pos Pred Value : 0.9451 \n          Neg Pred Value : 0.8368 \n              Prevalence : 0.8263 \n          Detection Rate : 0.8015 \n    Detection Prevalence : 0.8480 \n       Balanced Accuracy : 0.8511 \n               Precision : 0.9451 \n                  Recall : 0.9700 \n\n        'Positive' Class : 1"
  },
  {
    "objectID": "explanatorymodelling.html#comparing-lr-model-1-2",
    "href": "explanatorymodelling.html#comparing-lr-model-1-2",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.5 Comparing LR Model 1 & 2",
    "text": "5.5 Comparing LR Model 1 & 2\nThe two models thus far yield similar results with small changes in accuracy, sensitivity and specificity despite a reduced number of variables from the first to the second model. We create a comparison table using the data.frame function from the base package in R to compare the performance metrics of the two models.\nThe metrics we’ve chosen to include in this comparison table are:\n\nAccuracy: This measures the proportion of total predictions that are correct.\nAIC (Akaike Information Criterion): This is a measure of the relative quality of a statistical model for a given set of data. Lower values indicate better-fitting models.\nSensitivity: This is the true positive rate, indicating the model’s ability to correctly predict positive outcomes.\nSpecificity: This is the true negative rate, reflecting the model’s ability to correctly predict negative outcomes.\nPercentage Deviance Explained: This is a measure of the proportion of the total variability in the response variable that is accounted for by the predictors in the model.\n\n\n\n\nComparing LR Model 1 and LR Model 2\n\n\nInformation\nModel1\nModel2\n\n\n\n\nSample Size\n50563.0000\n50563.0000\n\n\nNon-Landslide\n8783.0000\n8783.0000\n\n\nLandslide\n41780.0000\n41780.0000\n\n\nExplanatory Variable\n24.0000\n17.0000\n\n\nAccuracy\n0.9302\n0.9287\n\n\nAIC\n22979.4204\n23213.7938\n\n\nSensitivity\n0.9691\n0.9700\n\n\nSpecificity\n0.7455\n0.7322\n\n\nPercentage Deviant\n50.8911\n50.3635\n\n\n\n\n\n\n\nThis comparison table provides a side-by-side comparison of the two models, making it easier to see how the performance metrics have changed from the first model to the second model."
  },
  {
    "objectID": "explanatorymodelling.html#weight-of-evidence-information-value",
    "href": "explanatorymodelling.html#weight-of-evidence-information-value",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.6 Weight of Evidence & Information Value",
    "text": "5.6 Weight of Evidence & Information Value\nWeight of Evidence (WoE) is a variable transformation technique meant for independent variables according to Information Theory. WoE measures how good each grouped attribute or bin of a feature can predict the target variable.\nWoE is formulated as:\n\\[\nW~i^+ = ln \\frac{P\\{E~i/I\\}}{P\\{E~i/\\overline{I}\\}}\n\\]\n\\[\nW~i^- = ln \\frac{P\\{\\overline{E}~i/I\\}}{P\\{\\overline{E}~-i/\\overline{I}\\}}\n\\]\n\\[\nW~i = W~i^+ + W~i^-\n\\]\nInformation value (IV) explains the predictive power of the entirety of the feature.\n\\[\nIV = \\sum_{i=1}^{n} (W_i \\times (\\%I - \\%II))\n\\]\nTo calculate the IV of all independent variables in our dataset, we use the create_infotables() function from the Information package.\n\nlibrary(\"Information\")\nIV &lt;- create_infotables(data=train_grids_v4[, 5:28],\n                        valid=train_grids_v4[, 5:28],\n                        y=\"Landslide\")\nkable(IV$Summary[,1:2], row.names=FALSE)\n\n\n\n\nVariable\nIV\n\n\n\n\nSlope_Angle\n5.3574828\n\n\nTWI\n0.5119619\n\n\nElevation\n0.3270770\n\n\nProximity_Settlement\n0.2073722\n\n\nProximity_Road\n0.2060752\n\n\nProfile_Curvature\n0.1481448\n\n\nPlan_Curvature\n0.1469663\n\n\nPrecipitation\n0.1097135\n\n\nProximity_Fault\n0.0931591\n\n\nLithology_Sedimentary\n0.0770191\n\n\nLanduse_Vegetation\n0.0758787\n\n\nProximity_Stream\n0.0606072\n\n\nLithology_Metamorphic\n0.0243440\n\n\nLithology_Plutonic\n0.0184281\n\n\nAspect_East\n0.0028829\n\n\nAspect_SouthEast\n0.0025985\n\n\nAspect_South\n0.0020174\n\n\nAspect_North\n0.0019081\n\n\nAspect_West\n0.0011630\n\n\nSTI\n0.0008136\n\n\nSPI\n0.0007769\n\n\nAspect_SouthWest\n0.0000422\n\n\nAspect_NorthEast\n0.0000023\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nOur analysis reveals that the Slope_Angle variable has the highest predictive power among all variables. This suggests that Slope_Angle may be overly dominant in predicting landslides, as indicated by its unusually high IV value. Further investigation is needed to understand why Slope_Angle has such a significant predictive power."
  },
  {
    "objectID": "explanatorymodelling.html#stratified-slope-sampling",
    "href": "explanatorymodelling.html#stratified-slope-sampling",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.7 Stratified Slope Sampling",
    "text": "5.7 Stratified Slope Sampling\nOur data points are located in various places with varying slope angles. Since our initial IV analysis flags out the over-dominance of Slope_Angle over our model results, we first visualize the distribution of slope angles using a histogram. This will help us detect any unbalanced or irregular distribution patterns that could bias our model.\n\n5.7.1 Plotting Distribution of Slope Angles in Landslide and Non-Landslide Samples\nWe start by plotting the distribution of Slope_Angle in landslide samples.\n\nls_data &lt;- train_grids_v4[train_grids_v4$Landslide==1,]\n\nggplot(data=ls_data, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=100, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in landslide samples\") + \n  geom_vline(xintercept = 20, color = \"red\")\n\n\n\n\nNext, we plot the distribution of Slope_Angle in non-landslide samples.\n\nnon_ls_data &lt;- train_grids_v4[train_grids_v4$Landslide==0,]\n\nggplot(data=non_ls_data, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=100, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in non-landslide samples\") + \n  geom_vline(xintercept = 20, color = \"red\")\n\n\n\n\n\nObservation\nThe majority of landslide samples have slope angles larger than 20°. In contrast, the majority of non-landslide samples have slope angles less than 20°. As such, the current model predicts any instances with a slope angle greater than 20° to be a landslide. This observation suggests that the Slope_Angle variable might be a strong predictor of landslides.\n\n\n\n5.7.2 Implementing Stratified Slope Sampling\nTo address the data bias with the evidence of quasi-separation, we use a 20° cut-off based on the observation above. Quasi-separation is a situation in logistic regression where the outcome variable separates a predictor variable completely, leading to overfitting. By implementing stratified slope sampling, we aim to create a more balanced dataset that can lead to a more robust model.\nBelow is the code chunk for implementing stratified slope sampling. Here, we create two new datasets: ls_data_20 and non_ls_data_20. These datasets contain landslide and non-landslide samples, respectively, with a slope angle of 20° or less.\n\nls_data_20 &lt;- train_grids_v4[train_grids_v4$Landslide==1 & train_grids_v4$Slope_Angle &lt;= 20,]\nnon_ls_data_20 &lt;- train_grids_v4[train_grids_v4$Landslide==0 & train_grids_v4$Slope_Angle &lt;= 20,]\n\n\n\n5.7.3 Plotting Distribution of Slope Angles in Slope-Stratified Landslide and Non-Landslide Samples\nWe then plot the new distribution of slope in landslide samples.\n\nggplot(data=ls_data_20, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=40, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in landslide samples (15° slope cut-off)\")\n\n\n\n\nWe also plot the new distribution of slope in non-landslide samples.\n\nggplot(data=non_ls_data_20, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=40, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in non-landslide samples (20° slope cut-off)\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAlthough the distribution for this stratified non-landslide sample is left-skewed, the data skewness has been reduced significantly. This indicates that our stratified sampling approach has helped to balance the distribution of the Slope_Angle feature in our dataset, which should lead to a more robust and reliable model."
  },
  {
    "objectID": "explanatorymodelling.html#fitting-logistic-regression-model-3",
    "href": "explanatorymodelling.html#fitting-logistic-regression-model-3",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.8 Fitting Logistic Regression Model 3",
    "text": "5.8 Fitting Logistic Regression Model 3\nIn this section, we fit LR Model 3 using the stratified sample created in the previous section. The goal is to see if the stratified sampling approach improves the model’s performance.\n\nlandslide.lr3 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = data_20)\n\n\n5.8.1 Printing Model Summary\nWe then print the summary statistics of Logistic Regression Model 3 to understand the model’s performance and the significance of the explanatory variables.\n\nsum_lr3 &lt;- summary(landslide.lr3)\nsum_lr3\n\n\nCall:\nglm(formula = Landslide ~ Elevation + Slope_Angle + Aspect_North + \n    Aspect_NorthEast + Aspect_East + Aspect_SouthEast + Aspect_South + \n    Aspect_SouthWest + Aspect_West + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Sedimentary + Lithology_Plutonic + \n    Proximity_Settlement + Proximity_Stream + Proximity_Road + \n    Proximity_Fault + Landuse_Vegetation + Precipitation + TWI + \n    SPI + STI, family = \"binomial\", data = data_20)\n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)           -1.604e+00  2.034e-01  -7.887 3.09e-15 ***\nElevation             -2.044e-04  4.452e-05  -4.591 4.40e-06 ***\nSlope_Angle            2.327e-01  4.793e-03  48.544  &lt; 2e-16 ***\nAspect_North          -3.447e-02  1.143e-01  -0.301 0.763080    \nAspect_NorthEast      -2.622e-01  9.729e-02  -2.695 0.007043 ** \nAspect_East           -3.398e-01  9.640e-02  -3.525 0.000424 ***\nAspect_SouthEast      -4.619e-01  9.286e-02  -4.974 6.55e-07 ***\nAspect_South          -3.900e-01  9.048e-02  -4.310 1.63e-05 ***\nAspect_SouthWest      -2.814e-01  9.239e-02  -3.046 0.002323 ** \nAspect_West           -2.256e-01  9.300e-02  -2.426 0.015253 *  \nProfile_Curvature     -8.755e+02  2.675e+01 -32.726  &lt; 2e-16 ***\nPlan_Curvature        -7.710e+02  3.152e+01 -24.459  &lt; 2e-16 ***\nLithology_Metamorphic -4.276e-01  5.686e-02  -7.521 5.42e-14 ***\nLithology_Sedimentary  1.977e-02  6.563e-02   0.301 0.763245    \nLithology_Plutonic    -1.306e+00  1.222e-01 -10.688  &lt; 2e-16 ***\nProximity_Settlement   6.520e-05  4.020e-05   1.622 0.104805    \nProximity_Stream      -5.438e-03  2.109e-03  -2.579 0.009918 ** \nProximity_Road        -5.378e-03  1.407e-03  -3.821 0.000133 ***\nProximity_Fault       -2.002e-05  2.347e-05  -0.853 0.393774    \nLanduse_Vegetation     6.680e-01  5.236e-02  12.757  &lt; 2e-16 ***\nPrecipitation         -5.977e+00  5.811e-01 -10.286  &lt; 2e-16 ***\nTWI                   -3.687e-02  1.124e-02  -3.279 0.001041 ** \nSPI                    1.389e+00  8.664e-01   1.603 0.108898    \nSTI                   -9.181e-04  1.020e-03  -0.900 0.367945    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 19171  on 14019  degrees of freedom\nResidual deviance: 11588  on 13996  degrees of freedom\nAIC: 11636\n\nNumber of Fisher Scoring iterations: 5\n\n\n\n\n5.8.2 Validating Logistic Regression Model 3\nNext, we validate Logistic Regression Model 3 by creating a confusion matrix. This allows us to see the model’s accuracy, sensitivity, and specificity.\n\ncm3 &lt;- blr_confusion_matrix(landslide.lr3, cutoff = 0.5)\ncm3\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction    0    1\n         0 6784 1404\n         1 1188 4644\n\n                Accuracy : 0.8151 \n     No Information Rate : 0.5686 \n\n                   Kappa : 0.6215 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.7679 \n             Specificity : 0.8510 \n          Pos Pred Value : 0.7963 \n          Neg Pred Value : 0.8285 \n              Prevalence : 0.4314 \n          Detection Rate : 0.3312 \n    Detection Prevalence : 0.4160 \n       Balanced Accuracy : 0.8094 \n               Precision : 0.7963 \n                  Recall : 0.7679 \n\n        'Positive' Class : 1\n\n\n\n\n5.8.3 Stepwise Selection\nWe then perform stepwise selection on Logistic Regression Model 3 to filter out only the statistically significant variables.\n\nstepwise_3 &lt;- blr_step_aic_both(landslide.lr3)\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1 . Elevation \n2 . Slope_Angle \n3 . Aspect_North \n4 . Aspect_NorthEast \n5 . Aspect_East \n6 . Aspect_SouthEast \n7 . Aspect_South \n8 . Aspect_SouthWest \n9 . Aspect_West \n10 . Profile_Curvature \n11 . Plan_Curvature \n12 . Lithology_Metamorphic \n13 . Lithology_Sedimentary \n14 . Lithology_Plutonic \n15 . Proximity_Settlement \n16 . Proximity_Stream \n17 . Proximity_Road \n18 . Proximity_Fault \n19 . Landuse_Vegetation \n20 . Precipitation \n21 . TWI \n22 . SPI \n23 . STI \n\n\nVariables Entered/Removed: \n\n- Slope_Angle added \n- Profile_Curvature added \n- Plan_Curvature added \n- Landuse_Vegetation added \n- Lithology_Plutonic added \n- Precipitation added \n- Lithology_Metamorphic added \n- Elevation added \n- Proximity_Road added \n- Aspect_SouthEast added \n- TWI added \n- Aspect_South added \n- Proximity_Stream added \n- Aspect_East added \n- Aspect_SouthWest added \n- Aspect_NorthEast added \n- Aspect_West added \n- Proximity_Settlement added \n\nNo more variables to be added or removed."
  },
  {
    "objectID": "explanatorymodelling.html#comparing-lr-model-1-2-3",
    "href": "explanatorymodelling.html#comparing-lr-model-1-2-3",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "5.9 Comparing LR Model 1 & 2 & 3",
    "text": "5.9 Comparing LR Model 1 & 2 & 3\nIn this section, we compare the three models - LR Model 1, 2, and 3. This comparison helps us understand the trade-offs between the models and decide which one to use for further analysis and calibration to GWLR.\n\n\n\nComparing LR Model 1, 2 and 3\n\n\nInformation\nModel_1\nModel_2\nModel_3\n\n\n\n\nSample Size\n50563.0000\n50563.0000\n9899.0000\n\n\nNon-Landslide\n8783.0000\n8783.0000\n4630.0000\n\n\nLandslide\n41780.0000\n41780.0000\n2304.0000\n\n\nExplanatory Variable\n24.0000\n17.0000\n24.0000\n\n\nAccuracy\n0.9302\n0.9287\n0.8151\n\n\nAIC\n22979.4204\n23213.7938\n11636.1941\n\n\nSensitivity\n0.9691\n0.9700\n0.7679\n\n\nSpecificity\n0.7455\n0.7322\n0.8510\n\n\nPercentage Deviant\n50.8911\n50.3635\n50.3635\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nLR Model 3 has the best Akaike Information Criterion (AIC) value, indicating that it might be the most efficient model among the three. However, it comes at the expense of having the lowest accuracy and sensitivity rates so far. As such, the overall performance was compromised after conducting stratified sampling. This suggests that while stratified sampling helped to balance the dataset, it may have introduced some bias that affected the model’s predictive power. Further investigation and model tuning might be needed to improve the model’s performance."
  },
  {
    "objectID": "explanatorymodelling.html#data-preparation-for-gwlr-model",
    "href": "explanatorymodelling.html#data-preparation-for-gwlr-model",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "6.1 Data Preparation for GWLR Model",
    "text": "6.1 Data Preparation for GWLR Model\nIn this section, we’re preparing the data for fitting a Geographically Weighted Logistic Regression (GWLR) model.\n\n6.1.1 Data Downsampling\nThe GWModel package has a limit on the number of observations it can handle. Therefore, we downsample our data to include only 20% of the initial data. We then split the data into training and testing sets. The initial_split function is used to ensure that the proportion of landslide data in both the training and testing sets is the same.\n\nls_data_sf &lt;- st_as_sf(data_20, coords = c(\"X\", \"Y\"))\nls_data_sf &lt;- st_set_crs(ls_data_sf, 32632) \nset.seed(1243)\n\nls_split &lt;- ls_data_sf %&gt;%\n  initial_split(prop = .2, \n                strata = Landslide)\n\ntraining_data_sf &lt;- training(ls_split)\ntesting_data_sf  &lt;- testing(ls_split)\n\ntraining_data_sp &lt;- as_Spatial(training_data_sf)\n\n\n\n6.1.2 Calculating Distance Matrix\nNext, we calculate a distance matrix. This matrix contains the distances between all pairs of data points and is required for fitting the GWLR model.\n\ndistMAT &lt;- gw.dist(dp.locat=\n                     coordinates(training_data_sp))\n\n\n\n6.1.3 Computing Adaptive Bandwidth\nWe then compute the adaptive bandwidth for our GWLR model. The bandwidth is a crucial parameter in GWLR models as it determines the extent of the geographical area that influences the prediction at each location. Bandwidth can be either fixed or adaptive. data as we see in the figure. In adaptive weighting scheme, the weight kernels have larger bandwidths where the data are sparse and have smaller bandwidths where the data are plentiful.​\n\n\n\n\n\nWith fixed method, there is greater likelihood that some local calibrations will be based on only a few data points and so the resulting distribution of local esitmates will exhibit greater variation. We can reduce such estimation bias with adaptive approach.\n\nbw.adaptive &lt;- bw.ggwr(formula = \n                       Landslide ~ Slope_Angle, \n                       family = \"binomial\", \n                       data = training_data_sp, \n                       approach=\"CV\", \n                       kernel=\"gaussian\", \n                       adaptive= TRUE, \n                       longlat=FALSE, \n                       p=2,\n                       theta=0,\n                       dMat=distMAT)\n\n\n\n\n\n\n\nNote\n\n\n\nThe computation of the adaptive bandwidth is a computationally intensive step. The resulting adaptive bandwidth value is 76. This means that the model considers the 76 closest data points when making a prediction at each location. This value was chosen to balance the trade-off between model accuracy and computational efficiency."
  },
  {
    "objectID": "explanatorymodelling.html#fitting-gwlr-model",
    "href": "explanatorymodelling.html#fitting-gwlr-model",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "6.2 Fitting GWLR Model",
    "text": "6.2 Fitting GWLR Model\nIn this section, we fit a Geographically Weighted Logistic Regression (GWLR) model. The bw parameter is set to 76, which is the adaptive bandwidth value we computed earlier. The family parameter is set to “binomial” due to the binary nature of the Landslide variable. The kernel parameter is set to “gaussian”, which means that the weights decrease smoothly from the center of the kernel. The adaptive parameter is set to TRUE, which means that the bandwidth adapts to the density of the data points.\n\ngwlr &lt;- ggwr.basic(Landslide ~ Aspect_North + \n                     Aspect_SouthEast + Profile_Curvature + \n                     Plan_Curvature + Slope_Angle + \n                     Lithology_Sedimentary + Lithology_Plutonic +\n                     Lithology_Unconsolidated + Proximity_Stream +\n                     Landuse_Vegetation + Precipitation, \n                   data = training_data_sp, \n                   bw = 76, \n                   family = \"binomial\", \n                   kernel = \"gaussian\", \n                   adaptive = TRUE, \n                   cv = T, \n                   tol = 1e-05, \n                   maxiter = 20, \n                   p = 2, \n                   theta = 0, \n                   longlat = FALSE, \n                   dMat = distMAT)\n\n\ngwlr\n\n   ***********************************************************************\n   *                       Package   GWmodel                             *\n   ***********************************************************************\n   Program starts at: 2024-03-07 14:20:08.332201 \n   Call:\n   ggwr.basic(formula = Landslide ~ Slope_Angle + Profile_Curvature + \n    Plan_Curvature + Landuse_Vegetation + Lithology_Plutonic + \n    Proximity_Road + Lithology_Metamorphic + Precipitation, data = training_data_sp, \n    bw = 76, family = \"binomial\", kernel = \"gaussian\", adaptive = TRUE, \n    cv = T, tol = 1e-05, maxiter = 20, p = 2, theta = 0, longlat = FALSE, \n    dMat = distMAT)\n\n   Dependent (y) variable:  Landslide\n   Independent variables:  Slope_Angle Profile_Curvature Plan_Curvature Landuse_Vegetation Lithology_Plutonic Proximity_Road Lithology_Metamorphic Precipitation\n   Number of data points: 2803\n   Used family: binomial\n   ***********************************************************************\n   *              Results of Generalized linear Regression               *\n   ***********************************************************************\n\nCall:\nNULL\n\nCoefficients:\n                        Estimate Std. Error z value Pr(&gt;|z|)    \nIntercept             -3.276e+00  2.179e-01 -15.034  &lt; 2e-16 ***\nSlope_Angle            2.455e-01  1.010e-02  24.302  &lt; 2e-16 ***\nProfile_Curvature     -8.797e+02  5.740e+01 -15.326  &lt; 2e-16 ***\nPlan_Curvature        -7.330e+02  6.481e+01 -11.309  &lt; 2e-16 ***\nLanduse_Vegetation     7.871e-01  1.124e-01   7.003 2.50e-12 ***\nLithology_Plutonic    -1.338e+00  3.133e-01  -4.272 1.94e-05 ***\nProximity_Road        -7.744e-03  2.642e-03  -2.931  0.00338 ** \nLithology_Metamorphic -3.410e-01  1.176e-01  -2.899  0.00375 ** \nPrecipitation         -2.530e+00  1.154e+00  -2.193  0.02830 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 3832.7  on 2802  degrees of freedom\nResidual deviance: 2291.0  on 2794  degrees of freedom\nAIC: 2309\n\nNumber of Fisher Scoring iterations: 5\n\n\n AICc:  2309.047\n Pseudo R-square value:  0.402259\n   ***********************************************************************\n   *          Results of Geographically Weighted Regression              *\n   ***********************************************************************\n\n   *********************Model calibration information*********************\n   Kernel function: gaussian \n   Adaptive bandwidth: 76 (number of nearest neighbours)\n   Regression points: the same locations as observations are used.\n   Distance metric: A distance matrix is specified for this model calibration.\n\n   ************Summary of Generalized GWR coefficient estimates:**********\n                                Min.     1st Qu.      Median     3rd Qu.\n   Intercept             -1.5369e+01 -5.6897e+00 -3.7829e+00 -2.2473e+00\n   Slope_Angle            9.6495e-02  2.0940e-01  2.5654e-01  3.0969e-01\n   Profile_Curvature     -1.3256e+03 -1.0209e+03 -8.8282e+02 -7.6573e+02\n   Plan_Curvature        -1.8414e+03 -1.0073e+03 -6.6435e+02 -4.4395e+02\n   Landuse_Vegetation    -2.2363e-01  5.5102e-01  8.0376e-01  1.0731e+00\n   Lithology_Plutonic    -1.0819e+01 -3.0798e+00 -1.5746e+00 -4.7993e-01\n   Proximity_Road        -5.4247e-02 -2.6211e-02 -1.3533e-02  1.5699e-03\n   Lithology_Metamorphic -1.7751e+00 -5.7195e-01 -2.7482e-01  1.8384e-01\n   Precipitation         -2.9477e+01 -5.8893e+00  2.9382e+00  1.2095e+01\n                              Max.\n   Intercept                1.0897\n   Slope_Angle              0.4220\n   Profile_Curvature     -316.9567\n   Plan_Curvature         329.3031\n   Landuse_Vegetation       3.7799\n   Lithology_Plutonic       1.8951\n   Proximity_Road           0.0324\n   Lithology_Metamorphic    2.1692\n   Precipitation           46.7696\n   ************************Diagnostic information*************************\n   Number of data points: 2803 \n   GW Deviance: 1793.14 \n   AIC : 2103.232 \n   AICc : 2121.513 \n   Pseudo R-square value:  0.5321514 \n\n   ***********************************************************************\n   Program stops at: 2024-03-07 14:46:38.405684 \n\n\n\n\n\n\n\n\nObservation\n\n\n\nUpon performing global LR Model and GWLR Model, it was observed that the GWLR model produced a significantly better adjusted R-squared value. This indicates that the GWLR model explains the variability of the response data around its mean better than the generalized LR model.\nAt the same time, there was an observable improvement in the AIC when using the GWLR model. A lower AIC suggests a better model fit, so this is a positive outcome.\nIn global LR model, only singular estimate coefficients were generated for each explanatory variable. This means that each predictor has a fixed effect that does not vary across different geographical locations.\nOn the other hand, the local GWLR model generated a range of coefficient estimates for each explanatory variable, including the minimum, maximum, and median values. This suggests that the effect of the predictors in the GWLR model varies across different geographical locations, which can provide more nuanced insights into the data.\n\n\n\ngwlr_result &lt;- st_as_sf(gwlr$SDF) %&gt;% st_set_crs(32632)\ngwlr_result &lt;- subset(gwlr_result, select = c(yhat, geometry))"
  },
  {
    "objectID": "explanatorymodelling.html#creating-raster-layer",
    "href": "explanatorymodelling.html#creating-raster-layer",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.1 Creating Raster Layer",
    "text": "7.1 Creating Raster Layer\nThe terra::rast() function is used to create a raster layer from the valtellina object with 700 rows and 1066 columns.\n\ngrid &lt;- terra::rast(valtellina, \n                    nrows = 700, \n                    ncols = 1066)\ngrid\n\nclass       : SpatRaster \ndimensions  : 700, 1066, 1  (nrow, ncol, nlyr)\nresolution  : 99.94376, 99.91744  (x, y)\nextent      : 518970, 625510, 5095447, 5165389  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 32N (EPSG:32632)"
  },
  {
    "objectID": "explanatorymodelling.html#extracting-cell-coordinates",
    "href": "explanatorymodelling.html#extracting-cell-coordinates",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.2 Extracting Cell Coordinates",
    "text": "7.2 Extracting Cell Coordinates\nThe terra::xyFromCell() function is used to extract the x and y coordinates of each cell in the raster layer.\n\nxy &lt;- terra::xyFromCell(grid, \n                        1:ncell(grid))\nhead(xy)\n\n            x       y\n[1,] 519019.9 5165339\n[2,] 519119.9 5165339\n[3,] 519219.8 5165339\n[4,] 519319.8 5165339\n[5,] 519419.7 5165339\n[6,] 519519.7 5165339"
  },
  {
    "objectID": "explanatorymodelling.html#creating-spatal-data-frame",
    "href": "explanatorymodelling.html#creating-spatal-data-frame",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.3 Creating Spatal Data Frame",
    "text": "7.3 Creating Spatal Data Frame\nThe st_as_sf() function from the sf package is used to convert the data frame of coordinates into a spatial data frame. The st_filter() function is then used to keep only the points that fall within the valtellina region.\n\ncoop &lt;- st_as_sf(as.data.frame(xy), \n                 coords = c(\"x\", \"y\"),\n                 crs = st_crs(valtellina))\ncoop &lt;- st_filter(coop, valtellina)\nhead(coop)\n\nSimple feature collection with 6 features and 0 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 594477.5 ymin: 5165139 xmax: 594877.2 ymax: 5165339\nProjected CRS: WGS 84 / UTM zone 32N\n                  geometry\n1 POINT (594777.3 5165339)\n2 POINT (594877.2 5165339)\n3 POINT (594677.4 5165239)\n4 POINT (594777.3 5165239)\n5 POINT (594877.2 5165239)\n6 POINT (594477.5 5165139)"
  },
  {
    "objectID": "explanatorymodelling.html#variogram",
    "href": "explanatorymodelling.html#variogram",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.4 Variogram",
    "text": "7.4 Variogram\nA variogram is a tool used in geostatistics to quantify the spatial autocorrelation of a variable. It provides a visual depiction of the covariance exhibited between each pair of points in the sampled data. For each pair of points in the sampled data, the “semivariance” is plotted against the distance between the pairs.\nThe variogram function from the gstat package in R is used to calculate the empirical variogram of the data. The fit.variogram function is then used to fit a theoretical variogram model to this empirical variogram. The vgm function is used to specify the theoretical variogram model to fit.\nThe psill parameter is the maximum semivariance value, also known as the sill. The model parameter specifies the type of variogram model to use, in this case, a spherical model. The range parameter is the distance at which the semivariance reaches the specified sill. The nugget parameter represents the variance at zero distance, accounting for measurement errors or spatial sources of variation at distances smaller than the sampling interval.\nSpherical variogram models are commonly used in geostatistical applications as they often have a similar shape to empirical variograms.\nHere is the code chunk that accomplishes this:\n\nv &lt;- variogram(yhat ~ 1, \n               data = gwlr_result)\nplot(v)\n\n\n\n\n\nfv &lt;- fit.variogram(object = v,\n                    model = vgm(\n                      psill = 0.5, \n                      model = \"Sph\",\n                      range = 5000, \n                      nugget = 0.1))\nfv\n\n  model      psill    range\n1   Nug 0.07203166    0.000\n2   Sph 0.05253883 8902.934\n\n\n\nplot(v, fv)"
  },
  {
    "objectID": "explanatorymodelling.html#creating-krige-object",
    "href": "explanatorymodelling.html#creating-krige-object",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.5 Creating Krige Object",
    "text": "7.5 Creating Krige Object\nIn this code chunk, we create a gstat object named k using the gstat function. This object represents a geostatistical model that we’ll use for Kriging. The formula Predicted ~ 1 specifies that we’re modeling the Predicted variable as a function of a constant (i.e., we’re fitting a mean model). The data argument is set to testing_data_sf. The model argument is set to fv.\n\nk &lt;- gstat(formula = yhat ~ 1, \n           data = gwlr_result, \n           model = fv)\nk"
  },
  {
    "objectID": "explanatorymodelling.html#prediction-with-krige-object",
    "href": "explanatorymodelling.html#prediction-with-krige-object",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.6 Prediction with Krige Object",
    "text": "7.6 Prediction with Krige Object\nIn this code chunk, we use the predict function to make predictions from the Kriging model k for the locations specified in coop. The predictions are stored in resp. We then extract the x and y coordinates and the predicted values from resp.\n\nresp &lt;- predict(k, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\nresp$pred &lt;- resp$pred\nresp"
  },
  {
    "objectID": "explanatorymodelling.html#rasterizing-predictions",
    "href": "explanatorymodelling.html#rasterizing-predictions",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.7 Rasterizing Predictions",
    "text": "7.7 Rasterizing Predictions\nIn this code chunk, we rasterize the predictions resp onto the raster grid grid using the terra::rasterize function. The rasterized predictions are stored in kpred.\n\nkpred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\")"
  },
  {
    "objectID": "explanatorymodelling.html#creating-spatial-interpolated-map",
    "href": "explanatorymodelling.html#creating-spatial-interpolated-map",
    "title": "Explanatory Landslide Susceptibility Modelling",
    "section": "7.8 Creating Spatial Interpolated Map",
    "text": "7.8 Creating Spatial Interpolated Map\nNow that we have the data ready, we use appropriate tmap functions to create a map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(kpred) + \n  tm_raster(alpha = 1, \n            palette = \"-RdYlGn\",\n            title = \"Probability of Landslides\") +\n  tm_layout(main.title = \"Landslide Susceptibility Map (GWLR)\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "predictivemodelling.html",
    "href": "predictivemodelling.html",
    "title": "Machine Learning Modelling",
    "section": "",
    "text": "Landslide susceptibility modelling is emerging field of research that aims to identify the contributing factors of landslides and predict areas that are most susceptible. These studies serve as a valuable decision-support tool, helping us identify the areas at highest risk and implement preventive measures accordingly. In this research project, we aims to demonstrate the potential contribution of spatial non-stationarity in landslide susceptibility modelling. To do so, we will attempt to make a comparative case study of nonspatial and spatial random forest techniques and how space can be incorporate to these models. In particular, we will be developing three different RF models\n\n(Nonspatial) Random Forest (ranger package)\nMoran’s Eigenvector Random Forest (spatialRF package)\nGeographically Weighted Random Forest (SpatialML package)"
  },
  {
    "objectID": "predictivemodelling.html#test-train-split",
    "href": "predictivemodelling.html#test-train-split",
    "title": "Machine Learning Modelling",
    "section": "3.1 Test-Train Split",
    "text": "3.1 Test-Train Split\nIn this section, we are preparing our data for the subsequent analysis. The ls_data dataset, which contains our landslide data, is divided into two subsets: a training set and a testing set.\nThe code chunk below performs this operation. This process is crucial because it allows us to train our model on one subset of the data (the training set) and then evaluate its performance on unseen data (the testing set). This helps to ensure that our model is not just memorizing the training data and is actually able to generalize to new data. The set.seed(1243) function ensures that the random split of data is reproducible. The initial_split function from the rsample package is used to perform the split, with 20% of the data allocated to the testing set (prop = .2). The split is stratified by the Landslide variable, meaning the proportion of each class of Landslide is the same in the training and testing sets.\n\nset.seed(1243)\nls_split &lt;- ls_data %&gt;%\n  initial_split(prop = .2, \n                strata = Landslide)\n\ntraining_data &lt;- training(ls_split)\ntesting_data  &lt;- testing(ls_split)"
  },
  {
    "objectID": "predictivemodelling.html#preparing-the-testing-data",
    "href": "predictivemodelling.html#preparing-the-testing-data",
    "title": "Machine Learning Modelling",
    "section": "3.2 Preparing the Testing Data",
    "text": "3.2 Preparing the Testing Data\nIn this section, we are further refining our testing data for the analysis. We will be performing two main operations:\n\nSaving the target variable: We save the Landslide values from testing_data as a separate column. This is done because Landslide is our target variable, and we want to compare our model’s predictions with the actual values to evaluate its performance.\nRemoving unnecessary variables: We remove the Train_ID, Grid_ID, and Landslide variables from the testing_data as they are not needed for the analysis. These variables are identifiers and the target variable, which are not used as input features in our model.\n\nThe code chunk below performs these operations:\n\ntest_col &lt;- as.factor(testing_data$Landslide)\ntesting_data &lt;- testing_data_temp &lt;- subset(testing_data, select = -c(Train_ID,Grid_ID,Landslide))"
  },
  {
    "objectID": "predictivemodelling.html#storing-variable-names",
    "href": "predictivemodelling.html#storing-variable-names",
    "title": "Machine Learning Modelling",
    "section": "3.3 Storing Variable Names",
    "text": "3.3 Storing Variable Names\nIn this section, we are streamlining our code by storing the names of our variables in vectors. y storing the variable names in vectors, we can easily reference them later in our code. This approach will make our code cleaner and more efficient, as we won’t have to repeatedly write out all the variable names. Also, it reduces the chance of errors that could arise from mistyping variable names.\nThe code chunk below performs these operations:\n\nWe first store the name of the dependent variable in a vector called dependent.variable.name.\nWe then use the colnames function to get the names of columns 6 to 29 from the ls_data dataset. These are the names of the independent variable used in this study, We store them in a vector called predictor.variable.names.\nWe etract the ‘X’ and ‘Y’ columns from the training data and store them in a new data frame called xy.\n\n\ndependent.variable.name &lt;- \"Landslide\"\npredictor.variable.names &lt;- colnames(ls_data)[6:29]\nxy &lt;- training_data[, c(\"X\", \"Y\")]\ncolnames(xy) &lt;- c(\"x\", \"y\")\nrandom.seed &lt;- 1"
  },
  {
    "objectID": "predictivemodelling.html#transforming-data-to-simple-feature-objects",
    "href": "predictivemodelling.html#transforming-data-to-simple-feature-objects",
    "title": "Machine Learning Modelling",
    "section": "3.4 Transforming Data to Simple Feature Objects",
    "text": "3.4 Transforming Data to Simple Feature Objects\nIn this section, we are transforming our training_data and testing_data data frames into simple feature (sf) objects. This is a crucial step for spatial analysis, as sf objects allow us to perform various spatial operations.\nThe code chunk below performs these transformations:\n\ntraining_data_sf &lt;- st_as_sf(training_data, coords = c(\"X\", \"Y\"))\ntesting_data_sf &lt;- st_as_sf(testing_data, coords = c(\"X\", \"Y\"))\n\nTo ensure that our spatial data is in the correct projected system, we will set the CRS of training_data_sf and testing_data_sf to WGS 84 / UTM zone 32N (EPSG code 32632). This is crucial for accurate spatial analysis, as different CRSs can lead to different results. By setting appropriate CRS, we ensure that our spatial data is in a projected system suitable for accurate distance and area calculations.\nThe code chunk below sets the CRS for our training_data_sf and testing_data_sf:\n\ntraining_data_sf &lt;- st_set_crs(training_data_sf, 32632) \ntesting_data_sf &lt;- st_set_crs(testing_data_sf, 32632) \nst_crs(training_data_sf)\n\nCoordinate Reference System:\n  User input: EPSG:32632 \n  wkt:\nPROJCRS[\"WGS 84 / UTM zone 32N\",\n    BASEGEOGCRS[\"WGS 84\",\n        ENSEMBLE[\"World Geodetic System 1984 ensemble\",\n            MEMBER[\"World Geodetic System 1984 (Transit)\"],\n            MEMBER[\"World Geodetic System 1984 (G730)\"],\n            MEMBER[\"World Geodetic System 1984 (G873)\"],\n            MEMBER[\"World Geodetic System 1984 (G1150)\"],\n            MEMBER[\"World Geodetic System 1984 (G1674)\"],\n            MEMBER[\"World Geodetic System 1984 (G1762)\"],\n            MEMBER[\"World Geodetic System 1984 (G2139)\"],\n            ELLIPSOID[\"WGS 84\",6378137,298.257223563,\n                LENGTHUNIT[\"metre\",1]],\n            ENSEMBLEACCURACY[2.0]],\n        PRIMEM[\"Greenwich\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433]],\n        ID[\"EPSG\",4326]],\n    CONVERSION[\"UTM zone 32N\",\n        METHOD[\"Transverse Mercator\",\n            ID[\"EPSG\",9807]],\n        PARAMETER[\"Latitude of natural origin\",0,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8801]],\n        PARAMETER[\"Longitude of natural origin\",9,\n            ANGLEUNIT[\"degree\",0.0174532925199433],\n            ID[\"EPSG\",8802]],\n        PARAMETER[\"Scale factor at natural origin\",0.9996,\n            SCALEUNIT[\"unity\",1],\n            ID[\"EPSG\",8805]],\n        PARAMETER[\"False easting\",500000,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8806]],\n        PARAMETER[\"False northing\",0,\n            LENGTHUNIT[\"metre\",1],\n            ID[\"EPSG\",8807]]],\n    CS[Cartesian,2],\n        AXIS[\"(E)\",east,\n            ORDER[1],\n            LENGTHUNIT[\"metre\",1]],\n        AXIS[\"(N)\",north,\n            ORDER[2],\n            LENGTHUNIT[\"metre\",1]],\n    USAGE[\n        SCOPE[\"Engineering survey, topographic mapping.\"],\n        AREA[\"Between 6°E and 12°E, northern hemisphere between equator and 84°N, onshore and offshore. Algeria. Austria. Cameroon. Denmark. Equatorial Guinea. France. Gabon. Germany. Italy. Libya. Liechtenstein. Monaco. Netherlands. Niger. Nigeria. Norway. Sao Tome and Principe. Svalbard. Sweden. Switzerland. Tunisia. Vatican City State.\"],\n        BBOX[0,6,84,12]],\n    ID[\"EPSG\",32632]]"
  },
  {
    "objectID": "predictivemodelling.html#distance-matrix-transformation-and-threshold-setting",
    "href": "predictivemodelling.html#distance-matrix-transformation-and-threshold-setting",
    "title": "Machine Learning Modelling",
    "section": "3.5 Distance Matrix Transformation and Threshold Setting",
    "text": "3.5 Distance Matrix Transformation and Threshold Setting\nIn this section, we are performing transformations on the distance matrix and setting distance thresholds based on quantile values. These steps are crucial for further spatial analysis.\n\nWe use gw.dist function from the spgwr package to compute a geographically weighted distance matrix for the training data,\nWe convert the distance matrix from metres to kilometres for easier interpretation.\nWe then calculate the quantiles of the distance matrix.\n\nThe code chunk below performs these operations:\n\ntraining_data_sp &lt;- as_Spatial(training_data_sf)\ndistance.matrix &lt;- gw.dist(dp.locat=\n                     coordinates(training_data_sp))\ndistance.matrix &lt;- distance.matrix / 1000\nquantile(distance.matrix)\n\n       0%       25%       50%       75%      100% \n  0.00000  21.66893  36.99885  55.92637 106.64538 \n\n\nAfter examining the quantile values, we set the distance thresholds as follows:\n\ndistance.thresholds &lt;- c(0, 20, 35, 55, 110)"
  },
  {
    "objectID": "predictivemodelling.html#checking-the-balance-of-classes",
    "href": "predictivemodelling.html#checking-the-balance-of-classes",
    "title": "Machine Learning Modelling",
    "section": "3.6 Checking the Balance of Classes",
    "text": "3.6 Checking the Balance of Classes\nIn this section, we are verifying whether our training and testing datasets have a representative ratio of landslide (class 1) and non-landslide (class 0) data. This is an important step to ensure that our model is trained and tested on balanced data.\nThe code chunk below performs these checks:\n\nsum(training_data$Landslide == 1)\n\n[1] 1209\n\nsum(training_data$Landslide == 0)\n\n[1] 1594\n\nsum(testing_data$Landslide == 1)\n\n[1] 0\n\nsum(testing_data$Landslide == 0)\n\n[1] 0\n\n\nBased on these calculations, our training_data has 1209 landslide and 1594 non-landslide samples. Our testing_data has 4839 landslide and 6378 non-landslide samples. This indicates that our data has a representative ratio of landslide to non-landslide samples, which is crucial for training a balanced and unbiased model."
  },
  {
    "objectID": "predictivemodelling.html#variable-spatial-autocorrelation-analysis",
    "href": "predictivemodelling.html#variable-spatial-autocorrelation-analysis",
    "title": "Machine Learning Modelling",
    "section": "4.1 Variable Spatial Autocorrelation Analysis",
    "text": "4.1 Variable Spatial Autocorrelation Analysis\nSpatial predictor variables often exhibit spatial autocorrelation, where nearby observations are not independent but rather exhibit similar values. This leads to spatial nonstationarity, a phenomenon where the relationships between variables change over space, violating the assumption of a global model.\nTo address this issue, we use Moran’s I, a common measure of spatial autocorrelation widely adopted by the geospatial data science community. Moran’s I quantifies the similarity between values and neighbouring observations, considering spatial relationships between neighbours. It describes how each observation differs from the mean of the study area.\nOur aim is to assess the spatial autocorrelation level of predictor variables at different spatial scales. The function plot_training_df_moran() helps in assessing the spatial autocorrelation of the response variable and the predictors across different distance thresholds. This function generates a plot that visualizes the spatial autocorrelation of the response variable and the predictors across different distance thresholds. The fill.color and point.color arguments are used to customize the colors of the plot.\nThe code chunk below performs this operation:\n\nspatialRF::plot_training_df_moran(\n  data = training_data,\n  dependent.variable.name = dependent.variable.name,\n  predictor.variable.names = predictor.variable.names,\n  distance.matrix = distance_matrix,\n  distance.thresholds = distance.thresholds,\n  fill.color = viridis::viridis(\n    100,\n    option = \"A\",\n    direction = -1\n    ),\n  point.color = \"gray40\"\n)"
  },
  {
    "objectID": "predictivemodelling.html#fitting-a-non-spatial-random-forest-model",
    "href": "predictivemodelling.html#fitting-a-non-spatial-random-forest-model",
    "title": "Machine Learning Modelling",
    "section": "5.1 Fitting a non-spatial Random Forest model",
    "text": "5.1 Fitting a non-spatial Random Forest model\nThe rf() function from the spatialRF package is a convenient wrapper for the ranger::ranger() function, which is used in every modelling function of the spatialRF package. This function takes the training data, the names of the response variable and the predictor variables, and optionally, to assess the spatial autocorrelation of the residuals, the distance matrix, and a vector of distance thresholds (in the same units as the distances in distance_matrix).\nThe code chunk below fits a non-spatial random forest model using the rf() function:\nBy default, RF model from ranger use the following parameters.\n\nNumber of Trees (ntree) : 500 \nNumber of Features at Each Split (mtry) : 4 \nMinimum Node Size (min.node.size) : 5\n\n\nnon.spatial.rf &lt;- spatialRF::rf(\n  data = training_data,\n  dependent.variable.name = dependent.variable.name,\n  predictor.variable.names = predictor.variable.names,\n  distance.matrix = distance.matrix,\n  distance.thresholds = distance.thresholds,\n  xy = xy,\n  seed = random.seed,\n  verbose = FALSE\n)"
  },
  {
    "objectID": "predictivemodelling.html#residual-spatial-autocorrelation-analysis",
    "href": "predictivemodelling.html#residual-spatial-autocorrelation-analysis",
    "title": "Machine Learning Modelling",
    "section": "5.2 Residual Spatial Autocorrelation Analysis",
    "text": "5.2 Residual Spatial Autocorrelation Analysis\nThe residuals slot of our non-spatial random forest model (non.spatial.rf$residuals) stores the values of the residuals and the results of the normality and spatial autocorrelation tests. We can visualize this information using the plot_residuals_diagnostics() function from the spatialRF package. The xy, distance.matrix, and distance.thresholds arguments included in the model fitting are used to assess the spatial autocorrelation of the residuals.\nThe code chunk below generates a diagnostic plot of the residuals:\n\nspatialRF::plot_residuals_diagnostics(\n  non.spatial.rf,\n  verbose = FALSE\n  )\n\n\n\n\nThe plot above provides valuable insights into the behavior of the residuals:\n\nThe upper panels show the results of the normality test. The interpretation of the test is provided in the title of the plot.\nThe middle panel shows the relationship between the residuals and the fitted values. This is important for understanding the behavior of the residuals.\nThe lower panel shows Moran’s I of the residuals across distance thresholds and their respective p-values. Positive values indicate positive spatial autocorrelation at the corresponding distances (0, 20, 35 and 55 km in this case).\n\nBy examining these plots, we can gain a deeper understanding of our model’s performance and the spatial structure of the residuals."
  },
  {
    "objectID": "predictivemodelling.html#global-variable-importance",
    "href": "predictivemodelling.html#global-variable-importance",
    "title": "Machine Learning Modelling",
    "section": "5.3 Global Variable Importance",
    "text": "5.3 Global Variable Importance\nThe importance slot of our non-spatial random forest model (non.spatial.rf$variable.importance) contains the variable importance scores. These scores provide a measure of the contribution of each predictor variable to the predictive power of the model.\nWe can visualize these importance scores using the plot_importance() function from the spatialRF package, print them with the print_importance() function, or retrieve the data frame of importance scores with the get_importance() function.\nThe code chunk below generates a plot of the variable importance scores:\n\nspatialRF::plot_importance(\n  non.spatial.rf,\n  verbose = FALSE\n  )\n\n\n\n\nThe plot above provides a visual representation of the importance of each predictor variable in the model. The variables are ordered by their importance scores, with the most important variable at the top."
  },
  {
    "objectID": "predictivemodelling.html#understanding-variable-importance-scores",
    "href": "predictivemodelling.html#understanding-variable-importance-scores",
    "title": "Machine Learning Modelling",
    "section": "5.4 Understanding Variable Importance Scores",
    "text": "5.4 Understanding Variable Importance Scores\nThe randomForestExplainer package offers several options to deepen our understanding of variable importance scores. One such option is the measure_importance() function, which analyzes the forest to find out:\n\nThe average minimum tree depth at which each variable can be found (mean_min_depth).\nThe number of nodes in which a variable was selected to make a split (no_of_nodes).\nThe number of times the variable was selected as the first one to start a tree (times_a_root).\nThe probability of a variable to be in more nodes than what would be expected by chance (p_value).\n\nThe code chunk below performs this operation:\n\nimportance.df &lt;- randomForestExplainer::measure_importance(\n  non.spatial.rf,\n  measures = c(\"mean_min_depth\", \"no_of_nodes\", \"times_a_root\", \"p_value\")\n  )\n\nThe resulting data frame, importance.df, contains the variable importance scores for each measure. This data frame can be printed in a tidy format using the kableExtra::kbl() function:\n\nkableExtra::kbl(\n  importance.df %&gt;% \n    dplyr::arrange(mean_min_depth) %&gt;% \n    dplyr::mutate(p_value = round(p_value, 4)),\n  format = \"html\"\n) %&gt;%\n  kableExtra::kable_paper(\"hover\", full_width = T)\n\n\n\n\nvariable\nmean_min_depth\nno_of_nodes\ntimes_a_root\np_value\n\n\n\n\nSlope_Angle\n1.838000\n13675\n82\n0\n\n\nProfile_Curvature\n2.080000\n12161\n70\n0\n\n\nPlan_Curvature\n2.218000\n11717\n56\n0\n\n\nElevation\n2.406000\n11854\n59\n0\n\n\nTWI\n2.514000\n11436\n39\n0\n\n\nPrecipitation\n2.888000\n10709\n28\n0\n\n\nProximity_Stream\n3.166000\n9586\n14\n0\n\n\nProximity_Fault\n3.368000\n10908\n10\n0\n\n\nProximity_Settlement\n3.418000\n10140\n17\n0\n\n\nProximity_Road\n3.506000\n10242\n6\n0\n\n\nLanduse_Vegetation\n3.808000\n2106\n51\n1\n\n\nSPI\n3.982000\n9473\n2\n0\n\n\nSTI\n4.198000\n8035\n0\n0\n\n\nLithology_Sedimentary\n4.984324\n1685\n26\n1\n\n\nLithology_Plutonic\n5.424900\n1121\n20\n1\n\n\nLithology_Metamorphic\n6.020288\n1866\n8\n1\n\n\nLithology_Unconsolidated\n6.050288\n2045\n0\n1\n\n\nAspect_North\n6.636828\n1390\n8\n1\n\n\nAspect_SouthWest\n6.700396\n1682\n0\n1\n\n\nAspect_South\n6.816360\n1725\n4\n1\n\n\nAspect_SouthEast\n6.882432\n1762\n0\n1\n\n\nAspect_NorthEast\n7.090540\n1532\n0\n1\n\n\nAspect_West\n7.229044\n1550\n0\n1\n\n\nAspect_East\n7.296576\n1510\n0\n1\n\n\n\n\n\n\n\nThis table provides a detailed view of the variable importance scores, allowing us to better understand the contribution of each predictor variable to the model."
  },
  {
    "objectID": "predictivemodelling.html#assessing-predictor-contribution-to-model-transferability",
    "href": "predictivemodelling.html#assessing-predictor-contribution-to-model-transferability",
    "title": "Machine Learning Modelling",
    "section": "5.5 Assessing Predictor Contribution to Model Transferability",
    "text": "5.5 Assessing Predictor Contribution to Model Transferability\nThe rf_importance() function from the spatialRF package provides a way to assess the extent to which each predictor contributes to model transferability. Model transferability refers to the model’s predictive ability on independent spatial folds, which can be measured with the rf_evaluate() function (discussed later).\nThe rf_importance() function assesses predictor contribution by comparing the performance of the full model with models fitted without each predictor. The difference in performance between the full model and a model without a given predictor represents the contribution of that predictor to model transferability.\nThe code chunk below performs this operation:\n\nnon.spatial.rf &lt;- spatialRF::rf_importance(\n  model = non.spatial.rf\n  )"
  },
  {
    "objectID": "predictivemodelling.html#partial-dependence-plot-pdp",
    "href": "predictivemodelling.html#partial-dependence-plot-pdp",
    "title": "Machine Learning Modelling",
    "section": "5.6 Partial Dependence Plot (PDP)",
    "text": "5.6 Partial Dependence Plot (PDP)\nPartial dependence plots (PDPs) are a powerful tool in machine learning that allow us to visualize the relationship between predictor variables and the target outcome. Introduced by Friedman (2001), PDPs are used to interpret the output of complex machine learning models. They present the expected target outcomes as a function of the input variables and show the marginal effect one feature can have on the predicted outcome of the machine learning model.\nIn PDPs, the Y-axis value (ŷ) is defined by the average of all possible model predictions when the value of the objective predictor is at X. PDPs can reveal whether the relationship between the target and a feature is linear, monotonic, curvilinear, or of other complex types.\nThe code chunk below generates a partial dependence plot for our non-spatial random forest model:\n\nspatialRF::plot_response_curves(\n  non.spatial.rf,\n  quantiles = 0.5,\n  ncol = 3\n  )\n\n\n\n\nThe above plot presents the PDPs of the 12 variables exhibiting the highest variable importance. For these plots, all other predictor variables are held constant at their median values (i.e., the 0.5 qu"
  },
  {
    "objectID": "predictivemodelling.html#model-performance",
    "href": "predictivemodelling.html#model-performance",
    "title": "Machine Learning Modelling",
    "section": "5.7 Model Performance",
    "text": "5.7 Model Performance\nThe performance slot of our non-spatial random forest model (non.spatial.rf$performance) contains several performance measures. These can be printed using the print_performance() function from the spatialRF package.\n\nR squared (oob) and RMSE (oob): These are the R squared and root mean squared error (RMSE) of the model when predicting the out-of-bag data (the fraction of data not used to train individual trees). Among all the values available in the performance slot, these are probably the most honest ones, as they provide a performance estimate on independent data. However, out-of-bag data is not fully independent, and therefore these values will still be inflated, especially if the data is highly aggregated in space.\nR squared and pseudo R squared: These are computed from the observations and the predictions, and indicate to what extent model outcomes represent the input data. These values will usually be high if the data is highly aggregated in space.\nRMSE and its normalized version: These are computed via the root_mean_squared_error() function, and are linear with R squared and pseudo R squared.\n\nThe code chunk below prints these performance measures:\n\nspatialRF::print_performance(non.spatial.rf)\n\n\nModel performance \n  - R squared (oob):                  0.5446231\n  - R squared (cor(obs, pred)^2):     0.9355865\n  - Pseudo R squared (cor(obs, pred)):0.9672572\n  - RMSE (oob):                       0.3342698\n  - RMSE:                             0.1569\n  - Normalized RMSE:                  0.1569"
  },
  {
    "objectID": "predictivemodelling.html#predicting-onto-new-data",
    "href": "predictivemodelling.html#predicting-onto-new-data",
    "title": "Machine Learning Modelling",
    "section": "5.8 Predicting onto New Data",
    "text": "5.8 Predicting onto New Data\nWe can use our non-spatial random forest model to make predictions on the testing data. This is done using the stats::predict() function, which takes the model, the new data, and the type of prediction as arguments.\nThe code chunk below performs this prediction:\n\npredicted &lt;- stats::predict(\n  object = non.spatial.rf,\n  data = testing_data,\n  type = \"response\"\n  )$predictions\n\nAfter making the predictions, we can create a confusion matrix to evaluate the results. The confusion matrix provides a summary of the model’s performance by comparing the predicted values with the actual values.\nThe code chunk below creates a confusion matrix:\n\npredicted_col &lt;- ifelse(predicted &gt; 0.5, 1, 0)\npredicted_col &lt;- factor(predicted_col) \nconfusionMatrix(predicted_col, test_col)\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5616  940\n         1  762 3899\n                                          \n               Accuracy : 0.8483          \n                 95% CI : (0.8415, 0.8549)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6893          \n                                          \n Mcnemar's Test P-Value : 1.784e-05       \n                                          \n            Sensitivity : 0.8805          \n            Specificity : 0.8057          \n         Pos Pred Value : 0.8566          \n         Neg Pred Value : 0.8365          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5007          \n   Detection Prevalence : 0.5845          \n      Balanced Accuracy : 0.8431          \n                                          \n       'Positive' Class : 0"
  },
  {
    "objectID": "predictivemodelling.html#permutation-test",
    "href": "predictivemodelling.html#permutation-test",
    "title": "Machine Learning Modelling",
    "section": "5.9 Permutation Test",
    "text": "5.9 Permutation Test\nRandom Forest (RF) is a stochastic process, and to ensure that the results are not random, we can perform a permutation test. This involves repeating the RF process multiple times and comparing the results. In this case, we will repeat the process 10 times using the rf_repeat() function from the spatialRF package.\nThe code chunk below performs this permutation test:\n\nnon.spatial.rf.perm &lt;- rf_repeat(\n  model = non.spatial.rf, \n  repetitions = 10,\n  verbose = FALSE\n)\n\nplot_importance(non.spatial.rf.perm, verbose = FALSE)\n\n\n\n\nAfter performing the permutation test, we can plot the variable importance scores and the partial dependence plots (PDPs) of the permuted RF model. These plots provide insights into the stability of the variable importance scores and the PDPs across the repeated RF processes.\n\nplot_response_curves(\n  non.spatial.rf.perm, \n  quantiles = 0.5,\n  ncol = 3\n  )"
  },
  {
    "objectID": "predictivemodelling.html#fitting-merf-model",
    "href": "predictivemodelling.html#fitting-merf-model",
    "title": "Machine Learning Modelling",
    "section": "6.1 Fitting MERF Model",
    "text": "6.1 Fitting MERF Model\nWe use rf_spatial function to fit RF to MERF model by generating Moran’s eigenvectors and inclduing them into training dataset through sequential selection.\n\nspatial.rf &lt;- spatialRF::rf_spatial(\n  model = non.spatial.rf,\n  distance.matrix = distance.matrix,\n  distance.thresholds = distance.thresholds,\n  method = \"mem.moran.sequential\",\n  verbose = FALSE,\n  seed = random.seed,\n  n.cores = parallel::detectCores() - 2\n  )"
  },
  {
    "objectID": "predictivemodelling.html#residual-spatial-autocorrelation-analysis-1",
    "href": "predictivemodelling.html#residual-spatial-autocorrelation-analysis-1",
    "title": "Machine Learning Modelling",
    "section": "6.2 Residual Spatial Autocorrelation Analysis",
    "text": "6.2 Residual Spatial Autocorrelation Analysis\nJust like we did with the non-spatial RF model, we can also test the residual autocorrelation for both RF and MERF models and compare the results. This can be done using the plot_moran() function from the spatialRF package.\nThe code chunk below performs residual spatial autocorrelation analysis for both RF and MERF models:\n\nspatialRF::plot_moran(\n  non.spatial.rf, \n  verbose = FALSE\n  )\n\n\n\nspatialRF::plot_moran(\n  spatial.rf, \n  verbose = FALSE\n  )\n\n\n\n\nFrom the plots above, MERF has effectively eliminated the spatial autocorrelation of the model residuals for every spatial scale. The magnitude of spatial autocorrelation was reduced, as indicated by the decrease in Moran’s I values. The p-values of the Moran’s I estimates for each neighbourhood distance were higher than 0.05, indicating that they were statistically not significant."
  },
  {
    "objectID": "predictivemodelling.html#sequential-selection-of-spatial-predictors",
    "href": "predictivemodelling.html#sequential-selection-of-spatial-predictors",
    "title": "Machine Learning Modelling",
    "section": "6.3 Sequential Selection of Spatial Predictors",
    "text": "6.3 Sequential Selection of Spatial Predictors\nAs explained earlier, the rf_spatial function generates Moran’s eigenvectors and includes them into the training dataset through sequential selection. The selection procedure is performed by the select_spatial_predictors_sequential() function, which finds the smaller subset of spatial predictors that maximizes the model’s R squared and minimizes the Moran’s I of the residuals. The rf_spatial function already automates this process, so there’s no need to manually run it. However, we can use the plot_optimization() function to visualize the optimization process. In the plot below, dots linked by lines represent the selected spatial predictors.\n\np &lt;- spatialRF::plot_optimization(spatial.rf)"
  },
  {
    "objectID": "predictivemodelling.html#plotting-spatial-predictors",
    "href": "predictivemodelling.html#plotting-spatial-predictors",
    "title": "Machine Learning Modelling",
    "section": "6.4 Plotting Spatial Predictors",
    "text": "6.4 Plotting Spatial Predictors\nWe can also visualize the spatial predictors obtained from the Moran’s Eigenvector Random Forest (MERF) model. This can be done using the get_spatial_predictors() function from the spatialRF package, which retrieves the spatial predictors from the MERF model.\nThe code chunk below performs this operation and generates a plot of the spatial predictors using appropriate ggplot2 functions:\n\nspatial.predictors &lt;- spatialRF::get_spatial_predictors(spatial.rf)\npr &lt;- data.frame(spatial.predictors, training_data[, c(\"X\", \"Y\")])\n\np1 &lt;- ggplot2::ggplot() +\n  ggplot2::geom_sf(data = valtellina, fill = \"white\") +\n  ggplot2::geom_point(\n    data = pr,\n    ggplot2::aes(\n      x = X,\n      y = Y,\n      color = spatial_predictor_55_8\n    ),\n    size = 2.5\n  ) +\n  ggplot2::scale_color_viridis_c(option = \"F\") +\n  ggplot2::theme_bw() +\n  ggplot2::labs(color = \"Eigenvalue\") +\n  ggplot2::ggtitle(\"Variable: spatial_predictor_55_8\") + \n  ggplot2::theme(legend.position = \"bottom\",\n                 legend.key.width = unit(1, \"cm\"))+ \n  ggplot2::xlab(\"Longitude\") + \n  ggplot2::ylab(\"Latitude\")\n\np1"
  },
  {
    "objectID": "predictivemodelling.html#merf-variable-importance",
    "href": "predictivemodelling.html#merf-variable-importance",
    "title": "Machine Learning Modelling",
    "section": "6.5 MERF Variable Importance",
    "text": "6.5 MERF Variable Importance\nThe importance slot of our MERF model (spatial.rf$variable.importance) contains the variable importance scores. These scores provide a measure of the contribution of each predictor variable to the predictive power of the model.\nWe can visualize these importance scores using the plot_importance() function from the spatialRF package, print them with the print_importance() function, or retrieve the data frame of importance scores with the get_importance() function.\nThe code chunk below generates plots of the variable importance scores for both the RF and MERF models:\n\np1 &lt;- spatialRF::plot_importance(\n  non.spatial.rf, \n  verbose = FALSE) + \n  ggplot2::ggtitle(\"Non-spatial RF\") \n\np2 &lt;- spatialRF::plot_importance(\n  spatial.rf,\n  verbose = FALSE) + \n  ggplot2::ggtitle(\"Spatial RF\")\n\np1 | p2 \n\n\n\n\nIf we compare the variable importance plots of both models, we can see that the spatial model has an additional set of dots under the name “spatial_predictors”, and that the maximum importance of a few of these spatial predictors matches the importance of the most relevant non-spatial predictors.\nWe can also plot the 50 most important variables as below. This table provides a detailed view of the 50 most improtant variable importance and their scores, allowing us to better understand the contribution of each predictor variable to the model.\n\nkableExtra::kbl(\n  head(spatial.rf$importance$per.variable, n = 50),\n  format = \"html\"\n) %&gt;%\n  kableExtra::kable_paper(\"hover\", full_width = F)\n\n\n\n\nvariable\nimportance\n\n\n\n\nSlope_Angle\n0.224\n\n\nspatial_predictor_55_8\n0.139\n\n\nProfile_Curvature\n0.137\n\n\nspatial_predictor_0_124\n0.120\n\n\nspatial_predictor_55_12\n0.120\n\n\nspatial_predictor_35_14\n0.114\n\n\nElevation\n0.105\n\n\nspatial_predictor_0_9\n0.101\n\n\nPlan_Curvature\n0.100\n\n\nspatial_predictor_35_22\n0.098\n\n\nspatial_predictor_0_165\n0.095\n\n\nspatial_predictor_0_3\n0.091\n\n\nspatial_predictor_0_134\n0.090\n\n\nspatial_predictor_0_43\n0.089\n\n\nspatial_predictor_0_1\n0.088\n\n\nspatial_predictor_35_8\n0.086\n\n\nspatial_predictor_0_162\n0.082\n\n\nspatial_predictor_0_32\n0.081\n\n\nspatial_predictor_0_147\n0.080\n\n\nspatial_predictor_20_29\n0.078\n\n\nspatial_predictor_0_22\n0.077\n\n\nspatial_predictor_55_10\n0.070\n\n\nspatial_predictor_0_82\n0.070\n\n\nspatial_predictor_0_62\n0.070\n\n\nspatial_predictor_35_16\n0.069\n\n\nspatial_predictor_20_9\n0.069\n\n\nspatial_predictor_0_166\n0.069\n\n\nspatial_predictor_0_10\n0.069\n\n\nspatial_predictor_0_90\n0.068\n\n\nTWI\n0.068\n\n\nspatial_predictor_35_13\n0.067\n\n\nspatial_predictor_35_10\n0.067\n\n\nspatial_predictor_55_11\n0.066\n\n\nspatial_predictor_20_8\n0.066\n\n\nspatial_predictor_0_4\n0.066\n\n\nspatial_predictor_0_73\n0.066\n\n\nspatial_predictor_55_14\n0.066\n\n\nspatial_predictor_0_143\n0.065\n\n\nspatial_predictor_20_12\n0.065\n\n\nspatial_predictor_0_182\n0.064\n\n\nspatial_predictor_0_112\n0.062\n\n\nspatial_predictor_0_88\n0.061\n\n\nspatial_predictor_35_6\n0.061\n\n\nspatial_predictor_0_38\n0.060\n\n\nspatial_predictor_0_2\n0.060\n\n\nspatial_predictor_35_20\n0.060\n\n\nspatial_predictor_0_29\n0.060\n\n\nspatial_predictor_0_164\n0.059\n\n\nspatial_predictor_0_140\n0.058\n\n\nPrecipitation\n0.058"
  },
  {
    "objectID": "predictivemodelling.html#partial-dependence-plots-pdp-for-merf",
    "href": "predictivemodelling.html#partial-dependence-plots-pdp-for-merf",
    "title": "Machine Learning Modelling",
    "section": "6.6 Partial Dependence Plots (PDP) for MERF",
    "text": "6.6 Partial Dependence Plots (PDP) for MERF\nThe code chunk below generates a partial dependence plot for our MERF forest model:\n\nspatialRF::plot_response_curves(\n  spatial.rf,\n  quantiles = 0.5,\n  ncol = 3\n  )"
  },
  {
    "objectID": "predictivemodelling.html#model-performance-1",
    "href": "predictivemodelling.html#model-performance-1",
    "title": "Machine Learning Modelling",
    "section": "6.7 Model Performance",
    "text": "6.7 Model Performance\nThe performance slot of our MERF model (spatial.rf$performance) contains several performance measures. These can be printed using the print_performance() function from the spatialRF package. We can compare these performance measures with those of the non-spatial RF model to understand how the inclusion of spatial predictors has affected the model’s performance.\nThe code chunk below prints these performance measures:\n\nspatialRF::print_performance(spatial.rf)\n\n\nModel performance \n  - R squared (oob):                  0.7805373\n  - R squared (cor(obs, pred)^2):     0.9820365\n  - Pseudo R squared (cor(obs, pred)):0.9909776\n  - RMSE (oob):                       0.2320556\n  - RMSE:                             0.0958\n  - Normalized RMSE:                  0.0958\n\nspatialRF::print_performance(non.spatial.rf)\n\n\nModel performance \n  - R squared (oob):                  0.5446231\n  - R squared (cor(obs, pred)^2):     0.9355865\n  - Pseudo R squared (cor(obs, pred)):0.9672572\n  - RMSE (oob):                       0.3342698\n  - RMSE:                             0.1569\n  - Normalized RMSE:                  0.1569\n\n\nBased on our results, the performance of MERF model improved across all metrics compared to the basic RF model. This demonstrates the effectiveness of incorporating spatial variables into our model."
  },
  {
    "objectID": "predictivemodelling.html#spatial-folds-cross-validation",
    "href": "predictivemodelling.html#spatial-folds-cross-validation",
    "title": "Machine Learning Modelling",
    "section": "6.8 Spatial-Folds Cross-Validation",
    "text": "6.8 Spatial-Folds Cross-Validation\nTo further evaluate the performance of our models, we conducted spatial fold cross-validation for both the RF and MERF models. The function rf_evaluate() provides an honest performance estimate based on spatial cross-validation, overcoming the limitations of the performance scores explained above.\nIn this process, we divided the training dataset into 10 spatially independent training and testing folds. We then fitted the model using each training fold and made predictions with each testing fold. Subsequently, we calculated the Area Under the Curve (AUC) values across the folds.\nThe code chunk below carries out 10 spatial fold cross-validation on RF model:\n\nset.seed(1234)\nnon.spatial.rf &lt;- rf_evaluate(\n  non.spatial.rf,\n  repetitions = 10,\n  xy = xy,\n  metrics = c(\"auc\"),\n  verbose = FALSE\n)\n\nprint_evaluation(non.spatial.rf)\n\n\nSpatial evaluation \n  - Training fraction:             0.75\n  - Spatial folds:                 10\n\n Metric Median   MAD Minimum Maximum\n    auc  0.898 0.013   0.879   0.926\n\n\nWe can also visualize the training and testing data of each spatial fold. The maps below show two sets of training and testing folds.\n\npr &lt;- training_data[, c(\"X\", \"Y\")]\npr$group.2 &lt;- pr$group.1 &lt;- \"Training\"\npr[non.spatial.rf$evaluation$spatial.folds[[1]]$testing, \"group.1\"] &lt;- \"Testing\"\npr[non.spatial.rf$evaluation$spatial.folds[[10]]$testing, \"group.2\"] &lt;- \"Testing\"\n\np1 &lt;- ggplot2::ggplot() +\n  ggplot2::geom_sf(data = valtellina, fill = \"white\") +\n  ggplot2::geom_point(data = pr,\n          ggplot2::aes(\n            x = X,\n            y = Y,\n            color = group.1\n            ),\n          size = 2\n          ) +\n  ggplot2::scale_color_viridis_d(\n    direction = -1, \n    end = 0.5, \n    alpha = 0.8, \n    option = \"F\"\n    ) +\n  ggplot2::theme_bw() +\n  ggplot2::labs(color = \"Group\") +\n  ggplot2::ggtitle(\"Spatial fold 1\") + \n  ggplot2::theme(\n    plot.title = ggplot2::element_text(hjust = 0.5)\n  ) + \n  ggplot2::xlab(\"Longitude\") + \n  ggplot2::ylab(\"Latitude\")\n\np2 &lt;- ggplot2::ggplot() +\n  ggplot2::geom_sf(data = valtellina, fill = \"white\") +\n  ggplot2::geom_point(data = pr,\n          ggplot2::aes(\n            x = X,\n            y = Y,\n            color = group.2\n            ),\n          size = 2\n          ) +\n  ggplot2::scale_color_viridis_d(\n    direction = -1, \n    end = 0.5, \n    alpha = 0.8, \n    option = \"F\"\n    ) +\n  ggplot2::theme_bw() +\n  ggplot2::labs(color = \"Group\") +\n  ggplot2::theme(\n    plot.title = ggplot2::element_text(hjust = 0.5)\n  ) + \n  ggplot2::ggtitle(\"Spatial fold 10\") + \n  ggplot2::xlab(\"Longitude\") + \n  ggplot2::ylab(\"\")\n\np1\n\n\n\np2\n\n\n\n\nWe will do the same 10 spatial fold cross-validation for the MERF model as well:\n\nset.seed(1234)\n\n#| eval: false\nspatial.rf.eval &lt;- rf_evaluate(\n  spatial.rf,\n  repetitions = 10,\n  xy = xy,\n  metrics = \"auc\",\n  verbose = FALSE\n)\nprint_evaluation(spatial.rf.eval)\n\n\nSpatial evaluation \n  - Training fraction:             0.75\n  - Spatial folds:                 10\n\n Metric Median   MAD Minimum Maximum\n    auc  0.895 0.039   0.417   0.931"
  },
  {
    "objectID": "predictivemodelling.html#bandwidth-selection",
    "href": "predictivemodelling.html#bandwidth-selection",
    "title": "Machine Learning Modelling",
    "section": "7.1 Bandwidth Selection",
    "text": "7.1 Bandwidth Selection\nBefore we fit the GWRF model, have to select bandwidth, we need to select an optimal bandwidth. The grf.bw function from the gwrf package is used for this purpose.\nThe step parameter is used to define the increment in the bandwidth during the optimization process. The bw.min and bw.max parameters define the range within which the optimal bandwidth is searched.geo.weighted. The geo.weighted parameter is a boolean flag that determines the type of random forest algorithm to use. If geo.weighted is set to TRUE, the algorithm calculates a Geographically Weighted Random Forest using the case.weights option of the ranger package. This means that each observation in the local dataset is weighted based on its geographical location. If geo.weighted is set to FALSE, it will calculate local random forests without weighting each observation in the local dataset.\nBelow is the code chunk for calculating bandwidth selection\n\nset.seed(1234)\ngrf.bw.orig &lt;- grf.bw(Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n       data=training_data, \n       kernel=\"adaptive\", \n       coords=coords_train, \n       bw.min = 1,\n       bw.max = 306, \n       step = 1, \n       trees= 500, \n       importance=\"impurity\",\n       forests = FALSE, \n       geo.weighted = TRUE)\n\n\n\n\n\n\n\nLong Computation Time\n\n\n\nThe above step is computationally intensive due to the brute force approach used in searching for the optimal bandwidth. This means that the function will try all possible bandwidths within the specified range and select the one that results in the best model performance. This can take a significant amount of time, especially if the range of possible bandwidths is large. It’s important to be aware of this when running the code.\n\n\nThe code chunk above calculates the Out-of-Bag (OOB) \\(R^2\\) value for different bandwidths. A higher R2 value indicates a better fit of the model to the data. We have selected bandwidths of 59, 92, 154, 189, 260, and 306, as these values yielded the highest \\(R^2\\) values, indicating optimal model performance."
  },
  {
    "objectID": "predictivemodelling.html#fitting-gwrf-models-with-different-bandwidths",
    "href": "predictivemodelling.html#fitting-gwrf-models-with-different-bandwidths",
    "title": "Machine Learning Modelling",
    "section": "7.2 Fitting GWRF Models with Different Bandwidths",
    "text": "7.2 Fitting GWRF Models with Different Bandwidths\nIn this section, we use the selected bandwidths to run different GWLR models. By comparing the results of these models, we can determine which bandwidth provides the best balance between model complexity and performance.\n\n59-Bandwidth GWRF92-Bandwidth GWRF154-Bandwidth GWRF189-Bandwidth GWRF260-Bandwidth GWRF306-Bandwidth GWRF\n\n\n\nset.seed(1234)\ngwRF_adaptive_59 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=59,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_59, \"data/rds/gwRF_adaptive_59.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_92 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw= 92,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_92, \"data/rds/gwRF_adaptive_92.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_154 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=154,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_154, \"data/rds/gwRF_adaptive_154.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_189 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=189,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_189, \"data/rds/gwRF_adaptive_189.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_260 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=260,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_260, \"data/rds/gwRF_adaptive_260.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_306 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=306,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_306, \"data/rds/gwRF_adaptive_306.rds\")\n\n\n\n\n\nrm(gwRF_adaptive_59)\nrm(gwRF_adaptive_92)\nrm(gwRF_adaptive_154)\nrm(gwRF_adaptive_189)\nrm(gwRF_adaptive_260)\nrm(gwRF_adaptive_306)\nrm(ls_data)\nrm(ls_split)"
  },
  {
    "objectID": "predictivemodelling.html#prediction-with-various-spatial-weights",
    "href": "predictivemodelling.html#prediction-with-various-spatial-weights",
    "title": "Machine Learning Modelling",
    "section": "7.2 Prediction with Various Spatial Weights",
    "text": "7.2 Prediction with Various Spatial Weights\nIn previous section, we fitted a total of 6 GWRF models, each having different bandwidth. In this section, we will use these models to predict using different spatial weights.\nIn GWRF framework, prediction is carried out the fusion of global and local predictions using a weight parameter. This fusion of predictions enables the extraction of the locally heterogeneous signal (low bias) from the local sub-model and its integration with that of a global model which uses more data (low variance).\nThe weight parameter, denoted as α can be varied and user-specified. A purely global model is indicated by an α value of 0, which means it is devoid of any local model influence. Conversely, an α value of 1 denotes a purely local model, with no influence from the global model. For values between these thresholds, the weighting varies. For instance, an α value of 0.25 suggests a diminished weighting for the local model, thereby favouring the global one, while an α value of 0.75 implies a more favourable weighting for the local model over the global one. An α value of 0.50 signifies an equal weighting for both the local and global models.\nBelow is the code chunk for making predictions with various spatial weights.\n\nPreidctions are made using GWRF model with specific bandwidth and weight parameter.\nPredictions are then converted to binary values.\nConfusion matrix is computed using testing_data\nAccurarcy, precision, recall, and F1 scores are computed.\n\n\n59-Bandwidth GWRF92-Bandwidth GWRF154-Bandwidth GWRF189-Bandwidth GWRF260-Bandwidth GWRF306-Bandwidth GWRF\n\n\n\ngwRF_adaptive_59 &lt;- read_rds(\"data/rds/gwRF_adaptive_59.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_59 &lt;- predict.grf(gwRF_adaptive_59,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_59, \"data/rds/gwRF_pred_59_0.rds\")\n\npred_col_59 &lt;- ifelse(gwRF_pred_59 &gt; 0.5, 1, 0)\npred_col_59 &lt;- factor(pred_col_59)\n\ncm_59_0 &lt;- confusionMatrix(pred_col_59, test_col)\nwrite_rds(cm_59_0, \"data/rds/cm_59_0.rds\")\n\n\ncm_59_0 &lt;- read_rds(\"data/rds/cm_59_0.rds\")\ncm_59_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_59_0)\nrm(gwRF_pred_59)\n\nWarning in rm(gwRF_pred_59): object 'gwRF_pred_59' not found\n\n\n\npred_weight_0 &lt;- as.data.frame(pred_col_59)\n\ncm &lt;- confusionMatrix(pred_col_59, test_col)\n\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\nf1_score.df &lt;- data.frame(\n  \"pred_col_59\" = rep(NA, 5),\n  row.names = c(\"0\", \"0.25\", \"0.5\", \"0.75\", \"1\"),\n  stringsAsFactors = FALSE\n)\n\nf1_score.df[\"0\", \"pred_col_59\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_59 &lt;- predict.grf(gwRF_adaptive_59,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_59, \"data/rds/gwRF_pred_59_0.25.rds\")\n\npred_col_59 &lt;- ifelse(gwRF_pred_59 &gt; 0.5, 1, 0)\npred_col_59 &lt;- factor(pred_col_59)\n\ncm_59_0.25 &lt;- confusionMatrix(pred_col_59, test_col)\nwrite_rds(cm_59_0.25, \"data/rds/cm_59_0.25.rds\")\nrm(gwRF_pred_59)\n\n\ncm_59_0.25 &lt;- read_rds(\"data/rds/cm_59_0.25.rds\")\ncm_59_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5806  920\n         1  572 3919\n                                          \n               Accuracy : 0.867           \n                 95% CI : (0.8606, 0.8732)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7265          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9103          \n            Specificity : 0.8099          \n         Pos Pred Value : 0.8632          \n         Neg Pred Value : 0.8726          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5176          \n   Detection Prevalence : 0.5996          \n      Balanced Accuracy : 0.8601          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_59_0.25)\n\n\npred_weight_0.25 &lt;- as.data.frame(pred_col_59)\n\ncm &lt;- confusionMatrix(pred_col_59, test_col)\n\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\nf1_score.df[\"0.25\", \"pred_col_59\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_59 &lt;- predict.grf(gwRF_adaptive_59,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_59, \"data/rds/gwRF_pred_59_0.5.rds\")\n\npred_col_59 &lt;- ifelse(gwRF_pred_59 &gt; 0.5, 1, 0)\npred_col_59 &lt;- factor(pred_col_59)\n\ncm_59_0.5 &lt;- confusionMatrix(pred_col_59, test_col)\nwrite_rds(cm_59_0.5, \"data/rds/cm_59_0.5.rds\")\nrm(gwRF_pred_59)\n\n\ncm_59_0.5 &lt;- read_rds(\"data/rds/cm_59_0.5.rds\")\ncm_59_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5844  848\n         1  534 3991\n                                          \n               Accuracy : 0.8768          \n                 95% CI : (0.8706, 0.8828)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7469          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9163          \n            Specificity : 0.8248          \n         Pos Pred Value : 0.8733          \n         Neg Pred Value : 0.8820          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5210          \n   Detection Prevalence : 0.5966          \n      Balanced Accuracy : 0.8705          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_59_0.5)\n\n\npred_weight_0.5 &lt;- as.data.frame(pred_col_59)\n\ncm &lt;- confusionMatrix(pred_col_59, test_col)\n\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\nf1_score.df[\"0.5\", \"pred_col_59\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_59 &lt;- predict.grf(gwRF_adaptive_59,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_59, \"data/rds/gwRF_pred_59_0.75.rds\")\n\npred_col_59 &lt;- ifelse(gwRF_pred_59 &gt; 0.5, 1, 0)\npred_col_59 &lt;- factor(pred_col_59)\n\ncm_59_0.75 &lt;- confusionMatrix(pred_col_59, test_col)\nwrite_rds(cm_59_0.75, \"data/rds/cm_59_0.75.rds\")\nrm(gwRF_pred_59)\n\n\ncm_59_0.75 &lt;- read_rds(\"data/rds/cm_59_0.75.rds\")\ncm_59_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5804  902\n         1  574 3937\n                                         \n               Accuracy : 0.8684         \n                 95% CI : (0.862, 0.8746)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7296         \n                                         \n Mcnemar's Test P-Value : &lt; 2.2e-16      \n                                         \n            Sensitivity : 0.9100         \n            Specificity : 0.8136         \n         Pos Pred Value : 0.8655         \n         Neg Pred Value : 0.8728         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5174         \n   Detection Prevalence : 0.5978         \n      Balanced Accuracy : 0.8618         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_59_0.75)\n\n\npred_weight_0.75 &lt;- as.data.frame(pred_col_59)\n\ncm &lt;- confusionMatrix(pred_col_59, test_col)\n\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\nf1_score.df[\"0.75\", \"pred_col_59\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_59 &lt;- predict.grf(gwRF_adaptive_59,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_59, \"data/rds/gwRF_pred_59_1.rds\")\n\npred_col_59 &lt;- ifelse(gwRF_pred_59 &gt; 0.5, 1, 0)\npred_col_59 &lt;- factor(pred_col_59)\n\ncm_59_1 &lt;- confusionMatrix(pred_col_59, test_col)\nwrite_rds(cm_59_1, \"data/rds/cm_59_1.rds\")\nrm(gwRF_pred_59)\n\n\ncm_59_1 &lt;- read_rds(\"data/rds/cm_59_1.rds\")\ncm_59_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5717  996\n         1  661 3843\n                                          \n               Accuracy : 0.8523          \n                 95% CI : (0.8456, 0.8588)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6964          \n                                          \n Mcnemar's Test P-Value : 2.304e-16       \n                                          \n            Sensitivity : 0.8964          \n            Specificity : 0.7942          \n         Pos Pred Value : 0.8516          \n         Neg Pred Value : 0.8532          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5097          \n   Detection Prevalence : 0.5985          \n      Balanced Accuracy : 0.8453          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_59_1)\n\n\npred_weight_1 &lt;- as.data.frame(pred_col_59)\n\ncm &lt;- confusionMatrix(pred_col_59, test_col)\n\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\nf1_score.df[\"1\", \"pred_col_59\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_59)\n\n\n\n\n\n\n\ngwRF_adaptive_92 &lt;- read_rds(\"data/rds/gwRF_adaptive_92.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_92 &lt;- predict.grf(gwRF_adaptive_92,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_92, \"data/rds/gwRF_pred_92_0.rds\")\n\npred_col_92 &lt;- ifelse(gwRF_pred_92 &gt; 0.5, 1, 0)\npred_col_92 &lt;- factor(pred_col_92)\n\ncm_92_0 &lt;- confusionMatrix(pred_col_92, test_col)\nwrite_rds(cm_92_0, \"data/rds/cm_92_0.rds\")\nrm(gwRF_pred_92)\n\n\ncm_92_0 &lt;- read_rds(\"data/rds/cm_92_0.rds\")\ncm_92_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_92_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0, pred_col_92) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[,\"pred_col_92\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_92\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_92 &lt;- predict.grf(gwRF_adaptive_92,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_92, \"data/rds/gwRF_pred_92_0.25.rds\")\n\npred_col_92 &lt;- ifelse(gwRF_pred_92 &gt; 0.5, 1, 0)\npred_col_92 &lt;- factor(pred_col_92)\n\ncm_92_0.25 &lt;- confusionMatrix(pred_col_92, test_col)\nwrite_rds(cm_92_0.25, \"data/rds/cm_92_0.25.rds\")\nrm(gwRF_pred_92)\n\n\ncm_92_0.25 &lt;- read_rds(\"data/rds/cm_92_0.25.rds\")\ncm_92_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5792  921\n         1  586 3918\n                                          \n               Accuracy : 0.8657          \n                 95% CI : (0.8592, 0.8719)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7238          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9081          \n            Specificity : 0.8097          \n         Pos Pred Value : 0.8628          \n         Neg Pred Value : 0.8699          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5164          \n   Detection Prevalence : 0.5985          \n      Balanced Accuracy : 0.8589          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_92_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25, pred_col_92) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.25\",\"pred_col_92\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_92 &lt;- predict.grf(gwRF_adaptive_92,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_92, \"data/rds/gwRF_pred_92_0.5.rds\")\n\npred_col_92 &lt;- ifelse(gwRF_pred_92 &gt; 0.5, 1, 0)\npred_col_92 &lt;- factor(pred_col_92)\n\ncm_92_0.5 &lt;- confusionMatrix(pred_col_92, test_col)\nwrite_rds(cm_92_0.5, \"data/rds/cm_92_0.5.rds\")\nrm(gwRF_pred_92)\n\n\ncm_92_0.5 &lt;- read_rds(\"data/rds/cm_92_0.5.rds\")\ncm_92_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5820  848\n         1  558 3991\n                                          \n               Accuracy : 0.8747          \n                 95% CI : (0.8684, 0.8807)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7426          \n                                          \n Mcnemar's Test P-Value : 1.285e-14       \n                                          \n            Sensitivity : 0.9125          \n            Specificity : 0.8248          \n         Pos Pred Value : 0.8728          \n         Neg Pred Value : 0.8773          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5189          \n   Detection Prevalence : 0.5945          \n      Balanced Accuracy : 0.8686          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_92_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5, pred_col_92) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.5\",\"pred_col_92\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_92 &lt;- predict.grf(gwRF_adaptive_92,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_92, \"data/rds/gwRF_pred_92_0.75.rds\")\n\nread_rds(\"data/rds/gwRF_pred_92_0.75.rds\")\n\npred_col_92 &lt;- ifelse(gwRF_pred_92 &gt; 0.5, 1, 0)\npred_col_92 &lt;- factor(pred_col_92)\n\ncm_92_0.75 &lt;- confusionMatrix(pred_col_92, test_col)\nwrite_rds(cm_92_0.75, \"data/rds/cm_92_0.75.rds\")\nrm(gwRF_pred_92)\n\n\ncm_92_0.75 &lt;- read_rds(\"data/rds/cm_92_0.75.rds\")\ncm_92_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5796  877\n         1  582 3962\n                                          \n               Accuracy : 0.8699          \n                 95% CI : (0.8636, 0.8761)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7329          \n                                          \n Mcnemar's Test P-Value : 1.393e-14       \n                                          \n            Sensitivity : 0.9087          \n            Specificity : 0.8188          \n         Pos Pred Value : 0.8686          \n         Neg Pred Value : 0.8719          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5167          \n   Detection Prevalence : 0.5949          \n      Balanced Accuracy : 0.8638          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_92_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75, pred_col_92) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.75\",\"pred_col_92\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_92 &lt;- predict.grf(gwRF_adaptive_92,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_92, \"data/rds/gwRF_pred_92_1.rds\")\n\npred_col_92 &lt;- ifelse(gwRF_pred_92 &gt; 0.5, 1, 0)\npred_col_92 &lt;- factor(pred_col_92)\n\ncm_92_1 &lt;- confusionMatrix(pred_col_92, test_col)\nwrite_rds(cm_92_1, \"data/rds/cm_92_1.rds\")\nrm(gwRF_pred_92)\n\n\ncm_92_1 &lt;- read_rds(\"data/rds/cm_92_1.rds\")\ncm_92_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5741  973\n         1  637 3866\n                                          \n               Accuracy : 0.8565          \n                 95% CI : (0.8498, 0.8629)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.705           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9001          \n            Specificity : 0.7989          \n         Pos Pred Value : 0.8551          \n         Neg Pred Value : 0.8585          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5118          \n   Detection Prevalence : 0.5986          \n      Balanced Accuracy : 0.8495          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_92_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1, pred_col_92) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"1\",\"pred_col_92\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_92)\n\n\n\n\n\n\n\ngwRF_adaptive_154 &lt;- read_rds(\"data/rds/gwRF_adaptive_154.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_154 &lt;- predict.grf(gwRF_adaptive_154,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_154, \"data/rds/gwRF_pred_154_0.rds\")\n\npred_col_154 &lt;- ifelse(gwRF_pred_154 &gt; 0.5, 1, 0)\npred_col_154 &lt;- factor(pred_col_154)\n\ncm_154_0 &lt;- confusionMatrix(pred_col_154, test_col)\nwrite_rds(cm_154_0, \"data/rds/cm_154_0.rds\")\nrm(gwRF_pred_154)\n\n\ncm_154_0 &lt;- read_rds(\"data/rds/cm_154_0.rds\")\ncm_154_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_154_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0, pred_col_154) \n\ncm &lt;- confusionMatrix(pred_col_92, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[,\"pred_col_154\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_154\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_154 &lt;- predict.grf(gwRF_adaptive_154,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_154, \"data/rds/gwRF_pred_154_0.25.rds\")\n\npred_col_154 &lt;- ifelse(gwRF_pred_154 &gt; 0.5, 1, 0)\npred_col_154 &lt;- factor(pred_col_154)\n\ncm_154_0.25 &lt;- confusionMatrix(pred_col_154, test_col)\nwrite_rds(cm_154_0.25, \"data/rds/cm_154_0.25.rds\")\nrm(gwRF_pred_154)\n\n\ncm_154_0.25 &lt;- read_rds(\"data/rds/cm_154_0.25.rds\")\ncm_154_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5785  934\n         1  593 3905\n                                          \n               Accuracy : 0.8639          \n                 95% CI : (0.8574, 0.8702)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7201          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9070          \n            Specificity : 0.8070          \n         Pos Pred Value : 0.8610          \n         Neg Pred Value : 0.8682          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5157          \n   Detection Prevalence : 0.5990          \n      Balanced Accuracy : 0.8570          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_154_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25, pred_col_154) \n\ncm &lt;- confusionMatrix(pred_col_154, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.25\",\"pred_col_154\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_154 &lt;- predict.grf(gwRF_adaptive_154,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_154, \"data/rds/gwRF_pred_154_0.5.rds\")\n\npred_col_154 &lt;- ifelse(gwRF_pred_154 &gt; 0.5, 1, 0)\npred_col_154 &lt;- factor(pred_col_154)\n\ncm_154_0.5 &lt;- confusionMatrix(pred_col_154, test_col)\nwrite_rds(cm_154_0.5, \"data/rds/cm_154_0.5.rds\")\nrm(gwRF_pred_154)\n\n\ncm_154_0.5 &lt;- read_rds(\"data/rds/cm_154_0.5.rds\")\ncm_154_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5812  848\n         1  566 3991\n                                        \n               Accuracy : 0.8739        \n                 95% CI : (0.8677, 0.88)\n    No Information Rate : 0.5686        \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16     \n                                        \n                  Kappa : 0.7412        \n                                        \n Mcnemar's Test P-Value : 7.852e-14     \n                                        \n            Sensitivity : 0.9113        \n            Specificity : 0.8248        \n         Pos Pred Value : 0.8727        \n         Neg Pred Value : 0.8758        \n             Prevalence : 0.5686        \n         Detection Rate : 0.5181        \n   Detection Prevalence : 0.5937        \n      Balanced Accuracy : 0.8680        \n                                        \n       'Positive' Class : 0             \n                                        \n\nrm(cm_154_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5, pred_col_154) \n\ncm &lt;- confusionMatrix(pred_col_154, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.5\",\"pred_col_154\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_154 &lt;- predict.grf(gwRF_adaptive_154,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_154, \"data/rds/gwRF_pred_154_0.75.rds\")\n\npred_col_154 &lt;- ifelse(gwRF_pred_154 &gt; 0.5, 1, 0)\npred_col_154 &lt;- factor(pred_col_154)\n\ncm_154_0.75 &lt;- confusionMatrix(pred_col_154, test_col)\nwrite_rds(cm_154_0.75, \"data/rds/cm_154_0.75.rds\")\nrm(gwRF_pred_154)\n\n\ncm_154_0.75 &lt;- read_rds(\"data/rds/cm_154_0.75.rds\")\ncm_154_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5812  850\n         1  566 3989\n                                          \n               Accuracy : 0.8738          \n                 95% CI : (0.8675, 0.8799)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7408          \n                                          \n Mcnemar's Test P-Value : 5.451e-14       \n                                          \n            Sensitivity : 0.9113          \n            Specificity : 0.8243          \n         Pos Pred Value : 0.8724          \n         Neg Pred Value : 0.8757          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5181          \n   Detection Prevalence : 0.5939          \n      Balanced Accuracy : 0.8678          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_154_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75, pred_col_154) \n\ncm &lt;- confusionMatrix(pred_col_154, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"0.75\",\"pred_col_154\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\ngwRF_pred_154 &lt;- predict.grf(gwRF_adaptive_154,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_154, \"data/rds/gwRF_pred_154_1.rds\")\n\npred_col_154 &lt;- ifelse(gwRF_pred_154 &gt; 0.5, 1, 0)\npred_col_154 &lt;- factor(pred_col_154)\n\ncm_154_1 &lt;- confusionMatrix(pred_col_154, test_col)\nwrite_rds(cm_154_1, \"data/rds/cm_154_1.rds\")\nrm(gwRF_pred_154)\n\n\ncm_154_1 &lt;- read_rds(\"data/rds/cm_154_1.rds\")\ncm_154_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5779  925\n         1  599 3914\n                                          \n               Accuracy : 0.8641          \n                 95% CI : (0.8577, 0.8704)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7208          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9061          \n            Specificity : 0.8088          \n         Pos Pred Value : 0.8620          \n         Neg Pred Value : 0.8673          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5152          \n   Detection Prevalence : 0.5977          \n      Balanced Accuracy : 0.8575          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_154_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1, pred_col_154) \n\ncm &lt;- confusionMatrix(pred_col_154, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision * recall) / (precision + recall)\n\n\nf1_score.df[\"1\",\"pred_col_154\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_154)\n\n\n\n\n\n\n\ngwRF_adaptive_189 &lt;- read_rds(\"data/rds/gwRF_adaptive_189.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_189 &lt;- predict.grf(gwRF_adaptive_189,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_189, \"data/rds/gwRF_pred_189_0.rds\")\n\npred_col_189 &lt;- ifelse(gwRF_pred_189 &gt; 0.5, 1, 0)\npred_col_189 &lt;- factor(pred_col_189)\n\ncm_189_0 &lt;- confusionMatrix(pred_col_189, test_col)\nwrite_rds(cm_189_0, \"data/rds/cm_189_0.rds\")\n\nrm(gwRF_pred_189)\n\n\ncm_189_0 &lt;- read_rds(\"data/rds/cm_189_0.rds\")\ncm_189_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_189_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_189)\n\ncm &lt;- confusionMatrix(pred_col_189, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_189\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_189\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_189 &lt;- predict.grf(gwRF_adaptive_189,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_189, \"data/rds/gwRF_pred_189_0.25.rds\")\n\npred_col_189 &lt;- ifelse(gwRF_pred_189 &gt; 0.5, 1, 0)\npred_col_189 &lt;- factor(pred_col_189)\n\ncm_189_0.25 &lt;- confusionMatrix(pred_col_189, test_col)\nwrite_rds(cm_189_0.25, \"data/rds/cm_189_0.25.rds\")\n\nrm(gwRF_pred_189)\n\n\ncm_189_0.25 &lt;- read_rds(\"data/rds/cm_189_0.25.rds\")\ncm_189_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5773  938\n         1  605 3901\n                                          \n               Accuracy : 0.8624          \n                 95% CI : (0.8559, 0.8688)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7173          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9051          \n            Specificity : 0.8062          \n         Pos Pred Value : 0.8602          \n         Neg Pred Value : 0.8657          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5147          \n   Detection Prevalence : 0.5983          \n      Balanced Accuracy : 0.8557          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_189_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_189)\n\ncm &lt;- confusionMatrix(pred_col_189, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\n\nf1_score.df[\"0.25\",\"pred_col_189\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_189 &lt;- predict.grf(gwRF_adaptive_189,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_189, \"data/rds/gwRF_pred_189_0.5.rds\")\n\npred_col_189 &lt;- ifelse(gwRF_pred_189 &gt; 0.5, 1, 0)\npred_col_189 &lt;- factor(pred_col_189)\n\ncm_189_0.5 &lt;- confusionMatrix(pred_col_189, test_col)\nwrite_rds(cm_189_0.5, \"data/rds/cm_189_0.5.rds\")\nrm(gwRF_pred_189)\n\n\ncm_189_0.5 &lt;- read_rds(\"data/rds/cm_189_0.5.rds\")\ncm_189_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5817  866\n         1  561 3973\n                                          \n               Accuracy : 0.8728          \n                 95% CI : (0.8665, 0.8789)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7387          \n                                          \n Mcnemar's Test P-Value : 8.449e-16       \n                                          \n            Sensitivity : 0.9120          \n            Specificity : 0.8210          \n         Pos Pred Value : 0.8704          \n         Neg Pred Value : 0.8763          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5186          \n   Detection Prevalence : 0.5958          \n      Balanced Accuracy : 0.8665          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_189_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_189)\n\ncm &lt;- confusionMatrix(pred_col_189, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_189\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_189 &lt;- predict.grf(gwRF_adaptive_189,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\ngwRF_pred_189 &lt;- as.data.frame(gwRF_pred_189)\n\nwrite_rds(gwRF_pred_189, \"data/rds/gwRF_pred_189_0.75.rds\")\n\npred_col_189 &lt;- ifelse(gwRF_pred_189 &gt; 0.5, 1, 0)\npred_col_189 &lt;- factor(pred_col_189)\n\ncm_189_0.75 &lt;- confusionMatrix(pred_col_189, test_col)\nwrite_rds(cm_189_0.75, \"data/rds/cm_189_0.75.rds\")\nrm(gwRF_pred_189)\n\n\ncm_189_0.75 &lt;- read_rds(\"data/rds/cm_189_0.75.rds\")\ncm_189_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5824  841\n         1  554 3998\n                                          \n               Accuracy : 0.8756          \n                 95% CI : (0.8694, 0.8817)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7447          \n                                          \n Mcnemar's Test P-Value : 1.898e-14       \n                                          \n            Sensitivity : 0.9131          \n            Specificity : 0.8262          \n         Pos Pred Value : 0.8738          \n         Neg Pred Value : 0.8783          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5192          \n   Detection Prevalence : 0.5942          \n      Balanced Accuracy : 0.8697          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_189_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_189)\n\ncm &lt;- confusionMatrix(pred_col_189, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_189\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_189 &lt;- predict.grf(gwRF_adaptive_189,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_189, \"data/rds/gwRF_pred_189_1.rds\")\n\npred_col_189 &lt;- ifelse(gwRF_pred_189 &gt; 0.5, 1, 0)\npred_col_189 &lt;- factor(pred_col_189)\n\ncm_189_1 &lt;- confusionMatrix(pred_col_189, test_col)\nwrite_rds(cm_189_1, \"data/rds/cm_189_1.rds\")\nrm(gwRF_pred_189)\n\n\ncm_189_1 &lt;- read_rds(\"data/rds/cm_189_1.rds\")\ncm_189_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5785  902\n         1  593 3937\n                                         \n               Accuracy : 0.8667         \n                 95% CI : (0.8603, 0.873)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7262         \n                                         \n Mcnemar's Test P-Value : 1.641e-15      \n                                         \n            Sensitivity : 0.9070         \n            Specificity : 0.8136         \n         Pos Pred Value : 0.8651         \n         Neg Pred Value : 0.8691         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5157         \n   Detection Prevalence : 0.5961         \n      Balanced Accuracy : 0.8603         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_189_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_189)\n\ncm &lt;- confusionMatrix(pred_col_189, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_189\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_189)\n\n\n\n\n\n\n\ngwRF_adaptive_260 &lt;- read_rds(\"data/rds/gwRF_adaptive_260.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_260 &lt;- predict.grf(gwRF_adaptive_260,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_260, \"data/rds/gwRF_pred_260_0.rds\")\n\npred_col_260 &lt;- ifelse(gwRF_pred_260 &gt; 0.5, 1, 0)\npred_col_260 &lt;- factor(pred_col_260)\n\ncm_260_0 &lt;- confusionMatrix(pred_col_260, test_col)\nwrite_rds(cm_260_0, \"data/rds/cm_260_0.rds\")\nrm(gwRF_pred_260)\n\n\ncm_260_0 &lt;- read_rds(\"data/rds/cm_260_0.rds\")\ncm_260_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_260_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_260)\n\ncm &lt;- confusionMatrix(pred_col_260, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_260\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_260\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_260 &lt;- predict.grf(gwRF_adaptive_260,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_260, \"data/rds/gwRF_pred_260_0.25.rds\")\n\npred_col_260 &lt;- ifelse(gwRF_pred_260 &gt; 0.5, 1, 0)\npred_col_260 &lt;- factor(pred_col_260)\n\ncm_260_0.25 &lt;- confusionMatrix(pred_col_260, test_col)\nwrite_rds(cm_260_0.25, \"data/rds/cm_260_0.25.rds\")\nrm(gwRF_pred_260)\n\n\ncm_260_0.25 &lt;- read_rds(\"data/rds/cm_260_0.25.rds\")\ncm_260_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5758  952\n         1  620 3887\n                                          \n               Accuracy : 0.8599          \n                 95% CI : (0.8533, 0.8662)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7119          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9028          \n            Specificity : 0.8033          \n         Pos Pred Value : 0.8581          \n         Neg Pred Value : 0.8624          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5133          \n   Detection Prevalence : 0.5982          \n      Balanced Accuracy : 0.8530          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_260_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_260)\n\ncm &lt;- confusionMatrix(pred_col_260, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_260\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_260 &lt;- predict.grf(gwRF_adaptive_260,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_260, \"data/rds/gwRF_pred_260_0.5.rds\")\n\npred_col_260 &lt;- ifelse(gwRF_pred_260 &gt; 0.5, 1, 0)\npred_col_260 &lt;- factor(pred_col_260)\n\ncm_260_0.5 &lt;- confusionMatrix(pred_col_260, test_col)\nwrite_rds(cm_260_0.5, \"data/rds/cm_260_0.5.rds\")\nrm(gwRF_pred_260)\n\n\ncm_260_0.5 &lt;- read_rds(\"data/rds/cm_260_0.5.rds\")\ncm_260_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5807  877\n         1  571 3962\n                                          \n               Accuracy : 0.8709          \n                 95% CI : (0.8646, 0.8771)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7348          \n                                          \n Mcnemar's Test P-Value : 1.099e-15       \n                                          \n            Sensitivity : 0.9105          \n            Specificity : 0.8188          \n         Pos Pred Value : 0.8688          \n         Neg Pred Value : 0.8740          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5177          \n   Detection Prevalence : 0.5959          \n      Balanced Accuracy : 0.8646          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_260_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_260)\n\ncm &lt;- confusionMatrix(pred_col_260, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_260\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_260 &lt;- predict.grf(gwRF_adaptive_260,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_260, \"data/rds/gwRF_pred_260_0.75.rds\")\n\npred_col_260 &lt;- ifelse(gwRF_pred_260 &gt; 0.5, 1, 0)\npred_col_260 &lt;- factor(pred_col_260)\n\ncm_260_0.75 &lt;- confusionMatrix(pred_col_260, test_col)\nwrite_rds(cm_260_0.75, \"data/rds/cm_260_0.75.rds\")\nrm(gwRF_pred_260)\n\n\ncm_260_0.75 &lt;- read_rds(\"data/rds/cm_260_0.75.rds\")\ncm_260_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5799  853\n         1  579 3986\n                                         \n               Accuracy : 0.8723         \n                 95% CI : (0.866, 0.8785)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.738          \n                                         \n Mcnemar's Test P-Value : 5.423e-13      \n                                         \n            Sensitivity : 0.9092         \n            Specificity : 0.8237         \n         Pos Pred Value : 0.8718         \n         Neg Pred Value : 0.8732         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5170         \n   Detection Prevalence : 0.5930         \n      Balanced Accuracy : 0.8665         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_260_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_260)\n\ncm &lt;- confusionMatrix(pred_col_260, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_260\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_260 &lt;- predict.grf(gwRF_adaptive_260,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_260, \"data/rds/gwRF_pred_260_1.rds\")\n\npred_col_260 &lt;- ifelse(gwRF_pred_260 &gt; 0.5, 1, 0)\npred_col_260 &lt;- factor(pred_col_260)\n\ncm_260_1 &lt;- confusionMatrix(pred_col_260, test_col)\nwrite_rds(cm_260_1, \"data/rds/cm_260_1.rds\")\nrm(gwRF_pred_260)\n\n\ncm_260_1 &lt;- read_rds(\"data/rds/cm_260_1.rds\")\ncm_260_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5773  869\n         1  605 3970\n                                          \n               Accuracy : 0.8686          \n                 95% CI : (0.8622, 0.8748)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7304          \n                                          \n Mcnemar's Test P-Value : 7.372e-12       \n                                          \n            Sensitivity : 0.9051          \n            Specificity : 0.8204          \n         Pos Pred Value : 0.8692          \n         Neg Pred Value : 0.8678          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5147          \n   Detection Prevalence : 0.5921          \n      Balanced Accuracy : 0.8628          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_260_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_260)\n\ncm &lt;- confusionMatrix(pred_col_260, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_260\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_260)\n\n\n\n\n\n\n\ngwRF_adaptive_306 &lt;- read_rds(\"data/rds/gwRF_adaptive_306.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_306 &lt;- predict.grf(gwRF_adaptive_306,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_306, \"data/rds/gwRF_pred_306_0.rds\")\n\npred_col_306 &lt;- ifelse(gwRF_pred_306 &gt; 0.5, 1, 0)\npred_col_306 &lt;- factor(pred_col_306)\n\ncm_306_0 &lt;- confusionMatrix(pred_col_306, test_col)\nwrite_rds(cm_306_0, \"data/rds/cm_306_0.rds\")\nrm(gwRF_pred_306)\n\n\ncm_306_0 &lt;- read_rds(\"data/rds/cm_306_0.rds\")\ncm_306_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_306_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_306)\n\ncm &lt;- confusionMatrix(pred_col_306, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_306\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_306\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_306 &lt;- predict.grf(gwRF_adaptive_306,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_306, \"data/rds/gwRF_pred_306_0.25.rds\")\n\npred_col_306 &lt;- ifelse(gwRF_pred_306 &gt; 0.5, 1, 0)\npred_col_306 &lt;- factor(pred_col_306)\n\ncm_306_0.25 &lt;- confusionMatrix(pred_col_306, test_col)\nwrite_rds(cm_306_0.25, \"data/rds/cm_306_0.25.rds\")\nrm(gwRF_pred_306) \n\n\ncm_306_0.25 &lt;- read_rds(\"data/rds/cm_306_0.25.rds\")\ncm_306_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5757  951\n         1  621 3888\n                                          \n               Accuracy : 0.8599          \n                 95% CI : (0.8533, 0.8662)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.712           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9026          \n            Specificity : 0.8035          \n         Pos Pred Value : 0.8582          \n         Neg Pred Value : 0.8623          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5132          \n   Detection Prevalence : 0.5980          \n      Balanced Accuracy : 0.8531          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_306_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_306)\n\ncm &lt;- confusionMatrix(pred_col_306, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_306\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_306 &lt;- predict.grf(gwRF_adaptive_306,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_306, \"data/rds/gwRF_pred_306_0.5.rds\")\n\npred_col_306 &lt;- ifelse(gwRF_pred_306 &gt; 0.5, 1, 0)\npred_col_306 &lt;- factor(pred_col_306)\n\ncm_306_0.5 &lt;- confusionMatrix(pred_col_306, test_col)\nwrite_rds(cm_306_0.5, \"data/rds/cm_306_0.5.rds\")\nrm(gwRF_pred_306) \n\n\ncm_306_0.5 &lt;- read_rds(\"data/rds/cm_306_0.5.rds\")\ncm_306_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5804  875\n         1  574 3964\n                                         \n               Accuracy : 0.8708         \n                 95% CI : (0.8645, 0.877)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7347         \n                                         \n Mcnemar's Test P-Value : 3.245e-15      \n                                         \n            Sensitivity : 0.9100         \n            Specificity : 0.8192         \n         Pos Pred Value : 0.8690         \n         Neg Pred Value : 0.8735         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5174         \n   Detection Prevalence : 0.5954         \n      Balanced Accuracy : 0.8646         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_306_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_306)\n\ncm &lt;- confusionMatrix(pred_col_306, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_306\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_306 &lt;- predict.grf(gwRF_adaptive_306,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_306, \"data/rds/gwRF_pred_306_0.75.rds\")\n\npred_col_306 &lt;- ifelse(gwRF_pred_306 &gt; 0.5, 1, 0)\npred_col_306 &lt;- factor(pred_col_306)\n\ncm_306_0.75 &lt;- confusionMatrix(pred_col_306, test_col)\nwrite_rds(cm_306_0.75, \"data/rds/cm_306_0.75.rds\")\nrm(gwRF_pred_306) \n\n\ncm_306_0.75 &lt;- read_rds(\"data/rds/cm_306_0.75.rds\")\ncm_306_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5806  860\n         1  572 3979\n                                         \n               Accuracy : 0.8723         \n                 95% CI : (0.866, 0.8785)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7379         \n                                         \n Mcnemar's Test P-Value : 3.345e-14      \n                                         \n            Sensitivity : 0.9103         \n            Specificity : 0.8223         \n         Pos Pred Value : 0.8710         \n         Neg Pred Value : 0.8743         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5176         \n   Detection Prevalence : 0.5943         \n      Balanced Accuracy : 0.8663         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_306_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_306)\n\ncm &lt;- confusionMatrix(pred_col_306, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_306\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_306 &lt;- predict.grf(gwRF_adaptive_306,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_306, \"data/rds/gwRF_pred_306_1.rds\")\n\npred_col_306 &lt;- ifelse(gwRF_pred_306 &gt; 0.5, 1, 0)\npred_col_306 &lt;- factor(pred_col_306)\n\ncm_306_1 &lt;- confusionMatrix(pred_col_306, test_col)\nwrite_rds(cm_306_1, \"data/rds/cm_306_1.rds\")\nrm(gwRF_pred_306) \n\n\ncm_306_1 &lt;- read_rds(\"data/rds/cm_306_1.rds\")\ncm_306_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5775  873\n         1  603 3966\n                                         \n               Accuracy : 0.8684         \n                 95% CI : (0.862, 0.8746)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.73           \n                                         \n Mcnemar's Test P-Value : 2.527e-12      \n                                         \n            Sensitivity : 0.9055         \n            Specificity : 0.8196         \n         Pos Pred Value : 0.8687         \n         Neg Pred Value : 0.8680         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5148         \n   Detection Prevalence : 0.5927         \n      Balanced Accuracy : 0.8625         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_306_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_306)\n\ncm &lt;- confusionMatrix(pred_col_306, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_306\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_306)"
  },
  {
    "objectID": "predictivemodelling.html#plotting-gwrf-model-prediction-accuracy-at-incrementing-weight-optimised-bandwidth",
    "href": "predictivemodelling.html#plotting-gwrf-model-prediction-accuracy-at-incrementing-weight-optimised-bandwidth",
    "title": "Machine Learning Modelling",
    "section": "7.3 Plotting GWRF Model Prediction Accuracy at Incrementing Weight & Optimised Bandwidth",
    "text": "7.3 Plotting GWRF Model Prediction Accuracy at Incrementing Weight & Optimised Bandwidth\nIn this section, we are plotting the prediction accuracy of the GWRFmodels at incrementing weight parameters and optimised bandwidths. The weight parameters range from 0 to 1 in increments of 0.25, and the optimised bandwidths used are 59, 92, 154, 189, 260, and 306.\nThe code chunk below creates a data frame with all combinations of weights and bandwidths, adds the accuracy values for each combination, and then creates a line plot of the accuracy against the bandwidth for each weight.\n\nweights &lt;- c(\"0\", \"0.25\", \"0.50\", \"0.75\", \"1\")\nbandwidths &lt;- c(59, 92, 154, 189, 260, 306)\n\n# Create a data frame with all combinations of weights and bandwidths\ndf_gwRF &lt;- expand.grid(Weight = weights, Bandwidth = bandwidths)\n\n# Add your accuracy values\n\ndf_gwRF$Accuracy &lt;-  c(\n  0.8487, 0.8670, 0.8768, 0.8684, 0.8523, \n  0.8487, 0.8657, 0.8747, 0.8699, 0.8565,\n  0.8487, 0.8639, 0.8739, 0.8738, 0.8641,\n  0.8487, 0.8264, 0.8728, 0.8756, 0.8667,\n  0.8487, 0.8599, 0.8709, 0.8723, 0.8686,\n  0.8487, 0.8599, 0.8708, 0.8723, 0.8684\n)\n\n# Create the plot\nggplot(df_gwRF, aes(x = Bandwidth, y = Accuracy, color = Weight)) +\n  geom_line() +\n  geom_point(shape = 9, size = 2.5) +\n  labs(x = \"Bandwidth\", y = \"Accuracy\", title = \"GWRF Model Prediction Accuracy \\nat Incrementing Weight & Optimised Bandwidth\") +\n  scale_x_continuous(breaks = c(59, 92, 154, 189, 260,306)) +\n  scale_y_continuous(limits = c(0.82, 0.89)) +\n  scale_color_manual(values = c(\"#e4c838\", \"#de573e\", \"#b977cb\", \"#4225df\", \"#32c962\")) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),  # Remove internal grid lines\n    panel.border = element_rect(color = \"black\", fill = NA),\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )"
  },
  {
    "objectID": "predictivemodelling.html#iteraction-with-standardised-bandwidths",
    "href": "predictivemodelling.html#iteraction-with-standardised-bandwidths",
    "title": "Machine Learning Modelling",
    "section": "7.4 Iteraction with Standardised Bandwidths",
    "text": "7.4 Iteraction with Standardised Bandwidths\nIn the previous sections, we fitted, trained, and tested Geographically Weighted Random Forest (GWRF) models using optimised bandwidth values. However, the bandwidths used were random with different steps between them, which may make the observed result patterns not generalisable. To see if the patterns we observed earlier can be generalised (at least for our dataset), we will use standardised bandwidths with 50 steps to fit new models. We will use 50, 100, 150, 200, 250, and 300 as bandwidths.\nBelow is the code chunk that accomplishes this:\n\n50-Bandwidth GWRF100-Bandwidth GWRF150-Bandwidth GWRF200-Bandwidth GWRF250-Bandwidth GWRF300-Bandwidth GWRF\n\n\n\nset.seed(1234)\ngwRF_adaptive_50 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=50,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_50, \"data/rds/gwRF_adaptive_50.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_100 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw= 100,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_100, \"data/rds/gwRF_adaptive_100.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_150 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=150,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_150, \"data/rds/gwRF_adaptive_150.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_200 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=200,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_200, \"data/rds/gwRF_adaptive_200.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_250 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=250,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_250, \"data/rds/gwRF_adaptive_250.rds\")\n\n\n\n\nset.seed(1234)\ngwRF_adaptive_300 &lt;- grf(formula = Landslide ~ Elevation + \n                 Aspect_North + Aspect_NorthEast + \n                 Aspect_East + Aspect_SouthEast + \n                 Aspect_South + Aspect_SouthWest + \n                 Aspect_West + Profile_Curvature + \n                 Plan_Curvature + Slope_Angle + \n                 Lithology_Metamorphic + \n                 Lithology_Sedimentary + \n                 Lithology_Plutonic +\n                 Lithology_Unconsolidated +\n                 Proximity_Settlement +\n                 Proximity_Stream +\n                 Proximity_Road + Proximity_Fault + \n                 Landuse_Vegetation + Precipitation + \n                 TWI + SPI + STI,\n                 dframe=training_data, \n                 bw=300,\n                 kernel=\"adaptive\",\n                 coords=coords_train)\n\nwrite_rds(gwRF_adaptive_300, \"data/rds/gwRF_adaptive_300.rds\")\n\n\n\n\n\nrm(gwRF_adaptive_50)\nrm(gwRF_adaptive_100)\nrm(gwRF_adaptive_150)\nrm(gwRF_adaptive_200)\nrm(gwRF_adaptive_250)\nrm(gwRF_adaptive_300)"
  },
  {
    "objectID": "predictivemodelling.html#prediction-with-various-spatial-weights-1",
    "href": "predictivemodelling.html#prediction-with-various-spatial-weights-1",
    "title": "Machine Learning Modelling",
    "section": "7.5 Prediction with Various Spatial Weights",
    "text": "7.5 Prediction with Various Spatial Weights\nIn this section, we will test the predictions using the newly fitted Geographically Weighted Random Forest (GWRF) models with standardised bandwidths at different weight parameters. This process is similar to what we did in the previous sections.\nWe will use these models to make predictions and then extract the performance metrics. These metrics will allow us to evaluate the performance of each model and compare the results with the GWRF models that were fitted with optimised bandwidths.\nBelow is the code chunk that accomplishes this:\n\n50-Bandwidth GWRF100-Bandwidth GWRF150-Bandwidth GWRF200-Bandwidth GWRF250-Bandwidth GWRF300-Bandwidth GWRF\n\n\n\ngwRF_adaptive_50 &lt;- read_rds(\"data/rds/gwRF_adaptive_50.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_50 &lt;- predict.grf(gwRF_adaptive_50,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_50, \"data/rds/gwRF_pred_50_0.rds\")\n\ngwRF_pred_50 &lt;- read_rds(\"data/rds/gwRF_pred_50_0.rds\")\n\npred_col_50 &lt;- ifelse(gwRF_pred_50 &gt; 0.5, 1, 0)\npred_col_50 &lt;- factor(pred_col_50)\n\ncm_50_0 &lt;- confusionMatrix(pred_col_50, test_col)\nwrite_rds(cm_50_0, \"data/rds/cm_50_0.rds\")\nrm(gwRF_pred_50)\n\n\ncm_50_0 &lt;- read_rds(\"data/rds/cm_50_0.rds\")\ncm_50_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_50_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_50)\n\ncm &lt;- confusionMatrix(pred_col_50, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_50\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_50\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_50 &lt;- predict.grf(gwRF_adaptive_50,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_50, \"data/rds/gwRF_pred_50_0.25.rds\")\n\ngwRF_pred_50 &lt;- read_rds(\"data/rds/gwRF_pred_50_0.25.rds\")\n\npred_col_50 &lt;- ifelse(gwRF_pred_50 &gt; 0.5, 1, 0)\npred_col_50 &lt;- factor(pred_col_50)\n\ncm_50_0.25 &lt;- confusionMatrix(pred_col_50, test_col)\nwrite_rds(cm_50_0.25, \"data/rds/cm_50_0.25.rds\")\nrm(gwRF_pred_50)\n\n\ncm_50_0.25 &lt;- read_rds(\"data/rds/cm_50_0.25.rds\")\ncm_50_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5817  919\n         1  561 3920\n                                          \n               Accuracy : 0.8681          \n                 95% CI : (0.8617, 0.8743)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7286          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9120          \n            Specificity : 0.8101          \n         Pos Pred Value : 0.8636          \n         Neg Pred Value : 0.8748          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5186          \n   Detection Prevalence : 0.6005          \n      Balanced Accuracy : 0.8611          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_50_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_50)\n\ncm &lt;- confusionMatrix(pred_col_50, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_50\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_50 &lt;- predict.grf(gwRF_adaptive_50,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_50, \"data/rds/gwRF_pred_50_0.5.rds\")\n\ngwRF_pred_50 &lt;- read_rds(\"data/rds/gwRF_pred_50_0.5.rds\")\n\npred_col_50 &lt;- ifelse(gwRF_pred_50 &gt; 0.5, 1, 0)\npred_col_50 &lt;- factor(pred_col_50)\n\ncm_50_0.5 &lt;- confusionMatrix(pred_col_50, test_col)\nwrite_rds(cm_50_0.5, \"data/rds/cm_50_0.5.rds\")\nrm(gwRF_pred_50)\n\n\ncm_50_0.5 &lt;- read_rds(\"data/rds/cm_50_0.5.rds\")\ncm_50_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5853  851\n         1  525 3988\n                                          \n               Accuracy : 0.8773          \n                 95% CI : (0.8711, 0.8833)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7479          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9177          \n            Specificity : 0.8241          \n         Pos Pred Value : 0.8731          \n         Neg Pred Value : 0.8837          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5218          \n   Detection Prevalence : 0.5977          \n      Balanced Accuracy : 0.8709          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_50_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_50)\n\ncm &lt;- confusionMatrix(pred_col_50, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_50\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_50 &lt;- predict.grf(gwRF_adaptive_50,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\n\nwrite_rds(gwRF_pred_50, \"data/rds/gwRF_pred_50_0.75.rds\")\n\ngwRF_pred_50 &lt;- read_rds(\"data/rds/gwRF_pred_50_0.75.rds\")\n\npred_col_50 &lt;- ifelse(gwRF_pred_50 &gt; 0.5, 1, 0)\npred_col_50 &lt;- factor(pred_col_50)\n\ncm_50_0.75 &lt;- confusionMatrix(pred_col_50, test_col)\nwrite_rds(cm_50_0.75, \"data/rds/cm_50_0.75.rds\")\nrm(gwRF_pred_50)\n\n\ncm_50_0.75 &lt;- read_rds(\"data/rds/cm_50_0.75.rds\")\ncm_50_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5822  923\n         1  556 3916\n                                          \n               Accuracy : 0.8681          \n                 95% CI : (0.8617, 0.8744)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7288          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9128          \n            Specificity : 0.8093          \n         Pos Pred Value : 0.8632          \n         Neg Pred Value : 0.8757          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5190          \n   Detection Prevalence : 0.6013          \n      Balanced Accuracy : 0.8610          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_50_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_50)\n\ncm &lt;- confusionMatrix(pred_col_50, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_50\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234) \ngwRF_pred_50 &lt;- predict.grf(gwRF_adaptive_50,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\nwrite_rds(gwRF_pred_50, \"data/rds/gwRF_pred_50_1.rds\")\n\ngwRF_pred_50 &lt;- read_rds(\"data/rds/gwRF_pred_50_1.rds\")\n\npred_col_50 &lt;- ifelse(gwRF_pred_50 &gt; 0.5, 1, 0)\npred_col_50 &lt;- factor(pred_col_50)\n\ncm_50_1 &lt;- confusionMatrix(pred_col_50, test_col)\nwrite_rds(cm_50_1, \"data/rds/cm_50_1.rds\")\nrm(gwRF_pred_50)\n\n\ncm_50_1 &lt;- read_rds(\"data/rds/cm_50_1.rds\")\ncm_50_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5942  892\n         1  436 3947\n                                          \n               Accuracy : 0.8816          \n                 95% CI : (0.8755, 0.8875)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7559          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9316          \n            Specificity : 0.8157          \n         Pos Pred Value : 0.8695          \n         Neg Pred Value : 0.9005          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5297          \n   Detection Prevalence : 0.6093          \n      Balanced Accuracy : 0.8737          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_50_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_50)\n\ncm &lt;- confusionMatrix(pred_col_50, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_50\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_50)\n\n\n\n\n\n\n\ngwRF_adaptive_100 &lt;- read_rds(\"data/rds/gwRF_adaptive_100.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_100 &lt;- predict.grf(gwRF_adaptive_100,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_100, \"data/rds/gwRF_pred_100_0.rds\")\n\ngwRF_pred_100 &lt;- read_rds(\"data/rds/gwRF_pred_100_0.rds\")\n\npred_col_100 &lt;- ifelse(gwRF_pred_100 &gt; 0.5, 1, 0)\npred_col_100 &lt;- factor(pred_col_100)\n\ncm_100_0 &lt;- confusionMatrix(pred_col_100, test_col)\nwrite_rds(cm_100_0, \"data/rds/cm_100_0.rds\")\nrm(gwRF_pred_100)\n\n\ncm_100_0 &lt;- read_rds(\"data/rds/cm_100_0.rds\")\ncm_100_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_100_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_100)\n\ncm &lt;- confusionMatrix(pred_col_100, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_100\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_100\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_100 &lt;- predict.grf(gwRF_adaptive_100,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_100, \"data/rds/gwRF_pred_100_0.25.rds\")\n\ngwRF_pred_100 &lt;- read_rds(\"data/rds/gwRF_pred_100_0.25.rds\")\n\npred_col_100 &lt;- ifelse(gwRF_pred_100 &gt; 0.5, 1, 0)\npred_col_100 &lt;- factor(pred_col_100)\n\ncm_100_0.25 &lt;- confusionMatrix(pred_col_100, test_col)\nwrite_rds(cm_100_0.25, \"data/rds/cm_100_0.25.rds\")\n\nrm(gwRF_pred_100)\n\n\ncm_100_0.25 &lt;- read_rds(\"data/rds/cm_100_0.25.rds\")\ncm_100_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5794  930\n         1  584 3909\n                                          \n               Accuracy : 0.865           \n                 95% CI : (0.8586, 0.8713)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7225          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9084          \n            Specificity : 0.8078          \n         Pos Pred Value : 0.8617          \n         Neg Pred Value : 0.8700          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5165          \n   Detection Prevalence : 0.5994          \n      Balanced Accuracy : 0.8581          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_100_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_100)\n\ncm &lt;- confusionMatrix(pred_col_100, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_100\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_100 &lt;- predict.grf(gwRF_adaptive_100,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_100, \"data/rds/gwRF_pred_100_0.5.rds\")\n\ngwRF_pred_100 &lt;- read_rds(\"data/rds/gwRF_pred_100_0.5.rds\")\n\npred_col_100 &lt;- ifelse(gwRF_pred_100 &gt; 0.5, 1, 0)\npred_col_100 &lt;- factor(pred_col_100)\n\ncm_100_0.5 &lt;- confusionMatrix(pred_col_100, test_col)\nwrite_rds(cm_100_0.5, \"data/rds/cm_100_0.5.rds\")\n\nrm(gwRF_pred_100)\n\n\ncm_100_0.5 &lt;- read_rds(\"data/rds/cm_100_0.5.rds\")\ncm_100_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5824  848\n         1  554 3991\n                                          \n               Accuracy : 0.875           \n                 95% CI : (0.8687, 0.8811)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7433          \n                                          \n Mcnemar's Test P-Value : 5.07e-15        \n                                          \n            Sensitivity : 0.9131          \n            Specificity : 0.8248          \n         Pos Pred Value : 0.8729          \n         Neg Pred Value : 0.8781          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5192          \n   Detection Prevalence : 0.5948          \n      Balanced Accuracy : 0.8689          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_100_0.5)\n\n\nset.seed(1234)\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_100)\n\ncm &lt;- confusionMatrix(pred_col_100, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_100\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_100 &lt;- predict.grf(gwRF_adaptive_100,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\nwrite_rds(gwRF_pred_100, \"data/rds/gwRF_pred_100_0.75.rds\")\n\ngwRF_pred_100 &lt;- read_rds(\"data/rds/gwRF_pred_100_0.75.rds\")\n\npred_col_100 &lt;- ifelse(gwRF_pred_100 &gt; 0.5, 1, 0)\npred_col_100 &lt;- factor(pred_col_100)\n\ncm_100_0.75 &lt;- confusionMatrix(pred_col_100, test_col)\nwrite_rds(cm_100_0.75, \"data/rds/cm_100_0.75.rds\")\n\nrm(gwRF_pred_100)\n\n\ncm_100_0.75 &lt;- read_rds(\"data/rds/cm_100_0.75.rds\")\ncm_100_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5796  878\n         1  582 3961\n                                         \n               Accuracy : 0.8698         \n                 95% CI : (0.8635, 0.876)\n    No Information Rate : 0.5686         \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16      \n                                         \n                  Kappa : 0.7327         \n                                         \n Mcnemar's Test P-Value : 1.159e-14      \n                                         \n            Sensitivity : 0.9087         \n            Specificity : 0.8186         \n         Pos Pred Value : 0.8684         \n         Neg Pred Value : 0.8719         \n             Prevalence : 0.5686         \n         Detection Rate : 0.5167         \n   Detection Prevalence : 0.5950         \n      Balanced Accuracy : 0.8637         \n                                         \n       'Positive' Class : 0              \n                                         \n\nrm(cm_100_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_100)\n\ncm &lt;- confusionMatrix(pred_col_100, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_100\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_100 &lt;- predict.grf(gwRF_adaptive_100,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_100, \"data/rds/gwRF_pred_100_1.rds\")\n\ngwRF_pred_100 &lt;- read_rds(\"data/rds/gwRF_pred_100_1.rds\")\n\npred_col_100 &lt;- ifelse(gwRF_pred_100 &gt; 0.5, 1, 0)\npred_col_100 &lt;- factor(pred_col_100)\n\ncm_100_1 &lt;- confusionMatrix(pred_col_100, test_col)\nwrite_rds(cm_100_1, \"data/rds/cm_100_1.rds\")\n\nrm(gwRF_pred_100)\n\n\ncm_100_1 &lt;- read_rds(\"data/rds/cm_100_1.rds\")\ncm_100_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5752  955\n         1  626 3884\n                                          \n               Accuracy : 0.8591          \n                 95% CI : (0.8525, 0.8654)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7103          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9019          \n            Specificity : 0.8026          \n         Pos Pred Value : 0.8576          \n         Neg Pred Value : 0.8612          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5128          \n   Detection Prevalence : 0.5979          \n      Balanced Accuracy : 0.8522          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_100_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_100)\n\ncm &lt;- confusionMatrix(pred_col_100, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_100\"] &lt;- NA\n\nf1_score.df[\"1\",\"pred_col_100\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_100)\n\n\n\n\n\n\n\ngwRF_adaptive_150 &lt;- read_rds(\"data/rds/gwRF_adaptive_150.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_150 &lt;- predict.grf(gwRF_adaptive_150,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_150, \"data/rds/gwRF_pred_150_0.rds\")\n\ngwRF_pred_150 &lt;- read_rds(\"data/rds/gwRF_pred_150_0.rds\")\n\npred_col_150 &lt;- ifelse(gwRF_pred_150 &gt; 0.5, 1, 0)\npred_col_150 &lt;- factor(pred_col_150)\n\ncm_150_0 &lt;- confusionMatrix(pred_col_150, test_col)\nwrite_rds(cm_150_0, \"data/rds/cm_150_0.rds\")\n\nrm(gwRF_pred_150) \n\n\ncm_150_0 &lt;- read_rds(\"data/rds/cm_150_0.rds\")\ncm_150_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_150_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_150)\n\ncm &lt;- confusionMatrix(pred_col_150, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_150\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_150\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_150 &lt;- predict.grf(gwRF_adaptive_150,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_150, \"data/rds/gwRF_pred_150_0.25.rds\")\n\ngwRF_pred_150 &lt;- read_rds(\"data/rds/gwRF_pred_150_0.25.rds\")\n\npred_col_150 &lt;- ifelse(gwRF_pred_150 &gt; 0.5, 1, 0)\npred_col_150 &lt;- factor(pred_col_150)\n\ncm_150_0.25 &lt;- confusionMatrix(pred_col_150, test_col)\nwrite_rds(cm_150_0.25, \"data/rds/cm_150_0.25.rds\")\n\nrm(gwRF_pred_150)\n\n\ncm_150_0.25 &lt;- read_rds(\"data/rds/cm_150_0.25.rds\")\ncm_150_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5779  930\n         1  599 3909\n                                        \n               Accuracy : 0.8637        \n                 95% CI : (0.8572, 0.87)\n    No Information Rate : 0.5686        \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16     \n                                        \n                  Kappa : 0.7198        \n                                        \n Mcnemar's Test P-Value : &lt; 2.2e-16     \n                                        \n            Sensitivity : 0.9061        \n            Specificity : 0.8078        \n         Pos Pred Value : 0.8614        \n         Neg Pred Value : 0.8671        \n             Prevalence : 0.5686        \n         Detection Rate : 0.5152        \n   Detection Prevalence : 0.5981        \n      Balanced Accuracy : 0.8569        \n                                        \n       'Positive' Class : 0             \n                                        \n\nrm(cm_150_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_150)\n\ncm &lt;- confusionMatrix(pred_col_150, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_150\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_150 &lt;- predict.grf(gwRF_adaptive_150,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\nwrite_rds(gwRF_pred_150, \"data/rds/gwRF_pred_150_0.5.rds\")\n\ngwRF_pred_150 &lt;- read_rds(\"data/rds/gwRF_pred_150_0.5.rds\")\n\npred_col_150 &lt;- ifelse(gwRF_pred_150 &gt; 0.5, 1, 0)\npred_col_150 &lt;- factor(pred_col_150)\n\ncm_150_0.5 &lt;- confusionMatrix(pred_col_150, test_col)\nwrite_rds(cm_150_0.5, \"data/rds/cm_150_0.5.rds\")\nrm(gwRF_pred_150)\n\n\ncm_150_0.5 &lt;- read_rds(\"data/rds/cm_150_0.5.rds\")\ncm_150_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5804  848\n         1  574 3991\n                                          \n               Accuracy : 0.8732          \n                 95% CI : (0.8669, 0.8793)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7398          \n                                          \n Mcnemar's Test P-Value : 4.501e-13       \n                                          \n            Sensitivity : 0.9100          \n            Specificity : 0.8248          \n         Pos Pred Value : 0.8725          \n         Neg Pred Value : 0.8743          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5174          \n   Detection Prevalence : 0.5930          \n      Balanced Accuracy : 0.8674          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_150_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_150)\n\ncm &lt;- confusionMatrix(pred_col_150, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_150\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_150 &lt;- predict.grf(gwRF_adaptive_150,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_150, \"data/rds/gwRF_pred_150_0.75.rds\")\n\ngwRF_pred_150 &lt;- read_rds(\"data/rds/gwRF_pred_150_0.75.rds\")\n\npred_col_150 &lt;- ifelse(gwRF_pred_150 &gt; 0.5, 1, 0)\npred_col_150 &lt;- factor(pred_col_150)\n\ncm_150_0.75 &lt;- confusionMatrix(pred_col_150, test_col)\nwrite_rds(cm_150_0.75, \"data/rds/cm_150_0.75.rds\")\n\nrm(gwRF_pred_150)\n\n\ncm_150_0.75 &lt;- read_rds(\"data/rds/cm_150_0.75.rds\")\ncm_150_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5799  860\n         1  579 3979\n                                          \n               Accuracy : 0.8717          \n                 95% CI : (0.8654, 0.8778)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7367          \n                                          \n Mcnemar's Test P-Value : 1.569e-13       \n                                          \n            Sensitivity : 0.9092          \n            Specificity : 0.8223          \n         Pos Pred Value : 0.8709          \n         Neg Pred Value : 0.8730          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5170          \n   Detection Prevalence : 0.5937          \n      Balanced Accuracy : 0.8657          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_150_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_150)\n\ncm &lt;- confusionMatrix(pred_col_150, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_150\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_150 &lt;- predict.grf(gwRF_adaptive_150,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_150, \"data/rds/gwRF_pred_150_1.rds\")\n\ngwRF_pred_150 &lt;- read_rds(\"data/rds/gwRF_pred_150_1.rds\")\n\npred_col_150 &lt;- ifelse(gwRF_pred_150 &gt; 0.5, 1, 0)\npred_col_150 &lt;- factor(pred_col_150)\n\ncm_150_1 &lt;- confusionMatrix(pred_col_150, test_col)\nwrite_rds(cm_150_1, \"data/rds/cm_150_1.rds\")\n\nrm(gwRF_pred_150)\n\n\ncm_150_1 &lt;- read_rds(\"data/rds/cm_150_1.rds\")\ncm_150_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5761  926\n         1  617 3913\n                                          \n               Accuracy : 0.8624          \n                 95% CI : (0.8559, 0.8688)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7174          \n                                          \n Mcnemar's Test P-Value : 4.472e-15       \n                                          \n            Sensitivity : 0.9033          \n            Specificity : 0.8086          \n         Pos Pred Value : 0.8615          \n         Neg Pred Value : 0.8638          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5136          \n   Detection Prevalence : 0.5961          \n      Balanced Accuracy : 0.8559          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_150_1)\n\n\npred_weight_1 &lt;- pred_weight_1[, -which(colnames(pred_weight_1) == \"pred_col_150\")]\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_150)\n\ncm &lt;- confusionMatrix(pred_col_150, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_150\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_150)\n\n\n\n\n\n\n\ngwRF_adaptive_200 &lt;- read_rds(\"data/rds/gwRF_adaptive_200.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_200 &lt;- predict.grf(gwRF_adaptive_200,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\nwrite_rds(gwRF_pred_200, \"data/rds/gwRF_pred_200_0.rds\")\n\ngwRF_pred_200 &lt;- read_rds(\"data/rds/gwRF_pred_200_0.rds\")\n\npred_col_200 &lt;- ifelse(gwRF_pred_200 &gt; 0.5, 1, 0)\npred_col_200 &lt;- factor(pred_col_200)\n\ncm_200_0 &lt;- confusionMatrix(pred_col_200, test_col)\nwrite_rds(cm_200_0, \"data/rds/cm_200_0.rds\")\nrm(gwRF_pred_200)\n\n\ncm_200_0 &lt;- read_rds(\"data/rds/cm_200_0.rds\")\ncm_200_0\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5710 1029\n         1  668 3810\n                                          \n               Accuracy : 0.8487          \n                 95% CI : (0.8419, 0.8553)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.6888          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.8953          \n            Specificity : 0.7874          \n         Pos Pred Value : 0.8473          \n         Neg Pred Value : 0.8508          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5090          \n   Detection Prevalence : 0.6008          \n      Balanced Accuracy : 0.8413          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_200_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_200)\n\ncm &lt;- confusionMatrix(pred_col_200, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_200\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_200\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_200 &lt;- predict.grf(gwRF_adaptive_200,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_200, \"data/rds/gwRF_pred_200_0.25.rds\")\n\ngwRF_pred_200 &lt;- read_rds(\"data/rds/gwRF_pred_200_0.25.rds\")\n\npred_col_200 &lt;- ifelse(gwRF_pred_200 &gt; 0.5, 1, 0)\npred_col_200 &lt;- factor(pred_col_200)\n\ncm_200_0.25 &lt;- confusionMatrix(pred_col_200, test_col)\nwrite_rds(cm_200_0.25, \"data/rds/cm_200_0.25.rds\")\n\nrm(gwRF_pred_200)\n\n\ncm_200_0.25 &lt;- read_rds(\"data/rds/cm_200_0.25.rds\")\ncm_200_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5776  941\n         1  602 3898\n                                          \n               Accuracy : 0.8624          \n                 95% CI : (0.8559, 0.8688)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7172          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9056          \n            Specificity : 0.8055          \n         Pos Pred Value : 0.8599          \n         Neg Pred Value : 0.8662          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5149          \n   Detection Prevalence : 0.5988          \n      Balanced Accuracy : 0.8556          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_200_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_200)\n\ncm &lt;- confusionMatrix(pred_col_200, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_200\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_200 &lt;- predict.grf(gwRF_adaptive_200,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\nwrite_rds(gwRF_pred_200, \"data/rds/gwRF_pred_200_0.5.rds\")\n\ngwRF_pred_200 &lt;- read_rds(\"data/rds/gwRF_pred_200_0.5.rds\")\n\npred_col_200 &lt;- ifelse(gwRF_pred_200 &gt; 0.5, 1, 0)\npred_col_200 &lt;- factor(pred_col_200)\n\ncm_200_0.5 &lt;- confusionMatrix(pred_col_200, test_col)\nwrite_rds(cm_200_0.5, \"data/rds/cm_200_0.5.rds\")\nrm(gwRF_pred_200)\n\n\ncm_200_0.5 &lt;- read_rds(\"data/rds/cm_200_0.5.rds\")\ncm_200_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5827  861\n         1  551 3978\n                                          \n               Accuracy : 0.8741          \n                 95% CI : (0.8678, 0.8802)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7414          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9136          \n            Specificity : 0.8221          \n         Pos Pred Value : 0.8713          \n         Neg Pred Value : 0.8783          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5195          \n   Detection Prevalence : 0.5962          \n      Balanced Accuracy : 0.8678          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_200_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_200)\n\ncm &lt;- confusionMatrix(pred_col_200, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_200\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_200 &lt;- predict.grf(gwRF_adaptive_200,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\n\nwrite_rds(gwRF_pred_200, \"data/rds/gwRF_pred_200_0.75.rds\")\n\ngwRF_pred_200 &lt;- read_rds(\"data/rds/gwRF_pred_200_0.75.rds\")\n\npred_col_200 &lt;- ifelse(gwRF_pred_200 &gt; 0.5, 1, 0)\npred_col_200 &lt;- factor(pred_col_200)\n\ncm_200_0.75 &lt;- confusionMatrix(pred_col_200, test_col)\nwrite_rds(cm_200_0.75, \"data/rds/cm_200_0.75.rds\")\n\nrm(gwRF_pred_200)\n\n\ncm_200_0.75 &lt;- read_rds(\"data/rds/cm_200_0.75.rds\")\ncm_200_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5821  841\n         1  557 3998\n                                          \n               Accuracy : 0.8754          \n                 95% CI : (0.8691, 0.8814)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7441          \n                                          \n Mcnemar's Test P-Value : 3.764e-14       \n                                          \n            Sensitivity : 0.9127          \n            Specificity : 0.8262          \n         Pos Pred Value : 0.8738          \n         Neg Pred Value : 0.8777          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5189          \n   Detection Prevalence : 0.5939          \n      Balanced Accuracy : 0.8694          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_200_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_200)\n\ncm &lt;- confusionMatrix(pred_col_200, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_200\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_200 &lt;- predict.grf(gwRF_adaptive_200,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_200, \"data/rds/gwRF_pred_200_1.rds\")\n\ngwRF_pred_200 &lt;- read_rds(\"data/rds/gwRF_pred_200_1.rds\")\n\npred_col_200 &lt;- ifelse(gwRF_pred_200 &gt; 0.5, 1, 0)\npred_col_200 &lt;- factor(pred_col_200)\n\ncm_200_1 &lt;- confusionMatrix(pred_col_200, test_col)\nwrite_rds(cm_200_1, \"data/rds/cm_200_1.rds\")\nrm(gwRF_pred_200)\n\n\ncm_200_1 &lt;- read_rds(\"data/rds/cm_200_1.rds\")\ncm_200_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5796  887\n         1  582 3952\n                                          \n               Accuracy : 0.869           \n                 95% CI : (0.8627, 0.8752)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.731           \n                                          \n Mcnemar's Test P-Value : 2.163e-15       \n                                          \n            Sensitivity : 0.9087          \n            Specificity : 0.8167          \n         Pos Pred Value : 0.8673          \n         Neg Pred Value : 0.8716          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5167          \n   Detection Prevalence : 0.5958          \n      Balanced Accuracy : 0.8627          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_200_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_200)\n\ncm &lt;- confusionMatrix(pred_col_200, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_200\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_200)\n\n\n\n\n\n\n\ngwRF_adaptive_250 &lt;- read_rds(\"data/rds/gwRF_adaptive_250.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_250 &lt;- predict.grf(gwRF_adaptive_250,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_250, \"data/rds/gwRF_pred_250_0.rds\")\n\ngwRF_pred_250 &lt;- read_rds(\"data/rds/gwRF_pred_250_0.rds\")\n\npred_col_250 &lt;- ifelse(gwRF_pred_250 &gt; 0.5, 1, 0)\npred_col_250 &lt;- factor(pred_col_250)\n\ncm_250_0 &lt;- confusionMatrix(pred_col_250, test_col)\nwrite_rds(cm_250_0, \"data/rds/cm_250_0.rds\")\nrm(gwRF_pred_250)\n\n\ncm_250_0 &lt;- read_rds(\"data/rds/cm_250_0.rds\")\ncm_250_0\nrm(cm_250_0)\n\n\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_250)\n\ncm &lt;- confusionMatrix(pred_col_250, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_250\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_250\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_250 &lt;- predict.grf(gwRF_adaptive_250,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\nwrite_rds(gwRF_pred_250, \"data/rds/gwRF_pred_250_0.25.rds\")\n\ngwRF_pred_250 &lt;- read_rds(\"data/rds/gwRF_pred_250_0.25.rds\")\n\npred_col_250 &lt;- ifelse(gwRF_pred_250 &gt; 0.5, 1, 0)\npred_col_250 &lt;- factor(pred_col_250)\n\ncm_250_0 &lt;- confusionMatrix(pred_col_250, test_col)\nwrite_rds(cm_250_0, \"data/rds/cm_250_0.25.rds\")\nrm(gwRF_pred_250)\n\n\ncm_250_0.25 &lt;- read_rds(\"data/rds/cm_250_0.25.rds\")\ncm_250_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5765  953\n         1  613 3886\n                                          \n               Accuracy : 0.8604          \n                 95% CI : (0.8538, 0.8668)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.713           \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9039          \n            Specificity : 0.8031          \n         Pos Pred Value : 0.8581          \n         Neg Pred Value : 0.8637          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5140          \n   Detection Prevalence : 0.5989          \n      Balanced Accuracy : 0.8535          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_250_0.25)\n\n\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_250)\n\ncm &lt;- confusionMatrix(pred_col_250, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_250\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_250 &lt;- predict.grf(gwRF_adaptive_250,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_250, \"data/rds/gwRF_pred_250_0.5.rds\")\n\ngwRF_pred_250 &lt;- read_rds(\"data/rds/gwRF_pred_250_0.5.rds\")\n\npred_col_250 &lt;- ifelse(gwRF_pred_250 &gt; 0.5, 1, 0)\npred_col_250 &lt;- factor(pred_col_250)\n\ncm_250_0.5 &lt;- confusionMatrix(pred_col_250, test_col)\nwrite_rds(cm_250_0.5, \"data/rds/cm_250_0.5.rds\")\nrm(gwRF_pred_250)\n\n\ncm_250_0.5 &lt;- read_rds(\"data/rds/cm_250_0.5.rds\")\ncm_250_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5810  867\n         1  568 3972\n                                          \n               Accuracy : 0.8721          \n                 95% CI : (0.8657, 0.8782)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7373          \n                                          \n Mcnemar's Test P-Value : 3.642e-15       \n                                          \n            Sensitivity : 0.9109          \n            Specificity : 0.8208          \n         Pos Pred Value : 0.8702          \n         Neg Pred Value : 0.8749          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5180          \n   Detection Prevalence : 0.5953          \n      Balanced Accuracy : 0.8659          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_250_0.5)\n\n\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_250)\n\ncm &lt;- confusionMatrix(pred_col_250, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_250\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_250 &lt;- predict.grf(gwRF_adaptive_250,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_250, \"data/rds/gwRF_pred_250_0.75.rds\")\n\ngwRF_pred_250 &lt;- read_rds(\"data/rds/gwRF_pred_250_0.75.rds\")\n\npred_col_250 &lt;- ifelse(gwRF_pred_250 &gt; 0.5, 1, 0)\npred_col_250 &lt;- factor(pred_col_250)\n\ncm_250_0.75 &lt;- confusionMatrix(pred_col_250, test_col)\nwrite_rds(cm_250_0.75, \"data/rds/cm_250_0.75.rds\")\nrm(gwRF_pred_250)\n\n\ncm_250_0.75 &lt;- read_rds(\"data/rds/cm_250_0.75.rds\")\ncm_250_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5808  843\n         1  570 3996\n                                          \n               Accuracy : 0.874           \n                 95% CI : (0.8677, 0.8801)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7415          \n                                          \n Mcnemar's Test P-Value : 4.622e-13       \n                                          \n            Sensitivity : 0.9106          \n            Specificity : 0.8258          \n         Pos Pred Value : 0.8733          \n         Neg Pred Value : 0.8752          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5178          \n   Detection Prevalence : 0.5929          \n      Balanced Accuracy : 0.8682          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_250_0.75)\n\n\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_250)\n\ncm &lt;- confusionMatrix(pred_col_250, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_250\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_250 &lt;- predict.grf(gwRF_adaptive_250,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\n\nwrite_rds(gwRF_pred_250, \"data/rds/gwRF_pred_250_1.rds\")\n\ngwRF_pred_250 &lt;- read_rds(\"data/rds/gwRF_pred_250_1.rds\")\n\npred_col_250 &lt;- ifelse(gwRF_pred_250 &gt; 0.5, 1, 0)\npred_col_250 &lt;- factor(pred_col_250)\n\ncm_250_1 &lt;- confusionMatrix(pred_col_250, test_col)\nwrite_rds(cm_250_1, \"data/rds/cm_250_1.rds\")\nrm(gwRF_pred_250)\n\n\ncm_250_1 &lt;- read_rds(\"data/rds/cm_250_1.rds\")\ncm_250_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5790  879\n         1  588 3960\n                                          \n               Accuracy : 0.8692          \n                 95% CI : (0.8628, 0.8754)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7315          \n                                          \n Mcnemar's Test P-Value : 3.689e-14       \n                                          \n            Sensitivity : 0.9078          \n            Specificity : 0.8184          \n         Pos Pred Value : 0.8682          \n         Neg Pred Value : 0.8707          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5162          \n   Detection Prevalence : 0.5945          \n      Balanced Accuracy : 0.8631          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_250_1)\n\n\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_250)\n\ncm &lt;- confusionMatrix(pred_col_250, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_250\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_250)\n\n\n\n\n\n\n\ngwRF_adaptive_300 &lt;- read_rds(\"data/rds/gwRF_adaptive_300.rds\")\n#f1_score.df &lt;- read_rds(\"data/rds/f1_score.df.rds\")\n\n\n\n\n\n\n\nLocal Weight: 0\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_300 &lt;- predict.grf(gwRF_adaptive_300,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0,\n                             global.w=1)\n\nwrite_rds(gwRF_pred_300, \"data/rds/gwRF_pred_300_0.rds\")\n\ngwRF_pred_300 &lt;- read_rds(\"data/rds/gwRF_pred_300_0.rds\")\n\npred_col_300 &lt;- ifelse(gwRF_pred_300 &gt; 0.5, 1, 0)\npred_col_300 &lt;- factor(pred_col_300)\n\ncm_300_0 &lt;- confusionMatrix(pred_col_300, test_col)\nwrite_rds(cm_300_0, \"data/rds/cm_300_0.rds\")\nrm(gwRF_pred_300)\n\n\ncm_300_0 &lt;- read_rds(\"data/rds/cm_300_0.rds\")\ncm_300_0\nrm(cm_300_0)\n\n\n#pred_weight_0 &lt;- as.data.frame(pred_col_300)\npred_weight_0 &lt;- cbind(pred_weight_0,pred_col_300)\n\ncm &lt;- confusionMatrix(pred_col_300, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[,\"pred_col_300\"] &lt;- NA\n\nf1_score.df[\"0\",\"pred_col_300\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.25\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_300 &lt;- predict.grf(gwRF_adaptive_300,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.25,\n                             global.w=0.75)\n\n\nwrite_rds(gwRF_pred_300, \"data/rds/gwRF_pred_300_0.25.rds\")\n\ngwRF_pred_300 &lt;- read_rds(\"data/rds/gwRF_pred_300_0.25.rds\")\n\npred_col_300 &lt;- ifelse(gwRF_pred_300 &gt; 0.5, 1, 0)\npred_col_300 &lt;- factor(pred_col_300)\n\ncm_300_0.25 &lt;- confusionMatrix(pred_col_300, test_col)\nwrite_rds(cm_300_0.25, \"data/rds/cm_300_0.25.rds\")\nrm(gwRF_pred_300)\n\n\ncm_300_0.25 &lt;- read_rds(\"data/rds/cm_300_0.25.rds\")\ncm_300_0.25\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5762  949\n         1  616 3890\n                                          \n               Accuracy : 0.8605          \n                 95% CI : (0.8539, 0.8668)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7132          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9034          \n            Specificity : 0.8039          \n         Pos Pred Value : 0.8586          \n         Neg Pred Value : 0.8633          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5137          \n   Detection Prevalence : 0.5983          \n      Balanced Accuracy : 0.8537          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_300_0.25)\n\n\npred_weight_0.25 &lt;- as.data.frame(pred_col_300)\npred_weight_0.25 &lt;- cbind(pred_weight_0.25,pred_col_300)\n\ncm &lt;- confusionMatrix(pred_col_300, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.25\",\"pred_col_300\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.5\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_300 &lt;- predict.grf(gwRF_adaptive_300,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.5,\n                             global.w=0.5)\n\nwrite_rds(gwRF_pred_300, \"data/rds/gwRF_pred_300_0.5.rds\")\n\ngwRF_pred_300 &lt;- read_rds(\"data/rds/gwRF_pred_300_0.5.rds\")\n\npred_col_300 &lt;- ifelse(gwRF_pred_300 &gt; 0.5, 1, 0)\npred_col_300 &lt;- factor(pred_col_300)\n\ncm_300_0.5 &lt;- confusionMatrix(pred_col_300, test_col)\nwrite_rds(cm_300_0.5, \"data/rds/cm_300_0.5.rds\")\nrm(gwRF_pred_300)\n\n\ncm_300_0.5 &lt;- read_rds(\"data/rds/cm_300_0.5.rds\")\ncm_300_0.5\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5812  885\n         1  566 3954\n                                          \n               Accuracy : 0.8706          \n                 95% CI : (0.8643, 0.8768)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7342          \n                                          \n Mcnemar's Test P-Value : &lt; 2.2e-16       \n                                          \n            Sensitivity : 0.9113          \n            Specificity : 0.8171          \n         Pos Pred Value : 0.8679          \n         Neg Pred Value : 0.8748          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5181          \n   Detection Prevalence : 0.5970          \n      Balanced Accuracy : 0.8642          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_300_0.5)\n\n\npred_weight_0.5 &lt;- as.data.frame(pred_col_300)\npred_weight_0.5 &lt;- cbind(pred_weight_0.5,pred_col_300)\n\ncm &lt;- confusionMatrix(pred_col_300, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.5\",\"pred_col_300\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 0.75\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_300 &lt;- predict.grf(gwRF_adaptive_300,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=0.75,\n                             global.w=0.25)\n\nwrite_rds(gwRF_pred_300, \"data/rds/gwRF_pred_300_0.75.rds\")\n\ngwRF_pred_300 &lt;- read_rds(\"data/rds/gwRF_pred_300_0.75.rds\")\n\npred_col_300 &lt;- ifelse(gwRF_pred_300 &gt; 0.5, 1, 0)\npred_col_300 &lt;- factor(pred_col_300)\n\ncm_300_0.75 &lt;- confusionMatrix(pred_col_300, test_col)\nwrite_rds(cm_300_0.75, \"data/rds/cm_300_0.75.rds\")\nrm(gwRF_pred_300)\n\n\ncm_300_0.75 &lt;- read_rds(\"data/rds/cm_300_0.75.rds\")\ncm_300_0.75\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5805  861\n         1  573 3978\n                                          \n               Accuracy : 0.8722          \n                 95% CI : (0.8658, 0.8783)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7375          \n                                          \n Mcnemar's Test P-Value : 3.484e-14       \n                                          \n            Sensitivity : 0.9102          \n            Specificity : 0.8221          \n         Pos Pred Value : 0.8708          \n         Neg Pred Value : 0.8741          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5175          \n   Detection Prevalence : 0.5943          \n      Balanced Accuracy : 0.8661          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_300_0.75)\n\n\npred_weight_0.75 &lt;- as.data.frame(pred_col_300)\npred_weight_0.75 &lt;- cbind(pred_weight_0.75,pred_col_300)\n\ncm &lt;- confusionMatrix(pred_col_300, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"0.75\",\"pred_col_300\"] &lt;- f1_score\n\n\n\n\n\n\n\n\n\n\nLocal Weight: 1\n\n\n\n\n\n\nset.seed(1234)\ngwRF_pred_300 &lt;- predict.grf(gwRF_adaptive_300,\n                             testing_data,\n                             x.var.name=\"X\",\n                             y.var.name=\"Y\",\n                             local.w=1,\n                             global.w=0)\n\nwrite_rds(gwRF_pred_300, \"data/rds/gwRF_pred_300_1.rds\")\n\ngwRF_pred_300 &lt;- read_rds(\"data/rds/gwRF_pred_300_1.rds\")\n\npred_col_300 &lt;- ifelse(gwRF_pred_300 &gt; 0.5, 1, 0)\npred_col_300 &lt;- factor(pred_col_300)\n\ncm_300_1 &lt;- confusionMatrix(pred_col_300, test_col)\nwrite_rds(cm_300_1, \"data/rds/cm_300_1.rds\")\nrm(gwRF_pred_300)\n\n\ncm_300_1 &lt;- read_rds(\"data/rds/cm_300_1.rds\")\ncm_300_1\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction    0    1\n         0 5783  879\n         1  595 3960\n                                          \n               Accuracy : 0.8686          \n                 95% CI : (0.8622, 0.8748)\n    No Information Rate : 0.5686          \n    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       \n                                          \n                  Kappa : 0.7302          \n                                          \n Mcnemar's Test P-Value : 1.691e-13       \n                                          \n            Sensitivity : 0.9067          \n            Specificity : 0.8184          \n         Pos Pred Value : 0.8681          \n         Neg Pred Value : 0.8694          \n             Prevalence : 0.5686          \n         Detection Rate : 0.5156          \n   Detection Prevalence : 0.5939          \n      Balanced Accuracy : 0.8625          \n                                          \n       'Positive' Class : 0               \n                                          \n\nrm(cm_300_1)\n\n\npred_weight_1 &lt;- as.data.frame(pred_col_300)\npred_weight_1 &lt;- cbind(pred_weight_1,pred_col_300)\n\ncm &lt;- confusionMatrix(pred_col_300, test_col)\n\ntp &lt;- cm$table[2, 2]  # True Positives\nfp &lt;- cm$table[1, 2]  # False Positives\nfn &lt;- cm$table[2, 1]  # False Negatives\n\nprecision &lt;- tp / (tp + fp)\nrecall &lt;- tp / (tp + fn)\nf1_score &lt;- 2 * (precision*recall) / (precision + recall)\n\nf1_score.df[\"1\",\"pred_col_300\"] &lt;- f1_score\n\n\nrm(gwRF_adaptive_300)"
  },
  {
    "objectID": "predictivemodelling.html#plotting-gwrf-model-prediction-accuracy-at-incrementing-weight-standardised-bandwidth",
    "href": "predictivemodelling.html#plotting-gwrf-model-prediction-accuracy-at-incrementing-weight-standardised-bandwidth",
    "title": "Machine Learning Modelling",
    "section": "7.6 Plotting GWRF Model Prediction Accuracy at Incrementing Weight & Standardised Bandwidth",
    "text": "7.6 Plotting GWRF Model Prediction Accuracy at Incrementing Weight & Standardised Bandwidth\nIn this section, we are plotting the prediction accuracy of the GWRF models at incrementing weight parameters and standardised bandwidths. The weight parameters range from 0 to 1 in increments of 0.25, and the standardised bandwidths used are 50, 100, 150, 200, 250, and 300.\nThe code chunk below creates a data frame with all combinations of weights and bandwidths, adds the accuracy values for each combination, and then creates a line plot of the accuracy against the bandwidth for each weight.\n\nweights &lt;- c(\"0\", \"0.25\", \"0.50\", \"0.75\", \"1\")\nbandwidths &lt;- c(50, 100, 150, 200, 250,300)\n\n# Create a data frame with all combinations of weights and bandwidths\ndf_gwRF &lt;- expand.grid(Weight = weights, Bandwidth = bandwidths)\n\n# Add your accuracy values\ndf_gwRF$Accuracy &lt;- c(0.8813, 0.8961, 0.8995, 0.8582, 0.8816,\n                      0.8813, 0.8945, 0.8997, 0.8941, 0.8829,\n                      0.8813, 0.8932, 0.9, 0.8977, 0.8891,\n                      0.8813, 0.891, 0.8991, 0.8985, 0.8931,\n                      0.8813, 0.8902, 0.8959, 0.898, 0.8938,\n                      0.8813, 0.8901, 0.8952, 0.8978, 0.8946)\n\n# Create the plot\nggplot(df_gwRF, aes(x = Bandwidth, y = Accuracy, color = Weight)) +\n  geom_line() +\n  geom_point(shape = 9, size = 2.5) +\n  labs(x = \"Bandwidth\", y = \"Accuracy\", title = \"GWRF Model Prediction Accuracy \\nat Incrementing Weight & Standardised Bandwidth\") +\n  scale_x_continuous(breaks = c(50, 100, 150, 200, 250)) +\n  scale_y_continuous(limits = c(0.84, 0.911)) +\n  scale_color_manual(values = c(\"#e4c838\", \"#de573e\", \"#b977cb\", \"#4225df\", \"#32c962\")) +\n  theme_minimal() +\n  theme(\n    panel.grid = element_blank(),  # Remove internal grid lines\n    panel.border = element_rect(color = \"black\", fill = NA),\n    plot.title = element_text(hjust = 0.5),\n    legend.position = \"bottom\"\n  )\n\n\n\n\n\nwrite_rds(f1_score.df, \"data/rds/f1_score.df.rds\")\nwrite_rds(pred_weight_0, \"data/rds/pred_weight_0.rds\")\nwrite_rds(pred_weight_0.25, \"data/rds/pred_weight_0.25.rds\")\nwrite_rds(pred_weight_0.5, \"data/rds/pred_weight_0.5.rds\")\nwrite_rds(pred_weight_0.75, \"data/rds/pred_weight_0.75.rds\")\nwrite_rds(pred_weight_1, \"data/rds/pred_weight_1.rds\")"
  },
  {
    "objectID": "predictivemodelling.html#creating-raster-layer",
    "href": "predictivemodelling.html#creating-raster-layer",
    "title": "Machine Learning Modelling",
    "section": "8.1 Creating Raster Layer",
    "text": "8.1 Creating Raster Layer\nThe terra::rast() function is used to create a raster layer from the valtellina object with 700 rows and 1066 columns.\n\ngrid &lt;- terra::rast(valtellina, \n                    nrows = 700, \n                    ncols = 1066)\ngrid\n\nclass       : SpatRaster \ndimensions  : 700, 1066, 1  (nrow, ncol, nlyr)\nresolution  : 99.94376, 99.91744  (x, y)\nextent      : 518970, 625510, 5095447, 5165389  (xmin, xmax, ymin, ymax)\ncoord. ref. : WGS 84 / UTM zone 32N (EPSG:32632)"
  },
  {
    "objectID": "predictivemodelling.html#extracting-cell-coordinates",
    "href": "predictivemodelling.html#extracting-cell-coordinates",
    "title": "Machine Learning Modelling",
    "section": "8.2 Extracting Cell Coordinates",
    "text": "8.2 Extracting Cell Coordinates\nThe terra::xyFromCell() function is used to extract the x and y coordinates of each cell in the raster layer.\n\nxy &lt;- terra::xyFromCell(grid, \n                        1:ncell(grid))\nhead(xy)\n\n            x       y\n[1,] 519019.9 5165339\n[2,] 519119.9 5165339\n[3,] 519219.8 5165339\n[4,] 519319.8 5165339\n[5,] 519419.7 5165339\n[6,] 519519.7 5165339"
  },
  {
    "objectID": "predictivemodelling.html#creating-spatal-data-frame",
    "href": "predictivemodelling.html#creating-spatal-data-frame",
    "title": "Machine Learning Modelling",
    "section": "8.3 Creating Spatal Data Frame",
    "text": "8.3 Creating Spatal Data Frame\nThe st_as_sf() function from the sf package is used to convert the data frame of coordinates into a spatial data frame. The st_filter() function is then used to keep only the points that fall within the valtellina region.\n\ncoop &lt;- st_as_sf(as.data.frame(xy), \n                 coords = c(\"x\", \"y\"),\n                 crs = st_crs(valtellina))\ncoop &lt;- st_filter(coop, valtellina)\nhead(coop)\n\nSimple feature collection with 6 features and 0 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 594477.5 ymin: 5165139 xmax: 594877.2 ymax: 5165339\nProjected CRS: WGS 84 / UTM zone 32N\n                  geometry\n1 POINT (594777.3 5165339)\n2 POINT (594877.2 5165339)\n3 POINT (594677.4 5165239)\n4 POINT (594777.3 5165239)\n5 POINT (594877.2 5165239)\n6 POINT (594477.5 5165139)"
  },
  {
    "objectID": "predictivemodelling.html#variogram",
    "href": "predictivemodelling.html#variogram",
    "title": "Machine Learning Modelling",
    "section": "8.4 Variogram",
    "text": "8.4 Variogram\nA variogram is a tool used in geostatistics to quantify the spatial autocorrelation of a variable. It provides a visual depiction of the covariance exhibited between each pair of points in the sampled data. For each pair of points in the sampled data, the “semivariance” is plotted against the distance between the pairs.\nThe variogram function from the gstat package in R is used to calculate the empirical variogram of the data. The fit.variogram function is then used to fit a theoretical variogram model to this empirical variogram. The vgm function is used to specify the theoretical variogram model to fit.\nThe psill parameter is the maximum semivariance value, also known as the sill. The model parameter specifies the type of variogram model to use, in this case, a spherical model. The range parameter is the distance at which the semivariance reaches the specified sill. The nugget parameter represents the variance at zero distance, accounting for measurement errors or spatial sources of variation at distances smaller than the sampling interval.\nSpherical variogram models are commonly used in geostatistical applications as they often have a similar shape to empirical variograms.\nHere is the code chunk that accomplishes this:\n\nv &lt;- variogram(Predicted ~ 1, \n               data = testing_data_sf)\nplot(v)\n\n\n\n\n\nfv &lt;- fit.variogram(object = v,\n                    model = vgm(\n                      psill = 0.5, \n                      model = \"Sph\",\n                      range = 5000, \n                      nugget = 0.1))\nfv\n\n  model      psill    range\n1   Nug 0.06388633    0.000\n2   Sph 0.04660956 9148.716\n\n\n\nplot(v, fv)"
  },
  {
    "objectID": "predictivemodelling.html#creating-krige-object",
    "href": "predictivemodelling.html#creating-krige-object",
    "title": "Machine Learning Modelling",
    "section": "8.5 Creating Krige Object",
    "text": "8.5 Creating Krige Object\nIn this code chunk, we create a gstat object named k using the gstat function. This object represents a geostatistical model that we’ll use for Kriging. The formula Predicted ~ 1 specifies that we’re modeling the Predicted variable as a function of a constant (i.e., we’re fitting a mean model). The data argument is set to testing_data_sf. The model argument is set to fv.\n\nk &lt;- gstat(formula = Predicted ~ 1, \n           data = testing_data_sf, \n           model = fv)\nk"
  },
  {
    "objectID": "predictivemodelling.html#prediction-with-krige-object",
    "href": "predictivemodelling.html#prediction-with-krige-object",
    "title": "Machine Learning Modelling",
    "section": "8.6 Prediction with Krige Object",
    "text": "8.6 Prediction with Krige Object\nIn this code chunk, we use the predict function to make predictions from the Kriging model k for the locations specified in coop. The predictions are stored in resp. We then extract the x and y coordinates and the predicted values from resp.\n\nresp &lt;- predict(k, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\nresp$pred &lt;- resp$pred\nresp"
  },
  {
    "objectID": "predictivemodelling.html#rasterizing-predictions",
    "href": "predictivemodelling.html#rasterizing-predictions",
    "title": "Machine Learning Modelling",
    "section": "8.7 Rasterizing Predictions",
    "text": "8.7 Rasterizing Predictions\nIn this code chunk, we rasterize the predictions resp onto the raster grid grid using the terra::rasterize function. The rasterized predictions are stored in kpred.\n\nkpred &lt;- terra::rasterize(resp, grid, \n                         field = \"pred\")\n\nNow we will save kpred for later use.\n\nwriteRaster(kpred, \"data/raster/kpred.tif\", filetype=\"GTIFF\")"
  },
  {
    "objectID": "predictivemodelling.html#creating-spatial-interpolated-map",
    "href": "predictivemodelling.html#creating-spatial-interpolated-map",
    "title": "Machine Learning Modelling",
    "section": "8.8 Creating Spatial Interpolated Map",
    "text": "8.8 Creating Spatial Interpolated Map\nNow that we have the data ready, we use appropriate tmap functions to create a map.\n\ntmap_options(check.and.fix = TRUE)\ntmap_mode(\"plot\")\n\ntmap mode set to plotting\n\ntm_shape(kpred) + \n  tm_raster(alpha = 1, \n            palette = \"-RdYlGn\",\n            title = \"Probability of Landslides\") +\n  tm_layout(main.title = \"Landslide Susceptibility Map (GWRF)\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project is submitted to the Singapore Management University in partial fulfillment of the requirements for the degree of Bachelor of Science (Information Systems) Smart-City Management and Technology major under IS485 IS Project Experience (SMT Research).\n\nCo-Authors\n\nKhant Min Naing\nKhant is a final year student at SMU, double-majoring in Smart City Management & Technology (SMT) and Public Policy & Public Management (PPPM). His research interests are centered around urban science, geospatial technology, and public policy. He has a particular interest in the challenges and opportunities presented by Southeast Asian urbanism. Khant is keen on leveraging data science and analytics to understand the dynamics of cities, communities, and natural environments in Southeast Asian cities.\nContact\nmnkhant.2020@scis.smu.edu.sg\nSingapore Management University\n\n\n\n\n\nVictoria Grace Ann\nVictoria is a penultimate-year student specializing in Smart City Management and Technology at SMU. She is deeply interested in the intersection of healthcare, public policy, and geographical information systems. These areas provide her with a comprehensive perspective on the social issues she is passionate about. Victoria is driven to become a social enabler, leveraging data-driven insights to make a meaningful impact.\nContact\nvictoriaann.2021@scis.smu.edu.sg\nSingapore Management University\n\n\n\n\n\n\nSupervisor\n\nAssociate Professor Kam Tin Seong\ntskam@smu.edu.sg\nSingapore Management University\n\nSubmitted to"
  },
  {
    "objectID": "data/aspatial/train_grid_v5.html",
    "href": "data/aspatial/train_grid_v5.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n                 +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "data/vector/landslide_inventory.html",
    "href": "data/vector/landslide_inventory.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                PROJCRS[“WGS 84 / UTM zone 32N”,BASEGEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],ID[“EPSG”,4326]],CONVERSION[“UTM zone 32N”,METHOD[“Transverse Mercator”,ID[“EPSG”,9807]],PARAMETER[“Latitude of natural origin”,0,ANGLEUNIT[“degree”,0.0174532925199433],ID[“EPSG”,8801]],PARAMETER[“Longitude of natural origin”,9,ANGLEUNIT[“degree”,0.0174532925199433],ID[“EPSG”,8802]],PARAMETER[“Scale factor at natural origin”,0.9996,SCALEUNIT[“unity”,1],ID[“EPSG”,8805]],PARAMETER[“False easting”,500000,LENGTHUNIT[“metre”,1],ID[“EPSG”,8806]],PARAMETER[“False northing”,0,LENGTHUNIT[“metre”,1],ID[“EPSG”,8807]]],CS[Cartesian,2],AXIS[“(E)”,east,ORDER[1],LENGTHUNIT[“metre”,1]],AXIS[“(N)”,north,ORDER[2],LENGTHUNIT[“metre”,1]],USAGE[SCOPE[“Engineering survey, topographic mapping.”],AREA[“Between 6°E and 12°E, northern hemisphere between equator and 84°N, onshore and offshore. Algeria. Austria. Cameroon. Denmark. Equatorial Guinea. France. Gabon. Germany. Italy. Libya. Liechtenstein. Monaco. Netherlands. Niger. Nigeria. Norway. Sao Tome and Principe. Svalbard. Sweden. Switzerland. Tunisia. Vatican City State.”],BBOX[0,6,84,12]],ID[“EPSG”,32632]] +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 3116 32632 EPSG:32632 WGS 84 / UTM zone 32N utm EPSG:7030 false"
  },
  {
    "objectID": "studyarea.html",
    "href": "studyarea.html",
    "title": "Study Area",
    "section": "",
    "text": "Study Area Selection\n\nValtellina Valley, Lombardy Region, Italy\n\nValtellina Valley, located in the Central Alps of Northern Italy, is chosen as the study area. The valley extends between 515,000 metres and 620,000 metres in easting (9.24°E to 10.63°E in longitude), and between 5,050,000 metres and 5,170,000 metres in northing (46.00°N to 46.64°N in latitude) and covers about 3308 square kilometres. The average mountain elevation there ranges from 2,500 to 3,000 meters with the bottom of the valley lying about 1000 to 1100 metres above sea level. The valley is cut by the Adda River flowing from North to South and characterized by a superimposed fluvial morphology and high steep slopes, akin to typical alpine glacial valleys [1]. The geomorphological features of the valley exhibit a pronounced contrast between its opposing slopes. The East–West orientation of the valley is also attributed to the geologic fault called the Periadriatic Seam, which imposes tectonic lineament upon the valley [2].\nValtellina valley has experienced significant damage and destruction over the century from landslides such as the historic Valpola landslide and floods. The landslides are mostly attributed to geological instability arising from tectonic and post-glacial conditions [3], soil type, soil moisture and slope acclivity which activate mass movements [4]. Additionally, Valtellina’s wine agriculture like Chiavennasca grapes, popular ski and holiday towns such as Sondrio, Livigno, Aprica, Bormio and Morbegno are highly sort after. The resulting surge in economic activities and overdevelopment of human settlements have extensively remodified the landform’s geomorphology which exacerbate Valtellina’s landslide susceptibility [2-3]. Overall, the region’s steep slopes, heavy rainfall, geological instability and man-made modifications to the natural landscape/ make it an interesting study area for this study.\n\nReferences\n\n\nAlexander, D.: Valtellina landslide and flood emergency, Northern Italy, 1987. Disasters. 12, 212–222 (1988)\nLuino, F., De Graff, J., Biddoccu, M., Faccini, F., Freppaz, M., Roccati, A., Ungaro, F., D’Amico, M., Turconi, L.: The role of soil type in triggering shallow landslides in the Alps (Lombardy, northern Italy). Land. 11, 1125 (2022)\nAzzoni, A., Chiesa, S., Frassoni, A., Govi, M.: The Valpola landslide. Engineering Geology. 33, 59–70 (1992)\nCamera, C., Apuani, T., Masetti, M.: Modeling the stability of terraced slopes: An approach from Valtellina (Northern Italy). Environmental Earth Sciences. 74, 855–868 (2015)"
  }
]