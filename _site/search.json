[
  {
    "objectID": "studyarea.html",
    "href": "studyarea.html",
    "title": "Study Area",
    "section": "",
    "text": "Study Area Selection\n\nValtellina Valley, Lombardy Region, Italy\nValtellina or the Valtelline is a valley in the Lombardy region of northern Italy. The most important comune of the valley is Sondrio; the others major centers are Aprica, Morbegno, Tirano, Chiavenna, Bormio and Livigno.\nNestled between Switzerland and the Lombard plain, the valley’s geographical setting plays a crucial role in its susceptibility to landslides, making it an ideal case study for understanding and mitigating these complex natural hazards.\nGeographic Features:\n\nAlpine Setting: Situated within the collision zone of the European and African plates, the Valtellina Valley experiences ongoing tectonic activity, leading to steep slopes, unstable rock formations, and frequent seismic tremors.\nGlacial Legacy: Past glacial activity sculpted the valley’s topography, resulting in U-shaped valleys, hanging valleys, and over-steepened slopes, all contributing to potential landslide initiation zones.\nHydrological Regimen: The Adda River, fed by abundant alpine meltwater and subject to intense seasonal precipitation, carves into the valley floor, further weakening slopes and contributing to soil saturation, a key trigger for landslides.\nDensely Populated: Despite its rugged terrain, the Valtellina Valley boasts a thriving population, with numerous villages and towns nestled along its slopes and valley floor. This proximity to potential landslides heightens the vulnerability of people and infrastructure."
  },
  {
    "objectID": "data/vector/landslide_inventory.html",
    "href": "data/vector/landslide_inventory.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     dataset\n\n\n                PROJCRS[“WGS 84 / UTM zone 32N”,BASEGEOGCRS[“WGS 84”,ENSEMBLE[“World Geodetic System 1984 ensemble”,MEMBER[“World Geodetic System 1984 (Transit)”],MEMBER[“World Geodetic System 1984 (G730)”],MEMBER[“World Geodetic System 1984 (G873)”],MEMBER[“World Geodetic System 1984 (G1150)”],MEMBER[“World Geodetic System 1984 (G1674)”],MEMBER[“World Geodetic System 1984 (G1762)”],ELLIPSOID[“WGS 84”,6378137,298.257223563,LENGTHUNIT[“metre”,1]],ENSEMBLEACCURACY[2.0]],PRIMEM[“Greenwich”,0,ANGLEUNIT[“degree”,0.0174532925199433]],ID[“EPSG”,4326]],CONVERSION[“UTM zone 32N”,METHOD[“Transverse Mercator”,ID[“EPSG”,9807]],PARAMETER[“Latitude of natural origin”,0,ANGLEUNIT[“degree”,0.0174532925199433],ID[“EPSG”,8801]],PARAMETER[“Longitude of natural origin”,9,ANGLEUNIT[“degree”,0.0174532925199433],ID[“EPSG”,8802]],PARAMETER[“Scale factor at natural origin”,0.9996,SCALEUNIT[“unity”,1],ID[“EPSG”,8805]],PARAMETER[“False easting”,500000,LENGTHUNIT[“metre”,1],ID[“EPSG”,8806]],PARAMETER[“False northing”,0,LENGTHUNIT[“metre”,1],ID[“EPSG”,8807]]],CS[Cartesian,2],AXIS[“(E)”,east,ORDER[1],LENGTHUNIT[“metre”,1]],AXIS[“(N)”,north,ORDER[2],LENGTHUNIT[“metre”,1]],USAGE[SCOPE[“Engineering survey, topographic mapping.”],AREA[“Between 6°E and 12°E, northern hemisphere between equator and 84°N, onshore and offshore. Algeria. Austria. Cameroon. Denmark. Equatorial Guinea. France. Gabon. Germany. Italy. Libya. Liechtenstein. Monaco. Netherlands. Niger. Nigeria. Norway. Sao Tome and Principe. Svalbard. Sweden. Switzerland. Tunisia. Vatican City State.”],BBOX[0,6,84,12]],ID[“EPSG”,32632]] +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 3116 32632 EPSG:32632 WGS 84 / UTM zone 32N utm EPSG:7030 false"
  },
  {
    "objectID": "data/aspatial/train_grid_v5.html",
    "href": "data/aspatial/train_grid_v5.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n                 +proj=utm +zone=32 +datum=WGS84 +units=m +no_defs 0 0     false"
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "In this section, we set up the necessary R packages for data processing and exploratory spatial data analysis. The following packages are downloaded.\nlibrary(sp)\nlibrary(raster) \nlibrary(elevatr)\nlibrary(sf)\nlibrary(RColorBrewer)\nlibrary(classInt)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(paletteer)\nlibrary(cowplot)\nlibrary(dplyr)\nlibrary(patchwork)\nlibrary(terra)\nlibrary(ggnewscale)\nIn this section, I will import the necessary datasets (both spatial and geospatial) into R environment.\nvaltellina &lt;- read_sf(dsn = \"data/vector\", layer = \"valtellina\")\nlandslides &lt;- read_sf(dsn = \"data/vector\", layer = \"landslide_inventory\")\nprecipitation &lt;-raster(\"data/raster/avgprecipitation_mm.tif\")\nelevation &lt;-raster(\"data/raster/elevation_m.tiff\")\ntwi &lt;-raster(\"data/raster/twi_.tif\")\nlithology &lt;- read_sf(dsn = \"data/vector\", layer = \"lithology_cat\")\nprofile_c &lt;- raster(\"data/raster/profile_curvature_cat.tif\")\nplan_c &lt;- raster(\"data/raster/plan_curvature_cat.tif\")\nslope &lt;- raster(\"data/raster/slope_degree.tif\")\ndistance_building &lt;- raster(\"data/raster/distance_to_building_m.tif\")\ndistance_roads &lt;-  raster(\"data/raster/distance_to_roads_m.tif\")\ndistance_river &lt;-  raster(\"data/raster/distance_to_river_m.tif\")\ndistance_faults &lt;-  raster(\"data/raster/distance_to_faults_m.tif\")\naspect &lt;- raster(\"data/raster/aspect_cat.tif\")\nhillshade &lt;- raster(\"data/raster/hillshade.tif\")\ncrs(valtellina)\nSome Layers Required Cropping and Masking\ndistance_building_cropped = crop(distance_building, valtellina)\ndistance_building_final = mask(distance_building_cropped, valtellina)\ndistance_roads_cropped = crop(distance_roads, valtellina)\ndistance_roads_final = mask(distance_roads_cropped, valtellina)\ndistance_river_cropped = crop(distance_river, valtellina)\ndistance_river_final = mask(distance_river_cropped, valtellina)\ndistance_faults_cropped = crop(distance_faults, valtellina)\ndistance_faults_final = mask(distance_faults_cropped, valtellina)\nhillshade_cropped = crop(hillshade, valtellina)\nhillshade_final = mask(hillshade_cropped, valtellina)\n\nref = extent(distance_building_final)\ndistance_faults_final &lt;- setExtent(distance_faults_final, ref, keepres=FALSE, snap=FALSE)\nBefore creating thematic maps for each landslide parameter, a map is created to plot the study area of this project, Valtellina Valley in Italy using ggplot package.\nvaltellina_transformed &lt;- st_transform(valtellina, crs = \"+proj=merc\")\n\nggplot(data = valtellina_transformed) +\n  geom_sf()+\n  coord_sf(expand=FALSE)+\n  labs(x='Longitude',y='Latitude',\n       title=\"Study Area\",\n       subtitle='Valtellina Valley, Italy',\n       caption='Source: Zindi') +\n  cowplot::theme_cowplot()+\n  theme(panel.grid.major = element_line(color = gray(.5),\n                                        linetype = 'dashed',\n                                        linewidth = 0.1),\n        panel.grid.minor = element_blank(),\n        panel.background = element_rect(fill=NA,color = 'black'),\n        panel.ontop = TRUE,\n        axis.title.x = element_text(size = 12), \n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10))\nMap projection is an important property of a geospatial data. In order to perform geoprocessing using geospatial data, we need to ensure that data are projected using the appropriate and standard coordinate system. For this project, we use EPSG:32632 (WGS 84 / UTM zone 32N) for all the datasets.\nprecipitation &lt;- projectRaster(precipitation, crs = \"+proj=merc\")\nreclass_df &lt;- c(-Inf, -0.0001, 1,\n                -0.0001, 0.0001, 2,\n                0.0001, Inf, 3)\nreclass_df\nreclass_m &lt;- matrix(reclass_df,ncol = 3,byrow = TRUE)\n\nprofile_classifed &lt;- reclassify(profile_c,reclass_m)\nprofile_classifed_df &lt;- as.data.frame(profile_classifed,xy=TRUE)%&gt;%drop_na()\nprofile_codes &lt;- unique(profile_classifed_df[\"profile_curvature_cat\"])\nprofile_names &lt;-c(\"convex\", \"flat\", \"concave\")\nprofile_colors &lt;-c(\"#0d3d83\",\"#eff635\",\"#77d91d\")\n\nplan_classifed &lt;- reclassify(plan_c,reclass_m)\nplan_classifed_df &lt;- as.data.frame(plan_classifed,xy=TRUE)%&gt;%drop_na()\nplan_codes &lt;- unique(plan_classifed_df[\"plan_curvature_cat\"])\nplan_names &lt;-c(\"concave\", \"flat\", \"convex\")\nplan_colors &lt;-c(\"#77d91d\",\"#eff635\",\"#0d3d83\")\nBefore plotting the thematic maps with ggplot2, raster datasets are converted into data frames.\nprecipitation_df &lt;- as.data.frame(precipitation,xy=TRUE)%&gt;%drop_na()\ntail(precipitation_df)\nelevation_df &lt;- as.data.frame(elevation,xy=TRUE)%&gt;%drop_na()\ntwi_df &lt;- as.data.frame(twi,xy=TRUE)%&gt;%drop_na()\nlithology_df &lt;- as.data.frame(lithology,xy=TRUE)%&gt;%drop_na()\nprofile_c_df &lt;- as.data.frame(profile_c,xy=TRUE)%&gt;%drop_na()\nplan_c_df &lt;- as.data.frame(plan_c,xy=TRUE)%&gt;%drop_na()\nslope_df &lt;- as.data.frame(slope,xy=TRUE)%&gt;%drop_na()\ndistance_building_df &lt;- as.data.frame(distance_building_final,xy=TRUE)%&gt;%drop_na()\ndistance_roads_df &lt;- as.data.frame(distance_roads_final,xy=TRUE)%&gt;%drop_na()\ndistance_river_df &lt;- as.data.frame(distance_river_final,xy=TRUE)%&gt;%drop_na()\ndistance_faults_df &lt;- as.data.frame(distance_faults_final,xy=TRUE)%&gt;%drop_na()\nhillshade_df &lt;- as.data.frame(hillshade_final,xy=TRUE)%&gt;%drop_na()\nIn this session, we will plot the various parametric data we prepared and processed in previous session into thematic maps. We will use the following functions from ggplot2 to plot these maps."
  },
  {
    "objectID": "project.html#import",
    "href": "project.html#import",
    "title": "Exploratory Data Analysis",
    "section": "2.0 Import",
    "text": "2.0 Import"
  },
  {
    "objectID": "project.html#study-area",
    "href": "project.html#study-area",
    "title": "Exploratory Data Analysis",
    "section": "3.0 Study Area",
    "text": "3.0 Study Area"
  },
  {
    "objectID": "project.html#fixing-crs-references",
    "href": "project.html#fixing-crs-references",
    "title": "Exploratory Data Analysis",
    "section": "4.0 Fixing CRS References",
    "text": "4.0 Fixing CRS References"
  },
  {
    "objectID": "project.html#reclassify-data-values",
    "href": "project.html#reclassify-data-values",
    "title": "Exploratory Data Analysis",
    "section": "5.0 Reclassify Data Values",
    "text": "5.0 Reclassify Data Values"
  },
  {
    "objectID": "project.html#create-database",
    "href": "project.html#create-database",
    "title": "Exploratory Data Analysis",
    "section": "6.0 Create Database",
    "text": "6.0 Create Database"
  },
  {
    "objectID": "project.html#plot-with-ggplot2",
    "href": "project.html#plot-with-ggplot2",
    "title": "Exploratory Data Analysis",
    "section": "7.0 Plot with ggplot2",
    "text": "7.0 Plot with ggplot2"
  },
  {
    "objectID": "gwsmodelling.html",
    "href": "gwsmodelling.html",
    "title": "Parametric Testing",
    "section": "",
    "text": "To develop a landslide susceptibility methodology framework, we will explore and calibrate different statistical and machine learning models."
  },
  {
    "objectID": "gwsmodelling.html#import-packages",
    "href": "gwsmodelling.html#import-packages",
    "title": "Parametric Testing",
    "section": "1.0 Import Packages",
    "text": "1.0 Import Packages\n\npacman::p_load(sp, sf, st, spdep, raster, spatstat, tmap, devtools,vtable,ggplot2,egg, corrplot, patchwork, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary,vtable, sjPlot, sjmisc, sjlabelled, tableHTML, olsrr, car, blorr,ISLR, klaR)"
  },
  {
    "objectID": "gwsmodelling.html#import-data",
    "href": "gwsmodelling.html#import-data",
    "title": "Parametric Testing",
    "section": "2.0 Import Data",
    "text": "2.0 Import Data\n\nvaltellina &lt;- read_sf(dsn = \"./data/vector\", layer = \"valtellina\")\ntrain_grids_v4 &lt;- read.csv(\"~/IS485-Landslide/data/aspatial/train_grid_v4.csv\")\n\n\ntrain_grid_v4.sf &lt;- st_as_sf(train_grids_v4,\n                            coords = c(\"X\", \"Y\"))\ntrain_grid_v4.sf &lt;- st_set_crs(train_grid_v4.sf, 32632)"
  },
  {
    "objectID": "gwsmodelling.html#exploratory-spatial-data-analysis-esda",
    "href": "gwsmodelling.html#exploratory-spatial-data-analysis-esda",
    "title": "Parametric Testing",
    "section": "3.0 Exploratory Spatial Data Analysis (ESDA)",
    "text": "3.0 Exploratory Spatial Data Analysis (ESDA)\nTo calculate the summary statistics of landslide_train data frame, we use st().\n\nst(train_grids_v4)\n\n\nSummary Statistics\n\n\nVariable\nN\nMean\nStd. Dev.\nMin\nPctl. 25\nPctl. 75\nMax\n\n\n\n\nTrain_ID\n50563\n25282\n14596\n1\n12642\n37922\n50563\n\n\nGrid_ID\n50563\n7258576\n4280699\n154\n3455206\n11141722\n14724829\n\n\nX\n50563\n573312\n27325\n519097\n550687\n594547\n624487\n\n\nY\n50563\n5129116\n17040\n5095541\n5115266\n5143076\n5164991\n\n\nLandslide\n50563\n0.83\n0.38\n0\n1\n1\n1\n\n\nElevation\n50563\n1913\n677\n0\n1509\n2420\n3924\n\n\nSlope_Angle\n50563\n29\n15\n0\n18\n39\n83\n\n\nAspect_North\n50563\n0.061\n0.24\n0\n0\n0\n1\n\n\nAspect_NorthEast\n50563\n0.12\n0.32\n0\n0\n0\n1\n\n\nAspect_East\n50563\n0.14\n0.34\n0\n0\n0\n1\n\n\nAspect_SouthEast\n50563\n0.15\n0.35\n0\n0\n0\n1\n\n\nAspect_South\n50563\n0.16\n0.36\n0\n0\n0\n1\n\n\nAspect_SouthWest\n50563\n0.15\n0.36\n0\n0\n0\n1\n\n\nAspect_West\n50563\n0.13\n0.34\n0\n0\n0\n1\n\n\nProfile_Curvature\n50563\n-0.00043\n0.0012\n-0.0066\n-0.0011\n0.00022\n0.0079\n\n\nPlan_Curvature\n50563\n-0.00019\n0.0011\n-0.0056\n-0.00071\n0.00032\n0.0068\n\n\nLithology_Metamorphic\n50563\n0.42\n0.49\n0\n0\n1\n1\n\n\nLithology_Sedimentary\n50563\n0.24\n0.42\n0\n0\n0\n1\n\n\nLithology_Plutonic\n50563\n0.057\n0.23\n0\n0\n0\n1\n\n\nLithology_Unconsolidated\n50563\n0.29\n0.45\n0\n0\n1\n1\n\n\nProximity_Settlement\n50563\n904\n764\n0\n328\n1288\n5600\n\n\nProximity_Stream\n50563\n12\n12\n0\n3.1\n17\n97\n\n\nProximity_Road\n50563\n26\n22\n0\n6.3\n40\n125\n\n\nProximity_Fault\n50563\n828\n1032\n0\n199\n1012\n7746\n\n\nLanduse_Vegetation\n50563\n0.51\n0.5\n0\n0\n1\n1\n\n\nPrecipitation\n50563\n0.15\n0.048\n0\n0.13\n0.17\n0.29\n\n\nTWI\n50563\n7.5\n2.3\n3.7\n6\n8.3\n23\n\n\nSPI\n50563\n0.0065\n0.029\n0\n0.00024\n0.0032\n1.4\n\n\nSTI\n50563\n7.7\n27\n0\n0\n5.8\n877\n\n\n\n\n\n\n\nNext, we will create atrellis plot by using ggarrange() of ggpubr package. In this way, we can see the distribution plots of different parameters at the same time.4.1 Correlation Matrix Using Corrplot\nBefore building a logistic regression model, it is important to ensure that the indepdent variables used are not highly correlated to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as multicollinearity in statistics.\nCorrelation matrix is commonly used to visualise the relationships between the independent variables. In this section, the corrplot package will be used to display the correlation matrix of the independent variables in condo_resale data frame.\n\ncorrplot(cor(train_grids_v4[, 6:29]), diag = FALSE, order = \"AOE\",\n         col=colorRampPalette(c(\"#50a8b4\",\"#e4c838\",\"#be804f\"))(10),\n         tl.pos = \"td\", tl.cex = 0.5,tl.col = \"black\", number.cex = 0.5, method = \"number\", type = \"upper\")\n\n\n\ncorrplot(cor(train_grids_v4[,6:29]), diag = FALSE, order = \"AOE\",\n         col=colorRampPalette(c(\"#50a8b4\",\"#ffffdd\",\"#be804f\"))(10),\n         tl.pos = \"td\", tl.cex = 0.5,tl.col = \"black\", number.cex = 0.5, method = \"ellipse\", type = \"upper\")\n\n\n\n\nMatrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the angular order of the eigenvectors method suggested by Michael Friendly.\n\n4.2 Correlation Matrix Using ggstats\n\nset.seed(123)\n## producing the correlation matrix\nggcorrmat(\n  data = train_grids_v4[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + ## modification outside `{ggstatsplot}` using `{ggplot2}` functions\n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )"
  },
  {
    "objectID": "gwsmodelling.html#multiple-logistic-regression",
    "href": "gwsmodelling.html#multiple-logistic-regression",
    "title": "Parametric Testing",
    "section": "Multiple Logistic Regression",
    "text": "Multiple Logistic Regression\nWe will fit a logistic regression model in order to predict the probability of a customer defaulting based on the average balance carried by the customer. The glm function fits generalized linear models, a class of models that includes logistic regression. The syntax of the glm function is similar to that of lm, except that we must pass the argument family = binomial in order to tell R to run a logistic regression rather than some other type of generalized linear model.\n\nlandslide.lr &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = train_grids_v4)\n\n\nsummary(landslide.lr)\n\n\nCall:\nglm(formula = Landslide ~ Elevation + Slope_Angle + Aspect_North + \n    Aspect_NorthEast + Aspect_East + Aspect_SouthEast + Aspect_South + \n    Aspect_SouthWest + Aspect_West + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Sedimentary + Lithology_Plutonic + \n    Lithology_Unconsolidated + Proximity_Settlement + Proximity_Stream + \n    Proximity_Road + Proximity_Fault + Landuse_Vegetation + Precipitation + \n    TWI + SPI + STI, family = \"binomial\", data = train_grids_v4)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.243e+00  1.893e-01 -11.847  &lt; 2e-16 ***\nElevation                 5.790e-05  3.517e-05   1.646 0.099718 .  \nSlope_Angle               1.706e-01  1.954e-03  87.343  &lt; 2e-16 ***\nAspect_North             -3.510e-02  8.618e-02  -0.407 0.683821    \nAspect_NorthEast         -2.225e-01  7.213e-02  -3.084 0.002041 ** \nAspect_East              -1.617e-01  7.128e-02  -2.268 0.023321 *  \nAspect_SouthEast         -2.401e-01  6.917e-02  -3.472 0.000517 ***\nAspect_South             -1.812e-01  6.829e-02  -2.653 0.007975 ** \nAspect_SouthWest         -4.600e-02  6.949e-02  -0.662 0.508031    \nAspect_West              -4.762e-02  7.108e-02  -0.670 0.502869    \nProfile_Curvature        -6.228e+02  1.777e+01 -35.052  &lt; 2e-16 ***\nPlan_Curvature           -5.890e+02  2.009e+01 -29.320  &lt; 2e-16 ***\nLithology_Metamorphic     1.109e+00  9.629e-02  11.522  &lt; 2e-16 ***\nLithology_Sedimentary     1.577e+00  1.005e-01  15.687  &lt; 2e-16 ***\nLithology_Plutonic       -3.030e-02  8.847e-02  -0.343 0.731946    \nLithology_Unconsolidated  1.499e+00  9.792e-02  15.312  &lt; 2e-16 ***\nProximity_Settlement      4.360e-05  2.970e-05   1.468 0.142100    \nProximity_Stream         -6.250e-03  1.593e-03  -3.924 8.72e-05 ***\nProximity_Road           -2.343e-03  1.026e-03  -2.283 0.022445 *  \nProximity_Fault          -1.315e-04  1.615e-05  -8.146 3.77e-16 ***\nLanduse_Vegetation        6.692e-01  4.060e-02  16.483  &lt; 2e-16 ***\nPrecipitation            -3.469e+00  4.229e-01  -8.202 2.37e-16 ***\nTWI                      -1.067e-01  9.637e-03 -11.067  &lt; 2e-16 ***\nSPI                       1.191e+00  7.010e-01   1.699 0.089396 .  \nSTI                      -5.287e-04  7.677e-04  -0.689 0.491022    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 22929  on 50538  degrees of freedom\nAIC: 22979\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n100*with(summary(landslide.lr), 1 - deviance/null.deviance)\n\n[1] 50.89114\n\nconfint(landslide.lr)\n\nWaiting for profiling to be done...\n\n\n                                 2.5 %        97.5 %\n(Intercept)              -2.614798e+00 -1.872528e+00\nElevation                -1.100535e-05  1.268617e-04\nSlope_Angle               1.668213e-01  1.744792e-01\nAspect_North             -2.036349e-01  1.342130e-01\nAspect_NorthEast         -3.639457e-01 -8.116805e-02\nAspect_East              -3.014909e-01 -2.205432e-02\nAspect_SouthEast         -3.758587e-01 -1.047178e-01\nAspect_South             -3.152073e-01 -4.749895e-02\nAspect_SouthWest         -1.823284e-01  9.008984e-02\nAspect_West              -1.870295e-01  9.162142e-02\nProfile_Curvature        -6.577535e+02 -5.880979e+02\nPlan_Curvature           -6.284441e+02 -5.496984e+02\nLithology_Metamorphic     9.214128e-01  1.298931e+00\nLithology_Sedimentary     1.380869e+00  1.775060e+00\nLithology_Plutonic       -2.039839e-01  1.428812e-01\nLithology_Unconsolidated  1.308214e+00  1.692127e+00\nProximity_Settlement     -1.450154e-05  1.019138e-04\nProximity_Stream         -9.364838e-03 -3.120470e-03\nProximity_Road           -4.349682e-03 -3.261896e-04\nProximity_Fault          -1.631453e-04 -9.983405e-05\nLanduse_Vegetation        5.897524e-01  7.489057e-01\nPrecipitation            -4.298446e+00 -2.640479e+00\nTWI                      -1.256194e-01 -8.783854e-02\nSPI                      -1.375593e-01  2.613875e+00\nSTI                      -2.021054e-03  9.886275e-04\n\n\n\ntbl_regression(landslide.lr, intercept = TRUE) %&gt;%\n  add_glance_source_note(\n  include = c(AIC))\n\n\n4.5 Calculating Adjusted Odd Ratios and Confidence Intervals\n\nOR.CI &lt;- cbind(\"AOR\" = exp(coef(landslide.lr)),\n                       exp(confint(landslide.lr)))[-1,]\nround(OR.CI, 6)\n\n\nvif(landslide.lr)\n\n               Elevation              Slope_Angle             Aspect_North \n                2.362748                 1.691170                 1.497475 \n        Aspect_NorthEast              Aspect_East         Aspect_SouthEast \n                1.905428                 1.954287                 2.093957 \n            Aspect_South         Aspect_SouthWest              Aspect_West \n                2.145022                 2.027933                 1.927346 \n       Profile_Curvature           Plan_Curvature    Lithology_Metamorphic \n                1.422228                 1.487571                 7.443019 \n   Lithology_Sedimentary       Lithology_Plutonic Lithology_Unconsolidated \n                5.130757                 1.910924                 7.685545 \n    Proximity_Settlement         Proximity_Stream           Proximity_Road \n                1.787204                 1.293758                 1.818813 \n         Proximity_Fault       Landuse_Vegetation            Precipitation \n                1.058314                 1.387744                 1.297600 \n                     TWI                      SPI                      STI \n                2.201753                 1.308706                 1.308264 \n\n\n\n\nStepwise Selection\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(landslide.lr)\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1 . Elevation \n2 . Slope_Angle \n3 . Aspect_North \n4 . Aspect_NorthEast \n5 . Aspect_East \n6 . Aspect_SouthEast \n7 . Aspect_South \n8 . Aspect_SouthWest \n9 . Aspect_West \n10 . Profile_Curvature \n11 . Plan_Curvature \n12 . Lithology_Metamorphic \n13 . Lithology_Sedimentary \n14 . Lithology_Plutonic \n15 . Lithology_Unconsolidated \n16 . Proximity_Settlement \n17 . Proximity_Stream \n18 . Proximity_Road \n19 . Proximity_Fault \n20 . Landuse_Vegetation \n21 . Precipitation \n22 . TWI \n23 . SPI \n24 . STI \n\n\nVariables Entered/Removed: \n\n- Slope_Angle added \n- Profile_Curvature added \n- Plan_Curvature added \n- Landuse_Vegetation added \n- Lithology_Plutonic added \n- Precipitation added \n- Proximity_Fault added \n- TWI added \n- Lithology_Sedimentary added \n- Lithology_Unconsolidated added \n- Lithology_Metamorphic added \n- Lithology_Plutonic removed \n- Proximity_Stream added \n- Aspect_SouthEast added \n- Aspect_NorthEast added \n- Aspect_South added \n- Aspect_East added \n- SPI added \n\nNo more variables to be added or removed.\n\n\n\n                              Stepwise Summary                               \n---------------------------------------------------------------------------\nVariable                     Method        AIC          BIC       Deviance  \n---------------------------------------------------------------------------\nSlope_Angle                 addition    27757.416    27775.078    27753.416 \nProfile_Curvature           addition    25065.141    25091.634    25059.141 \nPlan_Curvature              addition    24303.970    24339.294    24295.970 \nLanduse_Vegetation          addition    23891.260    23935.415    23881.260 \nLithology_Plutonic          addition    23677.727    23730.713    23665.727 \nPrecipitation               addition    23539.203    23601.020    23525.203 \nProximity_Fault             addition    23430.433    23501.081    23414.433 \nTWI                         addition    23337.014    23416.493    23319.014 \nLithology_Sedimentary       addition    23278.363    23366.672    23258.363 \nLithology_Unconsolidated    addition    23148.835    23245.976    23126.835 \nLithology_Metamorphic       addition    22999.689    23105.661    22975.689 \nLithology_Plutonic          removal     22997.760    23094.901    22975.760 \nProximity_Stream            addition    22989.371    23095.343    22965.371 \nAspect_SouthEast            addition    22984.054    23098.857    22958.054 \nAspect_NorthEast            addition    22979.924    23103.558    22951.924 \nAspect_South                addition    22975.790    23108.254    22945.790 \nAspect_East                 addition    22972.549    23113.844    22940.549 \nSPI                         addition    22971.964    23122.090    22937.964 \n---------------------------------------------------------------------------\n\n\n\nlandslide.lr %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1 . Elevation \n2 . Slope_Angle \n3 . Aspect_North \n4 . Aspect_NorthEast \n5 . Aspect_East \n6 . Aspect_SouthEast \n7 . Aspect_South \n8 . Aspect_SouthWest \n9 . Aspect_West \n10 . Profile_Curvature \n11 . Plan_Curvature \n12 . Lithology_Metamorphic \n13 . Lithology_Sedimentary \n14 . Lithology_Plutonic \n15 . Lithology_Unconsolidated \n16 . Proximity_Settlement \n17 . Proximity_Stream \n18 . Proximity_Road \n19 . Proximity_Fault \n20 . Landuse_Vegetation \n21 . Precipitation \n22 . TWI \n23 . SPI \n24 . STI \n\n\nVariables Entered/Removed: \n\n- Slope_Angle added \n- Profile_Curvature added \n- Plan_Curvature added \n- Landuse_Vegetation added \n- Lithology_Plutonic added \n- Precipitation added \n- Proximity_Fault added \n- TWI added \n- Lithology_Sedimentary added \n- Lithology_Unconsolidated added \n- Lithology_Metamorphic added \n- Lithology_Plutonic removed \n- Proximity_Stream added \n- Aspect_SouthEast added \n- Aspect_NorthEast added \n- Aspect_South added \n- Aspect_East added \n- SPI added \n\nNo more variables to be added or removed.\n\n\n\n\n\n\n\nModel Update\n\nlandslide.lr_modified &lt;- glm(Landslide ~ Slope_Angle + Aspect_SouthEast + Aspect_NorthEast + Aspect_South + Aspect_East + Profile_Curvature +Plan_Curvature +Lithology_Metamorphic+Lithology_Unconsolidated+ Lithology_Sedimentary+Proximity_Stream+Landuse_Vegetation+TWI+SPI, family = \"binomial\", data = train_grids_v4)\n\n\nsummary(landslide.lr_modified)\n\n\nCall:\nglm(formula = Landslide ~ Slope_Angle + Aspect_SouthEast + Aspect_NorthEast + \n    Aspect_South + Aspect_East + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Unconsolidated + Lithology_Sedimentary + \n    Proximity_Stream + Landuse_Vegetation + TWI + SPI, family = \"binomial\", \n    data = train_grids_v4)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.989e+00  1.226e-01 -24.386  &lt; 2e-16 ***\nSlope_Angle               1.699e-01  1.938e-03  87.672  &lt; 2e-16 ***\nAspect_SouthEast         -1.803e-01  5.117e-02  -3.523 0.000426 ***\nAspect_NorthEast         -2.012e-01  5.559e-02  -3.620 0.000295 ***\nAspect_South             -1.292e-01  4.982e-02  -2.593 0.009514 ** \nAspect_East              -1.277e-01  5.427e-02  -2.353 0.018603 *  \nProfile_Curvature        -6.192e+02  1.760e+01 -35.183  &lt; 2e-16 ***\nPlan_Curvature           -5.746e+02  1.953e+01 -29.417  &lt; 2e-16 ***\nLithology_Metamorphic     1.265e+00  7.068e-02  17.898  &lt; 2e-16 ***\nLithology_Unconsolidated  1.657e+00  7.387e-02  22.433  &lt; 2e-16 ***\nLithology_Sedimentary     1.797e+00  7.644e-02  23.510  &lt; 2e-16 ***\nProximity_Stream         -2.702e-03  1.486e-03  -1.818 0.069028 .  \nLanduse_Vegetation        6.586e-01  3.592e-02  18.336  &lt; 2e-16 ***\nTWI                      -1.088e-01  9.222e-03 -11.796  &lt; 2e-16 ***\nSPI                       7.985e-01  6.022e-01   1.326 0.184876    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 23127  on 50548  degrees of freedom\nAIC: 23157\n\nNumber of Fisher Scoring iterations: 7\n\nvif(landslide.lr_modified)\n\n             Slope_Angle         Aspect_SouthEast         Aspect_NorthEast \n                1.674417                 1.157345                 1.134779 \n            Aspect_South              Aspect_East        Profile_Curvature \n                1.164675                 1.137678                 1.397392 \n          Plan_Curvature    Lithology_Metamorphic Lithology_Unconsolidated \n                1.410249                 4.035544                 4.405966 \n   Lithology_Sedimentary         Proximity_Stream       Landuse_Vegetation \n                3.037511                 1.138366                 1.096464 \n                     TWI                      SPI \n                2.048050                 1.000892"
  },
  {
    "objectID": "gwsmodelling.html#model-fit-statistics",
    "href": "gwsmodelling.html#model-fit-statistics",
    "title": "Parametric Testing",
    "section": "Model Fit Statistics",
    "text": "Model Fit Statistics\nModel fit statistics are available to assess how well the model fits the data and to compare two different models.The output includes likelihood ratio test, AIC, BIC and a host of pseudo r-squared measures. You can read more about pseudo r-squared at https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/.\n\nblr_model_fit_stats(landslide.lr)\n\n                               Model Fit Statistics                                 \n-----------------------------------------------------------------------------------\nLog-Lik Intercept Only:     -23345.502    Log-Lik Full Model:            -11464.710 \nDeviance(50538):             22929.420    LR(24):                         23761.584 \n                                          Prob &gt; LR:                          0.000 \nMCFadden's R2                    0.509    McFadden's Adj R2:                  0.508 \nML (Cox-Snell) R2:               0.375    Cragg-Uhler(Nagelkerke) R2:         0.622 \nMcKelvey & Zavoina's R2:         0.684    Efron's R2:                         0.619 \nCount R2:                        0.930    Adj Count R2:                       0.598 \nBIC:                         23200.195    AIC:                            22979.420 \n-----------------------------------------------------------------------------------\n\n\nCompared with the basic model,\n\nblr_model_fit_stats(landslide.lr)\n\n                               Model Fit Statistics                                 \n-----------------------------------------------------------------------------------\nLog-Lik Intercept Only:     -23345.502    Log-Lik Full Model:            -11464.710 \nDeviance(50538):             22929.420    LR(24):                         23761.584 \n                                          Prob &gt; LR:                          0.000 \nMCFadden's R2                    0.509    McFadden's Adj R2:                  0.508 \nML (Cox-Snell) R2:               0.375    Cragg-Uhler(Nagelkerke) R2:         0.622 \nMcKelvey & Zavoina's R2:         0.684    Efron's R2:                         0.619 \nCount R2:                        0.930    Adj Count R2:                       0.598 \nBIC:                         23200.195    AIC:                            22979.420 \n-----------------------------------------------------------------------------------"
  },
  {
    "objectID": "gwsmodelling.html#model-validation",
    "href": "gwsmodelling.html#model-validation",
    "title": "Parametric Testing",
    "section": "Model Validation",
    "text": "Model Validation\n\nblr_confusion_matrix(landslide.lr, cutoff = 0.5)\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0  6548  1292\n         1  2235 40488\n\n                Accuracy : 0.9302 \n     No Information Rate : 0.1737 \n\n                   Kappa : 0.7462 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.9691 \n             Specificity : 0.7455 \n          Pos Pred Value : 0.9477 \n          Neg Pred Value : 0.8352 \n              Prevalence : 0.8263 \n          Detection Rate : 0.8007 \n    Detection Prevalence : 0.8449 \n       Balanced Accuracy : 0.8573 \n               Precision : 0.9477 \n                  Recall : 0.9691 \n\n        'Positive' Class : 1\n\n\n\nHosmer Lemeshow Test\nHosmer and Lemeshow developed a goodness-of-fit test for logistic regression models with binary responses. The test involves dividing the data into approximately ten groups of roughly equal size based on the percentiles of the estimated probabilities. The observations are sorted in increasing order of their estimated probability of having an even outcome. The discrepancies between the observed and expected number of observations in these groups are summarized by the Pearson chi-square statistic, which is then compared to chi-square distribution with t degrees of freedom, where t is the number of groups minus 2. Lower values of Goodness-of-fit are preferred.\n\nblr_test_hosmer_lemeshow(landslide.lr_modified)\n\n           Partition for the Hosmer & Lemeshow Test            \n--------------------------------------------------------------\n                        def = 1                 def = 0        \nGroup    Total    Observed    Expected    Observed    Expected \n--------------------------------------------------------------\n  1      5057       439        789.34       4618      4267.66  \n  2      5056       2216      2432.89       2840      2623.11  \n  3      5056       4303      4058.69       753        997.31  \n  4      5056       4916      4634.39       140        421.61  \n  5      5057       5024      4841.37        33        215.63  \n  6      5056       5043      4933.14        13        122.86  \n  7      5056       5043      4984.03        13        71.97   \n  8      5056       5046      5016.07        10        39.93   \n  9      5056       5032      5037.52        24        18.48   \n 10      5057       4718      5052.56       339         4.44   \n--------------------------------------------------------------\n\n     Goodness of Fit Test      \n------------------------------\nChi-Square    DF    Pr &gt; ChiSq \n------------------------------\n26056.1816    8       0.0000   \n------------------------------\n\n\n\n\nROC Curve\nROC curve is a graphical representation of the validity of cut-offs for a logistic regression model. The ROC curve is plotted using the sensitivity and specificity for all possible cut-offs, i.e., all the probability scores. The graph is plotted using sensitivity on the y-axis and 1-specificity on the x-axis. Any point on the ROC curve represents a sensitivity X (1-specificity) measure corresponding to a cut-off. The area under the ROC curve is used as a validation measure for the model – the bigger the area the better is the model.\n#| eval: false\npredicted &lt;- predict(landslide.lr, train_grids_v4[, 6:29], type=\"response\")\nroc_curve &lt;- roc(train_grids_v4$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (No Calibration Model)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\npredicted &lt;- predict(landslide.lr_modified, train_grids_v4[, 6:29], type=\"response\")\nroc_curve &lt;- roc(train_grids_v4$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Stepwise Model)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\nInfluence Diagnostics\n\nblr_plot_diag_influence(landslide.lr_modified)\n\n\n\n\n\n\nFitted Values Diagnostics\n\nblr_plot_diag_fit(landslide.lr_modified)"
  },
  {
    "objectID": "gwsmodelling.html#weight-of-evidence",
    "href": "gwsmodelling.html#weight-of-evidence",
    "title": "Parametric Testing",
    "section": "Weight of Evidence",
    "text": "Weight of Evidence\n\nlibrary(\"Information\")\n\nIV &lt;- create_infotables(data=train_grids_v4[, 5:29],\n                        valid=train_grids_v4[, 5:29],\n                        y=\"Landslide\")\nkable(IV$Summary, row.names=FALSE)\n\n\n\n\nVariable\nIV\nPENALTY\nAdjIV\n\n\n\n\nSlope_Angle\n5.3574828\n0\n5.3574828\n\n\nTWI\n0.5119619\n0\n0.5119619\n\n\nElevation\n0.3270770\n0\n0.3270770\n\n\nProximity_Settlement\n0.2073722\n0\n0.2073722\n\n\nProximity_Road\n0.2060752\n0\n0.2060752\n\n\nProfile_Curvature\n0.1481448\n0\n0.1481448\n\n\nPlan_Curvature\n0.1469663\n0\n0.1469663\n\n\nPrecipitation\n0.1097135\n0\n0.1097135\n\n\nLithology_Unconsolidated\n0.1047331\n0\n0.1047331\n\n\nProximity_Fault\n0.0931591\n0\n0.0931591\n\n\nLithology_Sedimentary\n0.0770191\n0\n0.0770191\n\n\nLanduse_Vegetation\n0.0758787\n0\n0.0758787\n\n\nProximity_Stream\n0.0606072\n0\n0.0606072\n\n\nLithology_Metamorphic\n0.0243440\n0\n0.0243440\n\n\nLithology_Plutonic\n0.0184281\n0\n0.0184281\n\n\nAspect_East\n0.0028829\n0\n0.0028829\n\n\nAspect_SouthEast\n0.0025985\n0\n0.0025985\n\n\nAspect_South\n0.0020174\n0\n0.0020174\n\n\nAspect_North\n0.0019081\n0\n0.0019081\n\n\nAspect_West\n0.0011630\n0\n0.0011630\n\n\nSTI\n0.0008136\n0\n0.0008136\n\n\nSPI\n0.0007769\n0\n0.0007769\n\n\nAspect_SouthWest\n0.0000422\n0\n0.0000422\n\n\nAspect_NorthEast\n0.0000023\n0\n0.0000023\n\n\n\n\n\n\n\n\nSpatial Interpolation\n\nvaltellina_boundary &lt;- st_union(valtellina) %&gt;% st_sf()\n\n\nlibrary(sf)\nlibrary(terra)\ngrid &lt;- terra::rast(valtellina_boundary, nrows = 10000, ncols = 15000)\nxy &lt;- terra::xyFromCell(grid, 1:ncell(grid))\ncoop &lt;- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n              crs = st_crs(valtellina_boundary))\ncoop &lt;- st_filter(coop, valtellina_boundary)\nqtm(coop)\n\n\n# Voronoi\nv &lt;- terra::voronoi(x = terra::vect(train.res.sf), bnd = valtellina_boundary)\nplot(v)\npoints(vect(train.res.sf), cex = 0.5)\n\n# Prediction\nv &lt;- st_as_sf(v)\ntm_shape(v) +\n  tm_fill(col = \"MLR_RES\", palette = \"viridis\")+\n  tm_layout(\n    legend.outside=TRUE\n  )\n\n\nresp &lt;- st_intersection(v, coop)\nresp$pred &lt;- resp$MLR_RES\n\npred_mean &lt;- terra::rasterize(resp, grid, field = \"pred\", fun = \"mean\")\ntm_shape(pred_mean) + \n  tm_raster(palette = \"plasma\")+\n  tm_layout(\n    legend.outside=TRUE\n  )\n\n\n\nIDW: Inverse Distance Weighting\nIn the IDW method, values at unsampled locations are estimated as the weighted average of values from the rest of locations with weights inversely proportional to the distance between the unsampled and the sampled locations.\nWe can apply the IDW method with the gstat() function of gstat and the following arguments:\n\nformula: vble ~ 1 to have an intercept only model,\nnmax: number of neighbors is set equal to the total number of locations,\nidp: inverse distance power is set to idp = 1 to have weights with β=1�=1.\n\nThen, we use the predict() function to obtain the predictions and tmap to show the results\n\nlibrary(gstat)\nres &lt;- gstat(formula = MLR_RES ~ 1, locations = train.res.sf,\n             nmax = nrow(train.res.sf), # use all the neighbors locations\n             set = list(idp = 1)) # beta = 1 \n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred &lt;- terra::rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\ntm_shape(pred) + \n  tm_raster(palette = \"viridis\")+\n  tm_layout(\n    legend.outside=TRUE\n  )"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Explanatory and Predictive Landslide Susceptibility Modelling Using Statistical and Machine Learning Techniques: Case Study of Valtellina Valley, Italy",
    "section": "",
    "text": "Abstract\n\nLandslides are a major natural hazard that can have a devastating impact on cities and communities all around the world. Over the past five decades, disasters caused by landslides have become ten times more frequent (Cendrero et al., 2020). Worldwide, landslides cause billions of dollars in infrastructural damage and thousands of deaths every year. On average, about 3,500 people per year are killed due to landslide events all around the world (Froude & Petley, 2018). In addition to casualties, landslides also impose long-term economic and social impacts, including property damage, disruption of access to essential services and supplies, and eventually displacement of people. Moreover, the aftermath of landslides often requires significant resources and time for recovery and reconstruction efforts, further straining already limited resources in affected areas.\nWith increased urbanisation and magnitude of landslides, landslide susceptibility modelling is an emerging research area of both importance and urgency. This gives rise from the eternal disaster threats of landslides across the world.\nSeveral approaches have been explored for landslide susceptibility zoning in the scientific literature. However, there are still many challenges in terms of developing accurate and reliable models. A pertinent challenge is the lack of comprehensive and high-quality landslide inventories which hinders the accurate assessment of the factors contributing to landslide susceptibility. Additionally, the complex nature of landslides makes it difficult to establish a universally applicable model.\nThus, this project aims to research and develop a reproducible methodology framework for building and calibrating landslide susceptibility zoning models in order to advance the current scientific knowledge base and research efforts."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This project is submitted to the Singapore Management University in partial fulfillment of the requirements for the degree of Bachelor of Science (Information Systems) Smart-City Management and Technology major under IS485 IS Project Experience (SMT Research).\n\nCo-Authors\n\nKhant Min Naing\nmnkhant.2020@scis.smu.edu.sg\nSingapore Management University\n\n\n\n\n\nAnn Mei Yi Victoria Grace\nvictoriaann.2021@scis.smu.edu.sg\nSingapore Management University\n\n\n\n\n\n\nSupervisor\n\nAssociate Professor Kam Tin Seong\ntskam@smu.edu.sg\nSingapore Management University\n\nSubmitted to"
  },
  {
    "objectID": "slopesampling.html",
    "href": "slopesampling.html",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "pacman::p_load(sp, sf, st, spdep, terra, raster, spatstat, tmap, devtools,vtable,ggplot2, corrplot, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary, blorr, car, ISLR, klaR,pROC)\n\n\n\n\nWe will import datasets used for this sampling.\n\nvaltellina &lt;- read_sf(dsn = \"./data/vector\", layer = \"valtellina\")\ntrain_grids_v4 &lt;- read.csv(\"data/aspatial/train_grid_v4.csv\")\n\n\n\n\n\n\nFirst, we will extract the Slope_Angle column from the train_grids_v4 data frame and assigning it to the variable slope_angle.\nNext we will calculate the quartiles of the slope_angle data such as minimum (0th percentile), first quartile (25th percentile), median (50th percentile), third quartile (75th percentile), and maximum (100th percentile). This helps us understand the distribution of slope angles in the data set.\nThe quantile function in R calculates the specified quantiles of a data set. The probs argument specifies the probabilities for which quantiles are required, and seq(0, 1, 1/4) generates a sequence of numbers from 0 to 1 in increments of 1/4.\n\nslope_angle &lt;- train_grids_v4$Slope_Angle\nquantile(slope_angle, probs = seq(0, 1, 1/4))\n\n\n\n\nBased on the quartile values that we have calculated, we will now subset the original dataset into four namely sample_Q1, sample_Q2, sample_Q3 & sample_Q4.\n\nFor sample_Q1, we select all rows where Slope_Angle is less than 18.41368. This represents the first quartile of the data.\nFor sample_Q2, we select all rows in new_train where Slope_Angle is less than 30.34639.\nFor sample_Q3, we select all rows where Slope_Angle is less than 38.54599.\nFinally, for sample_Q4, we select all rows where Slope_Angle is less than or equal to 82.91669.\n\nFinally, I’m using the nrow function to count the number of rows in each subset. This gives us the number of sample size in each quartile.\n\nsample_Q1 &lt;- subset(train_grids_v4,Slope_Angle &lt; 18.41368)\nnew_train &lt;- subset(train_grids_v4,Slope_Angle &gt;= 18.41368)\nsample_Q2 &lt;- subset(new_train,Slope_Angle &lt; 30.34639)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 30.34639)\nsample_Q3 &lt;- subset(new_train,Slope_Angle &lt; 38.54599)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 38.54599)\nsample_Q4 &lt;- subset(new_train,Slope_Angle &lt;= 82.91669)\nnrow(sample_Q1)\nnrow(sample_Q2)\nnrow(sample_Q3)\nnrow(sample_Q4)\n\n\n\n\nTo understand the distribution of slope angle in each sample - sample_Q1, sample_Q2, sample_Q3, and sample_Q4, we will plot four histograms as below.\n\nggplot(data=sample_Q1, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q2, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q3, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q4, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\n\n\n\nNext, we will use the ggcorrmat function from the ggstatsplot package to create a correlation matrix for each dataset.\n\nWe set matrix.type to “upper”, which means it will only show the upper triangle of the correlation matrix.\nWe set type to “parametric”, which means it will calculating the correlations using a parametric method (Pearson’s correlation).\nWe set k to 2, sig.level to 0.05, conf.level to 0.95, and bf.prior to 0.707. These are parameters for the statistical tests that ggcorrmat performs\n\n\nset.seed(123)\n\nggcorrmat(\n  data = sample_Q6[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + \n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\n\n\nQ1\n\n\n\n\n\nQ2\n\n\n\n\n\nQ3\n\n\n\n\n\nQ4\n\n\n\n\n\n\nIn this section, we will model a logistic regression model for each data sample.\nBefore wee build the model, we will need to split each data sample into training data and testing data. This is a common practice in machine learning and statistical modeling, where a model is trained on the training set and then evaluated on the test set. We use sample function to carry out test-train split with 7:3 ratio, resulting in four training sets (Q1_train, Q2_train, Q3_train, Q4_train) and four test sets (Q1_test, Q2_test, Q3_test, Q4_test).\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q1), replace=TRUE, prob=c(0.70,0.30))\nQ1_train  &lt;- sample_Q1[sample, ]\nQ1_test   &lt;- sample_Q1[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q2), replace=TRUE, prob=c(0.70,0.30))\nQ2_train  &lt;- sample_Q2[sample, ]\nQ2_test   &lt;- sample_Q2[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q3), replace=TRUE, prob=c(0.70,0.30))\nQ3_train  &lt;- sample_Q3[sample, ]\nQ3_test   &lt;- sample_Q3[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q4), replace=TRUE, prob=c(0.70,0.30))\nQ4_train  &lt;- sample_Q4[sample, ]\nQ4_test   &lt;- sample_Q4[!sample, ]\n\nOnce we have split the test and train for each data sample, we will now proceed to build a Logistic Regression (LR) model for each sampling dataset. We will fit the model using the glm function from stats package. It is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution.\n\n\nFirst LR model, log_model_1 is fitted using Q1_train dataset with specifications as follows:\n\nThe model is predicting the Landslide variable based on a number of predictor variables, including Elevation, Slope_Angle, Aspect_North, Aspect_NorthEast, Aspect_East, Aspect_SouthEast, Aspect_South, Aspect_SouthWest, Aspect_West, Profile_Curvature, Plan_Curvature, Lithology_Metamorphic, Lithology_Sedimentary, Lithology_Plutonic, Lithology_Unconsolidated, Proximity_Settlement, Proximity_Stream, Proximity_Road, Proximity_Fault, Landuse_Vegetation, Precipitation, TWI, SPI, and STI.\nThe family argument is set to \"binomial\" to fit a binomial logistic regression model.\n\n\nlog_model_1 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q1_train)\n\n\n\nOnce we have fitted the model, we will generate a summary of the model using summary() function. The model summary give us useful information about the model, including the coefficients of the predictor variables, the standard errors of these coefficients, and the statistical significance of each predictor.\n\nsummary(log_model_1)\n\n\n\n\nNext, we will calculate the percentage of deviance explained by the model. The deviance is a measure of how well the model fits the data, with lower values indicating a better fit. The null deviance is the deviance of a model with no predictors, i.e., a model that only includes the intercept. So, this calculation gives me the percentage reduction in deviance when going from the null model to the current model.\n\n100*with(summary(log_model_1), 1 - deviance/null.deviance)\n\n\n\n\nNext, we will generate a confusion matrix for the model predictions using blr_confusion_matrix() function from blorr package. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. The cutoff argument is set to 0.5, which means that predicted probabilities greater than or equal to 0.5 are classified as positive, and predicted probabilities less than 0.5 are classified as negative.\n\nblr_confusion_matrix(log_model_1, cutoff = 0.5)\n\n\n\n\nFinally, we will plot the ROC curve and calculate the AUC. The ROC curve is a plot of the true positive rate against the false positive rate for different cutoff values, and the AUC is the area under the ROC curve. These are common metrics for evaluating the performance of a binary classifier. The roc function from the pROC package is used to calculate the ROC curve, and the auc function is used to calculate the AUC.\n\npredicted &lt;- predict(log_model_1, Q1_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q1_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 1)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_2 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q2_train)\n\n\n\n\nsummary(log_model_2)\n\n\n\n\n\n100*with(summary(log_model_2), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_2, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_2, Q2_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q2_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 2)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_3 &lt;- glm(Landslide ~ Elevation + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q3_train)\n\n\n\n\nsummary(log_model_3)\n\n\n\n\n\n100*with(summary(log_model_3), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_3, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_3, Q3_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q3_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 3)\")\nabline(0, 1, lty = 2, col = \"gray\") \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_4 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q4_train)\n\n\n\n\nsummary(log_model_4)\n\n\n\n\n\n100*with(summary(log_model_4), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_4, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_4, Q4_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q4_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 4)\")\nabline(0, 1, lty = 2, col = \"gray\")  \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nsample_Q5 &lt;- subset(train_grids_v4,Slope_Angle &lt; 25)\nnrow(sample_Q5)\n\nggplot(data=sample_Q5, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\") +\n  ggtitle(\"Slope Stratified Sampling (Cut-off 25)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q5), replace=TRUE, prob=c(0.70,0.30))\nQ5_train  &lt;- sample_Q5[sample, ]\nQ5_test   &lt;- sample_Q5[!sample, ]\n\n\nlog_model_5 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q5_train)\n\n\n\n\nsummary(log_model_5)\n\n\n\n\n\n100*with(summary(log_model_5), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_5, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_5, Q5_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q5_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 5)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q6 &lt;- subset(train_grids_v4,Slope_Angle &lt; 20)\nnrow(sample_Q6)\n\nggplot(data=sample_Q6, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 20)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.70,0.30))\nQ6_train  &lt;- sample_Q6[sample, ]\nQ6_test   &lt;- sample_Q6[!sample, ]\n\n\nlog_model_6 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q6_train)\n\n\n\n\nsummary(log_model_6)\n\n\n\n\n\n100*with(summary(log_model_6), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_6, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_6, Q6_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q6_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 6)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q7 &lt;- subset(train_grids_v4,Slope_Angle &lt; 15)\nnrow(sample_Q7)\n\nggplot(data=sample_Q7, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 15)\")\n\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.70,0.30))\nQ7_train  &lt;- sample_Q7[sample, ]\nQ7_test   &lt;- sample_Q7[!sample, ]\n\n\nlog_model_7 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = sample_Q7)\n\n\n\n\nsummary(log_model_7)\n\n\n\n\n\n100*with(summary(log_model_7), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_7, cutoff = 0.5)\n\n\nvif(log_model_7)\n\n\n\n\n\npredicted &lt;- predict(log_model_7, Q7_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q7_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 7)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(log_model_7)\n\n\nlog_model_7 %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\n\n\n\n\nlog_model_7_modified &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_SouthEast + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Road+ Landuse_Vegetation+Precipitation, family = \"binomial\", data = sample_Q7)\n\n\nsummary(log_model_7_modified)\n\n\nvif(log_model_7_modified)\n\n\n\n\n\n\nNext, we will run Geographically Weighted Logistic Regression (GWLR) models using sample_Q5 dataset and GWmodel package. In order to perform GWLR modelling in GWmodel, we will first need to convert the datasets into a SpatialPointsDataFrame.\n\n\n\nset.seed(123)\n# Model 6 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.20,0.80))\nQ6_fit  &lt;- sample_Q6[sample, ]\n\nQ6_fit.sf &lt;- st_as_sf(Q6_fit,\n                            coords = c(\"X\", \"Y\"))\nQ6_fit.sf &lt;- st_set_crs(Q6_fit.sf, 32632)\nQ6_fit.sp &lt;- Q6_fit.sf %&gt;% as_Spatial()\n\n# Model 7 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.20,0.80))\nQ7_fit  &lt;- sample_Q6[sample, ]\n\nQ7_fit.sf &lt;- st_as_sf(Q7_fit,\n                            coords = c(\"X\", \"Y\"))\nQ7_fit.sf &lt;- st_set_crs(Q7_fit.sf, 32632)\nQ7_fit.sp &lt;- Q7_fit.sf %&gt;% as_Spatial()\n\nwrite_rds(Q6_fit.sp, \"data/rds/Q6_fit.sp.rds\")\nwrite_rds(Q7_fit.sp, \"data/rds/Q7_fit.sp.rds\")\n\n\nQ6_fit.sp &lt;- read_rds(\"data/rds/Q6_fit.sp.rds\")\nQ7_fit.sp &lt;- read_rds(\"data/rds/Q7_fit.sp.rds\")\n\nWe will make a quick plot to see the geographical distribution of landslide and non-landslide samples in Q6_fit.sp & Q7_fit.sp.\n\nQ6_fit.sf$Landslide &lt;- as.factor(Q6_fit.sf$Landslide)\nQ7_fit.sf$Landslide &lt;- as.factor(Q7_fit.sf$Landslide)\n\n\n\n\nIn this section, we will calculate the adaptive bandwidth for fitting a GWLE model using the bw.ggwr function from GWmodel.\nFirstly, we will create a distance matrix to be used for calculating the bandwidth. The st_coordinates function is used to extract the coordinates from the Q5_train.sf spatial object. The gw.dist function is then used to calculate the distance matrix dist.test based on these coordinates.\n\n\n\ndist_mat &lt;- st_coordinates(Q6_fit.sf) \ndist.Q6 &lt;- gw.dist(dp.locat=dist_mat,p=2, theta=0, longlat=FALSE)\n\nNow that, we have created the distance matrix, we will calculate the adaptive bandwidth value with specifications as below.\n\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable.\nThe approach argument is set to \"CV\", indicating that cross-validation is used for bandwidth selection.\nThe kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\nFinally, the dMat argument is set to dist.test, which is the pre-specified distance matrix that we calculated earlier.\n\n\nadaptive_bw &lt;- bw.gwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, approach=\"CV\", kernel=\"gaussian\",\n       adaptive=TRUE, p=2, theta=0, longlat=F)\n\n\nBased on the result, the optimal adaptive bandwidth value that yields the lowest CV score is 203 (with CV score = 1312.815). We will use this value in fitting GWLR model gwlr.\n\n\n\n\nWe will use ggwr.basic() function from GWmodel package to fit a GWLR model gwlr using the specifications below.\n\nThe bw argument is set to 203, which is the optimal adaptive bandwidth value that yields the lowest CV score (1312.815). This value was determined in a previous step.\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable. The kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors. The cv argument is set to TRUE, indicating that cross-validation data will be calculated.\nThe tol argument is set to 0.00001, which is the threshold that determines the convergence of the IRLS procedure.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\n\n\ngwlr &lt;- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, bw= 100, family = \"binomial\", kernel = \"gaussian\", adaptive = TRUE, cv = T, p = 2, theta = 0, longlat = FALSE)\n\n\n\n\n\ngwlr\n\n\nregression.points &lt;- gwlr$SDF\n\n\n\n\n\nvaltellina_boundary &lt;- st_union(valtellina) %&gt;% st_sf()\nclass(valtellina_boundary)\n\n\n\nWe wish to predict the prices of properties continuously in space in Athens. To do that, we create a fine raster grid covering Athens and consider the centroids of the raster cells as the prediction locations. We create the raster grid with the rast() function of terra by specifying the region to be covered (map), and the number of rows and columns of the grid (nrows = 700, ncols = 1066). The prediction locations are the centroids of the raster cells and can be obtained with the xyFromCell() function of terra. Alternatively, we could create the grid using the st_make_grid() function of sf by specifying the number of grid cells in the horizontal and vertical directions or the cell size.\n\ngrid &lt;- rast(valtellina_boundary, nrows = 700, ncols = 1066)\nxy &lt;- xyFromCell(grid, 1:ncell(grid))\ncoop &lt;- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n              crs = st_crs(valtellina_boundary))\ncoop &lt;- st_filter(coop, valtellina_boundary)\nqtm(coop)\n\n\n\n\n\nWe can obtain predictions at each of the prediction locations as the values of the closest sampled locations. To do that, we can employ the Voronoi diagram (also known as Dirichlet or Thiessen diagram). The Voronoi diagram is created when a region with n points is partitioned into convex polygons such that each polygon contains exactly one generating point, and every point in a given polygon is closer to its generating point than to any other.\nGiven a set of points, we can create a Voronoi diagram with the voronoi() function of terra specifying the points as an object of class SpatVector of terra, and map to set the outer boundary of the Voronoi diagram. This returns a Voronoi diagram for the set of points assuming constant values in each of the polygons.\nThen, we can use the functions tm_shape() and tm_fill() of tmap to plot the values of the variable in each of the polygons indicating the name of the variable col = \"vble\", the palette palette = \"viridis\" and the level of transparency alpha = 0.6 (if the plot is interactive).\n\n# Voronoi\nv &lt;- voronoi(x = vect(regression.points), bnd = valtellina_boundary)\nplot(v)\npoints(vect(regression.points), cex = 0.5)\n\n# Prediction\nv &lt;- st_as_sf(v)\ntm_shape(v) +\n  tm_fill(col = \"Landuse_Vegetation\", palette = \"Spectral\")\n\n\nresp &lt;- st_intersection(v, coop)\nresp$pred &lt;- resp$Landuse_Vegetation\n\npred_voronoi &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nvoronoi_map &lt;- tm_shape(pred_voronoi) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Voronoi\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nvoronoi_map\n\n\n\n\nIn the IDW method, values at unsampled locations are estimated as the weighted average of values from the rest of locations with weights inversely proportional to the distance between the unsampled and the sampled locations.\nWe can apply the IDW method with the gstat() function of gstat and the following arguments:\n\nformula: vble ~ 1 to have an intercept only model,\nnmax: number of neighbors is set equal to the total number of locations,\nidp: inverse distance power is set to idp = 1 to have weights with β=1�=1.\n\nThen, we use the predict() function to obtain the predictions and tmap to show the results\n\npacman::p_load(gstat)\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points,\n             nmax = nrow(regression.points), # use all the neighbors locations\n             set = list(idp = 1)) # beta = 1 \n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_idw &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nidw_map &lt;- tm_shape(pred_idw) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"IDW\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nidw_map\n\n\n\n\nIn the nearest neighbors interpolation method, values at unsampled locations are estimated as the average of the values of the k closest sampled locations. Specifically,\nWe can compute predictions using nearest neighbors interpolation with the gstat() function of gstat. Here, we consider the number of closest sampled locations equal to 5 by setting nmax = 5. Unlike the IDW method, in the nearest neighbors approach locations further away from the location where we wish to predict are assigned the same weights. Therefore, the inverse distance power idp is set equal to zero so all the neighbors are equally weighted.\nThen, we use the predict() function to get predictions at unsampled locations given in coop.\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_nn &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nnn_map &lt;- tm_shape(pred_nn) + \n  tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Nearest Neighbour\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nnn_map\n\n\n\n\nPredictions can also be obtained using an ensemble approach that combines the predictions obtained with several spatial interpolation methods.\nHere, we use an ensemble approach to predict the price per square meter of apartments in Athens by combining the predictions of the three previous approaches (closest observation, IDW, nearest neighbors) using equal weights.\nThe predictions with the closest observation method are obtained using the Voronoi diagram as follows:\n\n# Closest observation (Voronoi)\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\n\nThe IDW approach can be applied with the gstat() function of gstat specifying nmax as the total number of locations and idp = 1.\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\n\nThe nearest neighbors method is applied with the gstat() function specifying nmax as the number of neighbors and with equal weights (idp = 0).\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\n\nFinally, the ensemble predictions are obtained by combining the predictions of these three methods with equal weights.\n\n# Ensemble (equal weights)\nweights &lt;- c(1/3, 1/3, 1/3)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\n\nWe create a map with the predictions by creating a raster with the predictions and using the tmap package.\n\nresp &lt;- data.frame(\nx = st_coordinates(coop)[, 1],\ny = st_coordinates(coop)[, 2],\npred = p4)\n\nresp &lt;- st_as_sf(resp, coords = c(\"x\", \"y\"), crs = st_crs(map))\n\npred_ensemble &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\n ensemble_map &lt;- tm_shape(pred_ensemble) + \n   tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n             midpoint = NA) +\n tm_layout(main.title = \"Ensemble\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n \n ensemble_map\n\n\ntmap_arrange(voronoi_map, idw_map, nn_map, ensemble_map)\n\n\nwriteRaster(pred_nn, \"~/IS485-Landslide/data/gwr_maps/landuse_nn.tif\", overwrite=TRUE)\nwriteRaster(pred_idw, \"~/IS485-Landslide/data/gwr_maps/landuse_idw.tif\", overwrite=TRUE)\nwriteRaster(pred_voronoi, \"~/IS485-Landslide/data/gwr_maps/landuse_voronoi.tif\", overwrite=TRUE)\nwriteRaster(pred_ensemble, \"~/IS485-Landslide/data/gwr_maps/landuse_ensemble.tif\", overwrite=TRUE)\n\n\n\n\nWe can assess the performance of each of the methods presented above using K-fold cross-validation and the root mean squared error (RMSE). First, we split the data in K parts. For each part, we use the remaining K−1 parts (training data) to fit the model and that part (testing data) to predict. We compute the RMSE by comparing the testing and predicted data in each of the K parts.\nNote that if K is equal to the number of observations n, this procedure is called leave-one-out cross-validation (LOOCV). That means that n separate data sets are trained on all of the data except one observation, and then prediction is made for that one observation.\nHere, we assess the performance of each of the methods previously employed to predict the prices of apartments in Athens. We create training and testing sets by using the dismo:kfold() function of the dismo package (Hijmans et al. 2022) to randomly assign the observations to K=5 groups of roughly equal size. For each group, we fit the model using the training data, and obtain predictions of the testing data. We calculate the RMSEs of each part and average the RMSEs to obtain a K-fold cross-validation estimate.\n\npacman::p_load(dismo)\n\n\nRMSE &lt;- function(observed, predicted) {\nsqrt(mean((observed - predicted)^2))\n}\n\n# Split data in 5 sets\nkf &lt;- dismo::kfold(nrow(regression.points), k = 5) # K-fold partitioning\n\n# Vectors to store the RMSE values obtained with each method\nrmse1 &lt;- rep(NA, 5) # Closest observation\nrmse2 &lt;- rep(NA, 5) # IDW\nrmse3 &lt;- rep(NA, 5) # Nearest neighbors\nrmse4 &lt;- rep(NA, 5) # Ensemble\n\n\nfor(k in 1:5) {\n# Split data in test and train\ntest &lt;- regression.points[kf == k, ]\ntrain &lt;- regression.points[kf != k, ]\n\n# Closest observation\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\nrmse1[k] &lt;- RMSE(test$Landuse_Vegetation, p1)\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\nrmse2[k] &lt;- RMSE(test$Landuse_Vegetation, p2)\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\nrmse3[k] &lt;- RMSE(test$Landuse_Vegetation, p3)\n\n# Ensemble (weights are inverse RMSE so lower RMSE higher weight)\nw &lt;- 1/c(rmse1[k], rmse2[k], rmse3[k])\nweights &lt;- w/sum(w)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\nrmse4[k] &lt;- RMSE(test$Landuse_Vegetation, p4)\n}\n\nThe RMSE values obtained in each of the 5 splits are shown below.\n\n# RMSE obtained for each of the 5 splits\ndata.frame(closest.obs = rmse1, IDW = rmse2,\n           nearest.neigh = rmse3, ensemble = rmse4)\n\nWe see the minimum average RMSE corresponds to the ensemble method.\n\n# Average RMSE over the 5 splits\ndata.frame(closest.obs = mean(rmse1), IDW = mean(rmse2),\n           nearest.neigh = mean(rmse3), ensemble = mean(rmse4))\n\n\n\n\n\n\nwrite.csv(sample_Q6, \"~/IS485-Landslide/data/aspatial/slope_20degree.csv\")\nwrite.csv(sample_Q7, \"~/IS485-Landslide/data/aspatial/slope_15degree.csv\")"
  },
  {
    "objectID": "slopesampling.html#import-packages",
    "href": "slopesampling.html#import-packages",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "pacman::p_load(sp, sf, st, spdep, terra, raster, spatstat, tmap, devtools,vtable,ggplot2, corrplot, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary, blorr, car, ISLR, klaR,pROC)"
  },
  {
    "objectID": "slopesampling.html#import-data",
    "href": "slopesampling.html#import-data",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "We will import datasets used for this sampling.\n\nvaltellina &lt;- read_sf(dsn = \"./data/vector\", layer = \"valtellina\")\ntrain_grids_v4 &lt;- read.csv(\"data/aspatial/train_grid_v4.csv\")"
  },
  {
    "objectID": "slopesampling.html#slope-sampling",
    "href": "slopesampling.html#slope-sampling",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "First, we will extract the Slope_Angle column from the train_grids_v4 data frame and assigning it to the variable slope_angle.\nNext we will calculate the quartiles of the slope_angle data such as minimum (0th percentile), first quartile (25th percentile), median (50th percentile), third quartile (75th percentile), and maximum (100th percentile). This helps us understand the distribution of slope angles in the data set.\nThe quantile function in R calculates the specified quantiles of a data set. The probs argument specifies the probabilities for which quantiles are required, and seq(0, 1, 1/4) generates a sequence of numbers from 0 to 1 in increments of 1/4.\n\nslope_angle &lt;- train_grids_v4$Slope_Angle\nquantile(slope_angle, probs = seq(0, 1, 1/4))\n\n\n\n\nBased on the quartile values that we have calculated, we will now subset the original dataset into four namely sample_Q1, sample_Q2, sample_Q3 & sample_Q4.\n\nFor sample_Q1, we select all rows where Slope_Angle is less than 18.41368. This represents the first quartile of the data.\nFor sample_Q2, we select all rows in new_train where Slope_Angle is less than 30.34639.\nFor sample_Q3, we select all rows where Slope_Angle is less than 38.54599.\nFinally, for sample_Q4, we select all rows where Slope_Angle is less than or equal to 82.91669.\n\nFinally, I’m using the nrow function to count the number of rows in each subset. This gives us the number of sample size in each quartile.\n\nsample_Q1 &lt;- subset(train_grids_v4,Slope_Angle &lt; 18.41368)\nnew_train &lt;- subset(train_grids_v4,Slope_Angle &gt;= 18.41368)\nsample_Q2 &lt;- subset(new_train,Slope_Angle &lt; 30.34639)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 30.34639)\nsample_Q3 &lt;- subset(new_train,Slope_Angle &lt; 38.54599)\nnew_train &lt;- subset(new_train,Slope_Angle &gt;= 38.54599)\nsample_Q4 &lt;- subset(new_train,Slope_Angle &lt;= 82.91669)\nnrow(sample_Q1)\nnrow(sample_Q2)\nnrow(sample_Q3)\nnrow(sample_Q4)\n\n\n\n\nTo understand the distribution of slope angle in each sample - sample_Q1, sample_Q2, sample_Q3, and sample_Q4, we will plot four histograms as below.\n\nggplot(data=sample_Q1, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q2, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q3, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\nggplot(data=sample_Q4, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")\n\n\n\n\nNext, we will use the ggcorrmat function from the ggstatsplot package to create a correlation matrix for each dataset.\n\nWe set matrix.type to “upper”, which means it will only show the upper triangle of the correlation matrix.\nWe set type to “parametric”, which means it will calculating the correlations using a parametric method (Pearson’s correlation).\nWe set k to 2, sig.level to 0.05, conf.level to 0.95, and bf.prior to 0.707. These are parameters for the statistical tests that ggcorrmat performs\n\n\nset.seed(123)\n\nggcorrmat(\n  data = sample_Q6[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + \n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\n\n\nQ1\n\n\n\n\n\nQ2\n\n\n\n\n\nQ3\n\n\n\n\n\nQ4"
  },
  {
    "objectID": "slopesampling.html#logistic-regression-modelling",
    "href": "slopesampling.html#logistic-regression-modelling",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "In this section, we will model a logistic regression model for each data sample.\nBefore wee build the model, we will need to split each data sample into training data and testing data. This is a common practice in machine learning and statistical modeling, where a model is trained on the training set and then evaluated on the test set. We use sample function to carry out test-train split with 7:3 ratio, resulting in four training sets (Q1_train, Q2_train, Q3_train, Q4_train) and four test sets (Q1_test, Q2_test, Q3_test, Q4_test).\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q1), replace=TRUE, prob=c(0.70,0.30))\nQ1_train  &lt;- sample_Q1[sample, ]\nQ1_test   &lt;- sample_Q1[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q2), replace=TRUE, prob=c(0.70,0.30))\nQ2_train  &lt;- sample_Q2[sample, ]\nQ2_test   &lt;- sample_Q2[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q3), replace=TRUE, prob=c(0.70,0.30))\nQ3_train  &lt;- sample_Q3[sample, ]\nQ3_test   &lt;- sample_Q3[!sample, ]\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q4), replace=TRUE, prob=c(0.70,0.30))\nQ4_train  &lt;- sample_Q4[sample, ]\nQ4_test   &lt;- sample_Q4[!sample, ]\n\nOnce we have split the test and train for each data sample, we will now proceed to build a Logistic Regression (LR) model for each sampling dataset. We will fit the model using the glm function from stats package. It is used to fit generalized linear models, specified by giving a symbolic description of the linear predictor and a description of the error distribution.\n\n\nFirst LR model, log_model_1 is fitted using Q1_train dataset with specifications as follows:\n\nThe model is predicting the Landslide variable based on a number of predictor variables, including Elevation, Slope_Angle, Aspect_North, Aspect_NorthEast, Aspect_East, Aspect_SouthEast, Aspect_South, Aspect_SouthWest, Aspect_West, Profile_Curvature, Plan_Curvature, Lithology_Metamorphic, Lithology_Sedimentary, Lithology_Plutonic, Lithology_Unconsolidated, Proximity_Settlement, Proximity_Stream, Proximity_Road, Proximity_Fault, Landuse_Vegetation, Precipitation, TWI, SPI, and STI.\nThe family argument is set to \"binomial\" to fit a binomial logistic regression model.\n\n\nlog_model_1 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q1_train)\n\n\n\nOnce we have fitted the model, we will generate a summary of the model using summary() function. The model summary give us useful information about the model, including the coefficients of the predictor variables, the standard errors of these coefficients, and the statistical significance of each predictor.\n\nsummary(log_model_1)\n\n\n\n\nNext, we will calculate the percentage of deviance explained by the model. The deviance is a measure of how well the model fits the data, with lower values indicating a better fit. The null deviance is the deviance of a model with no predictors, i.e., a model that only includes the intercept. So, this calculation gives me the percentage reduction in deviance when going from the null model to the current model.\n\n100*with(summary(log_model_1), 1 - deviance/null.deviance)\n\n\n\n\nNext, we will generate a confusion matrix for the model predictions using blr_confusion_matrix() function from blorr package. The confusion matrix shows the number of true positives, true negatives, false positives, and false negatives. The cutoff argument is set to 0.5, which means that predicted probabilities greater than or equal to 0.5 are classified as positive, and predicted probabilities less than 0.5 are classified as negative.\n\nblr_confusion_matrix(log_model_1, cutoff = 0.5)\n\n\n\n\nFinally, we will plot the ROC curve and calculate the AUC. The ROC curve is a plot of the true positive rate against the false positive rate for different cutoff values, and the AUC is the area under the ROC curve. These are common metrics for evaluating the performance of a binary classifier. The roc function from the pROC package is used to calculate the ROC curve, and the auc function is used to calculate the AUC.\n\npredicted &lt;- predict(log_model_1, Q1_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q1_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 1)\")\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_2 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q2_train)\n\n\n\n\nsummary(log_model_2)\n\n\n\n\n\n100*with(summary(log_model_2), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_2, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_2, Q2_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q2_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 2)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_3 &lt;- glm(Landslide ~ Elevation + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q3_train)\n\n\n\n\nsummary(log_model_3)\n\n\n\n\n\n100*with(summary(log_model_3), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_3, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_3, Q3_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q3_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 3)\")\nabline(0, 1, lty = 2, col = \"gray\") \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nlog_model_4 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q4_train)\n\n\n\n\nsummary(log_model_4)\n\n\n\n\n\n100*with(summary(log_model_4), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_4, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_4, Q4_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q4_test$Landslide, predicted)\nplot(roc_curve, main = \"ROC Curve (Model 4)\")\nabline(0, 1, lty = 2, col = \"gray\")  \nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nsample_Q5 &lt;- subset(train_grids_v4,Slope_Angle &lt; 25)\nnrow(sample_Q5)\n\nggplot(data=sample_Q5, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\") +\n  ggtitle(\"Slope Stratified Sampling (Cut-off 25)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q5), replace=TRUE, prob=c(0.70,0.30))\nQ5_train  &lt;- sample_Q5[sample, ]\nQ5_test   &lt;- sample_Q5[!sample, ]\n\n\nlog_model_5 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q5_train)\n\n\n\n\nsummary(log_model_5)\n\n\n\n\n\n100*with(summary(log_model_5), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_5, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_5, Q5_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q5_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 5)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q6 &lt;- subset(train_grids_v4,Slope_Angle &lt; 20)\nnrow(sample_Q6)\n\nggplot(data=sample_Q6, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 20)\")\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.70,0.30))\nQ6_train  &lt;- sample_Q6[sample, ]\nQ6_test   &lt;- sample_Q6[!sample, ]\n\n\nlog_model_6 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = Q6_train)\n\n\n\n\nsummary(log_model_6)\n\n\n\n\n\n100*with(summary(log_model_6), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_6, cutoff = 0.5)\n\n\n\n\n\npredicted &lt;- predict(log_model_6, Q6_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q6_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 6)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\n\n\nset.seed(123)\n\nsample_Q7 &lt;- subset(train_grids_v4,Slope_Angle &lt; 15)\nnrow(sample_Q7)\n\nggplot(data=sample_Q7, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=10, color=\"black\", fill=\"#e9531e\")+\n  ggtitle(\"Slope Stratified Sampling (Cut-off 15)\")\n\n\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.70,0.30))\nQ7_train  &lt;- sample_Q7[sample, ]\nQ7_test   &lt;- sample_Q7[!sample, ]\n\n\nlog_model_7 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = sample_Q7)\n\n\n\n\nsummary(log_model_7)\n\n\n\n\n\n100*with(summary(log_model_7), 1 - deviance/null.deviance)\n\n\n\n\n\nblr_confusion_matrix(log_model_7, cutoff = 0.5)\n\n\nvif(log_model_7)\n\n\n\n\n\npredicted &lt;- predict(log_model_7, Q7_test[, 6:29], type=\"response\")\nroc_curve &lt;- roc(Q7_test$Landslide, predicted)\n# Plot the ROC curve\nplot(roc_curve, main = \"ROC Curve (Model 7)\")\nabline(0, 1, lty = 2, col = \"gray\")  # Add a reference line for a random classifier\nauc_value &lt;- auc(roc_curve)\ncat(\"AUC:\", auc_value, \"\\n\")\n\n\n\n\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(log_model_7)\n\n\nlog_model_7 %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\n\n\n\n\nlog_model_7_modified &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_SouthEast + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic + Proximity_Road+ Landuse_Vegetation+Precipitation, family = \"binomial\", data = sample_Q7)\n\n\nsummary(log_model_7_modified)\n\n\nvif(log_model_7_modified)"
  },
  {
    "objectID": "slopesampling.html#geographically-weighted-logistic-regression",
    "href": "slopesampling.html#geographically-weighted-logistic-regression",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "Next, we will run Geographically Weighted Logistic Regression (GWLR) models using sample_Q5 dataset and GWmodel package. In order to perform GWLR modelling in GWmodel, we will first need to convert the datasets into a SpatialPointsDataFrame.\n\n\n\nset.seed(123)\n# Model 6 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q6), replace=TRUE, prob=c(0.20,0.80))\nQ6_fit  &lt;- sample_Q6[sample, ]\n\nQ6_fit.sf &lt;- st_as_sf(Q6_fit,\n                            coords = c(\"X\", \"Y\"))\nQ6_fit.sf &lt;- st_set_crs(Q6_fit.sf, 32632)\nQ6_fit.sp &lt;- Q6_fit.sf %&gt;% as_Spatial()\n\n# Model 7 Slope Cut-off = 20\nsample &lt;- sample(c(TRUE, FALSE), nrow(sample_Q7), replace=TRUE, prob=c(0.20,0.80))\nQ7_fit  &lt;- sample_Q6[sample, ]\n\nQ7_fit.sf &lt;- st_as_sf(Q7_fit,\n                            coords = c(\"X\", \"Y\"))\nQ7_fit.sf &lt;- st_set_crs(Q7_fit.sf, 32632)\nQ7_fit.sp &lt;- Q7_fit.sf %&gt;% as_Spatial()\n\nwrite_rds(Q6_fit.sp, \"data/rds/Q6_fit.sp.rds\")\nwrite_rds(Q7_fit.sp, \"data/rds/Q7_fit.sp.rds\")\n\n\nQ6_fit.sp &lt;- read_rds(\"data/rds/Q6_fit.sp.rds\")\nQ7_fit.sp &lt;- read_rds(\"data/rds/Q7_fit.sp.rds\")\n\nWe will make a quick plot to see the geographical distribution of landslide and non-landslide samples in Q6_fit.sp & Q7_fit.sp.\n\nQ6_fit.sf$Landslide &lt;- as.factor(Q6_fit.sf$Landslide)\nQ7_fit.sf$Landslide &lt;- as.factor(Q7_fit.sf$Landslide)\n\n\n\n\nIn this section, we will calculate the adaptive bandwidth for fitting a GWLE model using the bw.ggwr function from GWmodel.\nFirstly, we will create a distance matrix to be used for calculating the bandwidth. The st_coordinates function is used to extract the coordinates from the Q5_train.sf spatial object. The gw.dist function is then used to calculate the distance matrix dist.test based on these coordinates.\n\n\n\ndist_mat &lt;- st_coordinates(Q6_fit.sf) \ndist.Q6 &lt;- gw.dist(dp.locat=dist_mat,p=2, theta=0, longlat=FALSE)\n\nNow that, we have created the distance matrix, we will calculate the adaptive bandwidth value with specifications as below.\n\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable.\nThe approach argument is set to \"CV\", indicating that cross-validation is used for bandwidth selection.\nThe kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\nFinally, the dMat argument is set to dist.test, which is the pre-specified distance matrix that we calculated earlier.\n\n\nadaptive_bw &lt;- bw.gwr(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, approach=\"CV\", kernel=\"gaussian\",\n       adaptive=TRUE, p=2, theta=0, longlat=F)\n\n\nBased on the result, the optimal adaptive bandwidth value that yields the lowest CV score is 203 (with CV score = 1312.815). We will use this value in fitting GWLR model gwlr.\n\n\n\n\nWe will use ggwr.basic() function from GWmodel package to fit a GWLR model gwlr using the specifications below.\n\nThe bw argument is set to 203, which is the optimal adaptive bandwidth value that yields the lowest CV score (1312.815). This value was determined in a previous step.\nThe family argument is set to \"binomial\", indicating that a binomial distribution is assumed for the dependent variable. The kernel argument is set to \"gaussian\", indicating that a Gaussian kernel function is used.\nThe adaptive argument is set to TRUE, indicating that an adaptive kernel is used, where the bandwidth corresponds to the number of nearest neighbors. The cv argument is set to TRUE, indicating that cross-validation data will be calculated.\nThe tol argument is set to 0.00001, which is the threshold that determines the convergence of the IRLS procedure.\nThe p and theta arguments are set to 2 and 0 respectively, which are the default values for the power of the Minkowski distance and the angle to rotate the coordinate system.\nThe longlat argument is set to FALSE, indicating that Euclidean distances are calculated.\n\n\ngwlr &lt;- ggwr.basic(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, data = Q6_fit.sp, bw= 100, family = \"binomial\", kernel = \"gaussian\", adaptive = TRUE, cv = T, p = 2, theta = 0, longlat = FALSE)\n\n\n\n\n\ngwlr\n\n\nregression.points &lt;- gwlr$SDF\n\n\n\n\n\nvaltellina_boundary &lt;- st_union(valtellina) %&gt;% st_sf()\nclass(valtellina_boundary)\n\n\n\nWe wish to predict the prices of properties continuously in space in Athens. To do that, we create a fine raster grid covering Athens and consider the centroids of the raster cells as the prediction locations. We create the raster grid with the rast() function of terra by specifying the region to be covered (map), and the number of rows and columns of the grid (nrows = 700, ncols = 1066). The prediction locations are the centroids of the raster cells and can be obtained with the xyFromCell() function of terra. Alternatively, we could create the grid using the st_make_grid() function of sf by specifying the number of grid cells in the horizontal and vertical directions or the cell size.\n\ngrid &lt;- rast(valtellina_boundary, nrows = 700, ncols = 1066)\nxy &lt;- xyFromCell(grid, 1:ncell(grid))\ncoop &lt;- st_as_sf(as.data.frame(xy), coords = c(\"x\", \"y\"),\n              crs = st_crs(valtellina_boundary))\ncoop &lt;- st_filter(coop, valtellina_boundary)\nqtm(coop)\n\n\n\n\n\nWe can obtain predictions at each of the prediction locations as the values of the closest sampled locations. To do that, we can employ the Voronoi diagram (also known as Dirichlet or Thiessen diagram). The Voronoi diagram is created when a region with n points is partitioned into convex polygons such that each polygon contains exactly one generating point, and every point in a given polygon is closer to its generating point than to any other.\nGiven a set of points, we can create a Voronoi diagram with the voronoi() function of terra specifying the points as an object of class SpatVector of terra, and map to set the outer boundary of the Voronoi diagram. This returns a Voronoi diagram for the set of points assuming constant values in each of the polygons.\nThen, we can use the functions tm_shape() and tm_fill() of tmap to plot the values of the variable in each of the polygons indicating the name of the variable col = \"vble\", the palette palette = \"viridis\" and the level of transparency alpha = 0.6 (if the plot is interactive).\n\n# Voronoi\nv &lt;- voronoi(x = vect(regression.points), bnd = valtellina_boundary)\nplot(v)\npoints(vect(regression.points), cex = 0.5)\n\n# Prediction\nv &lt;- st_as_sf(v)\ntm_shape(v) +\n  tm_fill(col = \"Landuse_Vegetation\", palette = \"Spectral\")\n\n\nresp &lt;- st_intersection(v, coop)\nresp$pred &lt;- resp$Landuse_Vegetation\n\npred_voronoi &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nvoronoi_map &lt;- tm_shape(pred_voronoi) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Voronoi\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nvoronoi_map\n\n\n\n\nIn the IDW method, values at unsampled locations are estimated as the weighted average of values from the rest of locations with weights inversely proportional to the distance between the unsampled and the sampled locations.\nWe can apply the IDW method with the gstat() function of gstat and the following arguments:\n\nformula: vble ~ 1 to have an intercept only model,\nnmax: number of neighbors is set equal to the total number of locations,\nidp: inverse distance power is set to idp = 1 to have weights with β=1�=1.\n\nThen, we use the predict() function to obtain the predictions and tmap to show the results\n\npacman::p_load(gstat)\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points,\n             nmax = nrow(regression.points), # use all the neighbors locations\n             set = list(idp = 1)) # beta = 1 \n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_idw &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nidw_map &lt;- tm_shape(pred_idw) + \n  tm_raster(palette = \"Spectral\",\n            title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"IDW\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nidw_map\n\n\n\n\nIn the nearest neighbors interpolation method, values at unsampled locations are estimated as the average of the values of the k closest sampled locations. Specifically,\nWe can compute predictions using nearest neighbors interpolation with the gstat() function of gstat. Here, we consider the number of closest sampled locations equal to 5 by setting nmax = 5. Unlike the IDW method, in the nearest neighbors approach locations further away from the location where we wish to predict are assigned the same weights. Therefore, the inverse distance power idp is set equal to zero so all the neighbors are equally weighted.\nThen, we use the predict() function to get predictions at unsampled locations given in coop.\n\nres &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n             set = list(idp = 0))\n\nresp &lt;- predict(res, coop)\nresp$x &lt;- st_coordinates(resp)[,1]\nresp$y &lt;- st_coordinates(resp)[,2]\nresp$pred &lt;- resp$var1.pred\n\npred_nn &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\nnn_map &lt;- tm_shape(pred_nn) + \n  tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n            midpoint = NA) +\n tm_layout(main.title = \"Nearest Neighbour\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n\nnn_map\n\n\n\n\nPredictions can also be obtained using an ensemble approach that combines the predictions obtained with several spatial interpolation methods.\nHere, we use an ensemble approach to predict the price per square meter of apartments in Athens by combining the predictions of the three previous approaches (closest observation, IDW, nearest neighbors) using equal weights.\nThe predictions with the closest observation method are obtained using the Voronoi diagram as follows:\n\n# Closest observation (Voronoi)\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\n\nThe IDW approach can be applied with the gstat() function of gstat specifying nmax as the total number of locations and idp = 1.\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\n\nThe nearest neighbors method is applied with the gstat() function specifying nmax as the number of neighbors and with equal weights (idp = 0).\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\n\nFinally, the ensemble predictions are obtained by combining the predictions of these three methods with equal weights.\n\n# Ensemble (equal weights)\nweights &lt;- c(1/3, 1/3, 1/3)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\n\nWe create a map with the predictions by creating a raster with the predictions and using the tmap package.\n\nresp &lt;- data.frame(\nx = st_coordinates(coop)[, 1],\ny = st_coordinates(coop)[, 2],\npred = p4)\n\nresp &lt;- st_as_sf(resp, coords = c(\"x\", \"y\"), crs = st_crs(map))\n\npred_ensemble &lt;- rasterize(resp, grid, field = \"pred\", fun = \"mean\")\n\n\n ensemble_map &lt;- tm_shape(pred_ensemble) + \n   tm_raster(palette = \"Spectral\",\n             title = \"Landuse Vegetation\",\n             midpoint = NA) +\n tm_layout(main.title = \"Ensemble\",\n            main.title.position = \"center\",\n            main.title.size = 0.8,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            legend.title.size = 0.5,\n            legend.text.size = 0.4,\n            frame = TRUE) +\n  tm_compass(type=\"8star\", text.size = 0.5, size = 2, position=c(\"RIGHT\", \"TOP\")) +\n   tm_scale_bar(position=c(\"LEFT\", \"TOP\"),\n                text.size = 0.4)\n \n ensemble_map\n\n\ntmap_arrange(voronoi_map, idw_map, nn_map, ensemble_map)\n\n\nwriteRaster(pred_nn, \"~/IS485-Landslide/data/gwr_maps/landuse_nn.tif\", overwrite=TRUE)\nwriteRaster(pred_idw, \"~/IS485-Landslide/data/gwr_maps/landuse_idw.tif\", overwrite=TRUE)\nwriteRaster(pred_voronoi, \"~/IS485-Landslide/data/gwr_maps/landuse_voronoi.tif\", overwrite=TRUE)\nwriteRaster(pred_ensemble, \"~/IS485-Landslide/data/gwr_maps/landuse_ensemble.tif\", overwrite=TRUE)\n\n\n\n\nWe can assess the performance of each of the methods presented above using K-fold cross-validation and the root mean squared error (RMSE). First, we split the data in K parts. For each part, we use the remaining K−1 parts (training data) to fit the model and that part (testing data) to predict. We compute the RMSE by comparing the testing and predicted data in each of the K parts.\nNote that if K is equal to the number of observations n, this procedure is called leave-one-out cross-validation (LOOCV). That means that n separate data sets are trained on all of the data except one observation, and then prediction is made for that one observation.\nHere, we assess the performance of each of the methods previously employed to predict the prices of apartments in Athens. We create training and testing sets by using the dismo:kfold() function of the dismo package (Hijmans et al. 2022) to randomly assign the observations to K=5 groups of roughly equal size. For each group, we fit the model using the training data, and obtain predictions of the testing data. We calculate the RMSEs of each part and average the RMSEs to obtain a K-fold cross-validation estimate.\n\npacman::p_load(dismo)\n\n\nRMSE &lt;- function(observed, predicted) {\nsqrt(mean((observed - predicted)^2))\n}\n\n# Split data in 5 sets\nkf &lt;- dismo::kfold(nrow(regression.points), k = 5) # K-fold partitioning\n\n# Vectors to store the RMSE values obtained with each method\nrmse1 &lt;- rep(NA, 5) # Closest observation\nrmse2 &lt;- rep(NA, 5) # IDW\nrmse3 &lt;- rep(NA, 5) # Nearest neighbors\nrmse4 &lt;- rep(NA, 5) # Ensemble\n\n\nfor(k in 1:5) {\n# Split data in test and train\ntest &lt;- regression.points[kf == k, ]\ntrain &lt;- regression.points[kf != k, ]\n\n# Closest observation\nv &lt;- terra::voronoi(x = terra::vect(regression.points), bnd = valtellina_boundary)\nv &lt;- st_as_sf(v)\np1 &lt;- st_intersection(v, coop)$Landuse_Vegetation\nrmse1[k] &lt;- RMSE(test$Landuse_Vegetation, p1)\n\n# IDW\ngs &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = nrow(regression.points),\n            set = list(idp = 1))\np2 &lt;- predict(gs, coop)$var1.pred\nrmse2[k] &lt;- RMSE(test$Landuse_Vegetation, p2)\n\n# Nearest neighbors\nnn &lt;- gstat(formula = Landuse_Vegetation ~ 1, locations = regression.points, nmax = 5,\n            set = list(idp = 0))\np3 &lt;- predict(nn, coop)$var1.pred\nrmse3[k] &lt;- RMSE(test$Landuse_Vegetation, p3)\n\n# Ensemble (weights are inverse RMSE so lower RMSE higher weight)\nw &lt;- 1/c(rmse1[k], rmse2[k], rmse3[k])\nweights &lt;- w/sum(w)\np4 &lt;- p1 * weights[1] + p2 * weights[2] + p3 * weights[3]\nrmse4[k] &lt;- RMSE(test$Landuse_Vegetation, p4)\n}\n\nThe RMSE values obtained in each of the 5 splits are shown below.\n\n# RMSE obtained for each of the 5 splits\ndata.frame(closest.obs = rmse1, IDW = rmse2,\n           nearest.neigh = rmse3, ensemble = rmse4)\n\nWe see the minimum average RMSE corresponds to the ensemble method.\n\n# Average RMSE over the 5 splits\ndata.frame(closest.obs = mean(rmse1), IDW = mean(rmse2),\n           nearest.neigh = mean(rmse3), ensemble = mean(rmse4))"
  },
  {
    "objectID": "slopesampling.html#page-break",
    "href": "slopesampling.html#page-break",
    "title": "Slope-Based Stratified Sampling",
    "section": "",
    "text": "write.csv(sample_Q6, \"~/IS485-Landslide/data/aspatial/slope_20degree.csv\")\nwrite.csv(sample_Q7, \"~/IS485-Landslide/data/aspatial/slope_15degree.csv\")"
  },
  {
    "objectID": "data/vector/train_point.html",
    "href": "data/vector/train_point.html",
    "title": "",
    "section": "",
    "text": "&lt;!DOCTYPE qgis PUBLIC ‘http://mrcc.com/qgis.dtd’ ‘SYSTEM’&gt;     \n\n\n                  0 0     false"
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "",
    "section": "",
    "text": "Landslide susceptibility assessment is an emerging research area of both importance and urgency and several approaches and models have been explored in scientific literature. These models can be generally categorized into four categories: expert-based, physically-based, statistical and machine learning-based.\n\nPhysically-based models are of the highest utility in theory [d], but such models often face challenges and uncertainties for real-world application due to the limited availability of spatially differentiated geotechnical data.\nCompared to physically-based models, expert-based models are less data-intensive as they are developed with the expert knowledge of local interactions between landslide occurrences and its controlling factors (Steger et al., 2019). Due to its qualitative nature, expert-based models often lack objectivity and reproducibility, and are not commonly used in scientific research.\nStatistical landslide susceptibility modelling seeks to estimate the spatial likelihood or relative spatial probability of spatial units to coincide with future landslide occurrence (Steger et al., 2019). These models have been widely adopted for practical application due to their relatively lower input data demand (than physically based models) and quantitative modelling output (which expert-based models lack).\nMachine learning models have emerged as promising alternatives to statistical-driven models due to their flexibility and potential for high predictive accuracy.\n\nNevertheless, previous research has demonstrated that each model type has its unique strengths and limitations, and choosing an appropriate model depends largely on various factors, such as interpretability, generalizability, and the specific research objectives.\nOur study focuses on comparing the performance and applications of statistical and machine learning models in landslide susceptibility assessment.\n\nPrecition Task: The first part involves using both approaches to predict landslide susceptibility through binary classification (landslide presence/absence). We will explore and evaulate whether data mining and machine learning methods perform better than stati\nAnalytical Task: Subsequently, the explanatory variables will be evaluated through global and local statistical models to understand the influence and significance of different landslide predisposing factors. We will identify (i) landform properties and (ii) human-environment interaction factors affecting landslide susceptibility results. We will also examine whether susceptibility is geospatially independent.\n\nThe differentiation between spatial prediction tasks and analytical tasks provides comprehensive review of the model performance and applications.\n\n\n\n\n\nIn practice, relationships between variables may be nonstationary. However, traditional regression models assume that predictors and outcome variables are spatially homogeneous, or stationary.\nOrdinary least squares (OLS) linear regression is a standard global modelling technique that cannot detect nonstationarity, and thus using it may obscure regional variation in the relationships between predictors and the outcome variable.\nGWR extends the ordinary least-sqaures regression framework by allowing local rather than global parameters to be estimated. That is, we allow a continuous surface of parameter values, and measurements of this surface are taken at certain points to denote the spatial variability of the surface. Thus, GWR accounts for spatial variations in relationships might exist and provides a way in which they can be measured. \nSpatial Weights\nSpatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates. Formally, the weights express the neighbour structure between the observations as a n×n matrix, in which the elements wij of the matrix are the spatial weights."
  },
  {
    "objectID": "methodology.html#explanatory-and-predictive-landslide-susceptibility-modelling-using-statistical-and-machine-learning-techniques-case-study-of-valtellina-valley-italy",
    "href": "methodology.html#explanatory-and-predictive-landslide-susceptibility-modelling-using-statistical-and-machine-learning-techniques-case-study-of-valtellina-valley-italy",
    "title": "",
    "section": "",
    "text": "Landslide susceptibility assessment is an emerging research area of both importance and urgency and several approaches and models have been explored in scientific literature. These models can be generally categorized into four categories: expert-based, physically-based, statistical and machine learning-based.\n\nPhysically-based models are of the highest utility in theory [d], but such models often face challenges and uncertainties for real-world application due to the limited availability of spatially differentiated geotechnical data.\nCompared to physically-based models, expert-based models are less data-intensive as they are developed with the expert knowledge of local interactions between landslide occurrences and its controlling factors (Steger et al., 2019). Due to its qualitative nature, expert-based models often lack objectivity and reproducibility, and are not commonly used in scientific research.\nStatistical landslide susceptibility modelling seeks to estimate the spatial likelihood or relative spatial probability of spatial units to coincide with future landslide occurrence (Steger et al., 2019). These models have been widely adopted for practical application due to their relatively lower input data demand (than physically based models) and quantitative modelling output (which expert-based models lack).\nMachine learning models have emerged as promising alternatives to statistical-driven models due to their flexibility and potential for high predictive accuracy.\n\nNevertheless, previous research has demonstrated that each model type has its unique strengths and limitations, and choosing an appropriate model depends largely on various factors, such as interpretability, generalizability, and the specific research objectives.\nOur study focuses on comparing the performance and applications of statistical and machine learning models in landslide susceptibility assessment.\n\nPrecition Task: The first part involves using both approaches to predict landslide susceptibility through binary classification (landslide presence/absence). We will explore and evaulate whether data mining and machine learning methods perform better than stati\nAnalytical Task: Subsequently, the explanatory variables will be evaluated through global and local statistical models to understand the influence and significance of different landslide predisposing factors. We will identify (i) landform properties and (ii) human-environment interaction factors affecting landslide susceptibility results. We will also examine whether susceptibility is geospatially independent.\n\nThe differentiation between spatial prediction tasks and analytical tasks provides comprehensive review of the model performance and applications.\n\n\n\n\n\nIn practice, relationships between variables may be nonstationary. However, traditional regression models assume that predictors and outcome variables are spatially homogeneous, or stationary.\nOrdinary least squares (OLS) linear regression is a standard global modelling technique that cannot detect nonstationarity, and thus using it may obscure regional variation in the relationships between predictors and the outcome variable.\nGWR extends the ordinary least-sqaures regression framework by allowing local rather than global parameters to be estimated. That is, we allow a continuous surface of parameter values, and measurements of this surface are taken at certain points to denote the spatial variability of the surface. Thus, GWR accounts for spatial variations in relationships might exist and provides a way in which they can be measured. \nSpatial Weights\nSpatial weights are a key component in any cross-sectional analysis of spatial dependence. They are an essential element in the construction of spatial autocorrelation statistics, and provide the means to create spatially explicit variables, such as spatially lagged variables and spatially smoothed rates. Formally, the weights express the neighbour structure between the observations as a n×n matrix, in which the elements wij of the matrix are the spatial weights."
  },
  {
    "objectID": "methodology.html#strengths",
    "href": "methodology.html#strengths",
    "title": "",
    "section": "Strengths",
    "text": "Strengths\nUsing machine learning models like Frequency Ratio (FR) and Analytic Hierarchy Process (AHP) can facilitate the adoption of appropriate mitigation measures against landslides (Goswami et. al, 2023).\nML models have been favoured for its ability to solve nonlinear problems, improve predictive performance across various classifiers (Song et al., 2023) and capture non-linear relationships between variables (Achu et al., 2023).\nThe compounding effect of ML models is that they can combine the predictions of multiple ML techniques which can improve the robustness and reliability of landslide susceptibility maps (Achu et al., 2023)."
  },
  {
    "objectID": "methodology.html#concerns",
    "href": "methodology.html#concerns",
    "title": "",
    "section": "Concerns",
    "text": "Concerns\nDespite its strengths, the performance of machine learning models can be affected by sample imbalances when landslide samples are much smaller than non-landslide samples, which can cause low recall rates and decreased predictive ability for landslide samples.\nFurthermore, machine learning models are at risk of poorer performance when faced with new or unseen data that differs significantly from the training data.\n\nTemporal Differences: Training data collected at different time periods than the new data lead to variations in environmental conditions, demographics and other factors that can affect relationships (Yao et al., 2023).\nSpatial Differences: When training data is collected from a specific location, new data from a different region with different characteristics and landslide distributions can challenge established underlying relationships (Yao et al., 2023).\n\nParticularly in landslide identification, machine learning models are lacking in the identification of landslide types and digital terrain model dominant landslide identification using machine learning has not been explored.\n\n4.0 Research Design\n\n\n5.0 References\n\nCascini, L.: Applicability of landslide susceptibility and hazard zoning at different scales. Engineering Geology. 102, 164–177 (2008).\nFrattini, P., Crosta, G., Carrara, A.: Techniques for evaluating the performance of landslide susceptibility models. Engineering Geology. 111, 62–72 (2010).\nGuzzetti, F., Carrara, A., Cardinali, M., Reichenbach, P.: Landslide hazard evaluation: A review of current techniques and their application in a multi-scale study, Central Italy. Geomorphology. 31, 181–216 (1999).\nKuriakose, S.L., van Beek, L.P., van Westen, C.J.: Parameterizing a physically based shallow landslide model in a data poor region. Earth Surface Processes and Landforms. 34, 867–881 (2009).\nRuff, M., Czurda, K.: Landslide susceptibility analysis with a heuristic approach in the eastern alps (Vorarlberg, Austria). Geomorphology. 94, 314–324 (2008).\nSteger, S., Kofler, C.: Statistical Modeling of Landslides: Landslide Susceptibility and Beyond. In: Pourghasemi, H.R. and Gokceoglu, C. (eds.) Spatial modeling in GIS and R for earth and environmental sciences. pp. 519–546. Elsevier, Amsterdam, Netherlands (2019).\nvan Westen, C.J., Rengers, N. & Soeters, R. Use of Geomorphological Information in Indirect Landslide Susceptibility Assessment. Natural Hazards 30, 399–419 (2003)."
  },
  {
    "objectID": "midterm_presentation.html#introduction",
    "href": "midterm_presentation.html#introduction",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Introduction",
    "text": "Introduction\n\nSignificance\n\n\nLandslides refer to the geomorphic phenomenon of slope failure and mass movement.\nIn the last five decades, the frequency of landslide events has increased tenfold [1]\nDespite comparatively lower casualty than other disasters, their impacts on urban development can be severely detrimental.\nCommonly-used extensive engineering prevention works are costly and challenging.\nLandslide susceptibility modelling enables decision-supporting for identifying highest-risk areas and conducting preventive measures"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-modelling-approaches",
    "href": "midterm_presentation.html#landslide-susceptibility-modelling-approaches",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Modelling Approaches",
    "text": "Landslide Susceptibility Modelling Approaches\n\n\n\n\n\nPhysically-based Modelling\n\n\nAnalytical outcomes from physical and mechanical principles\nSysteme Hydrologique Eropeen Transport (SHETRAN), TOPOG\nUncertainties mainly due to limited availability of spatially differentiated geotechnical data in real-world scenarios\n\n  \n\nExpert-based Modelling\n\n\nDeveloped with the expert knowledge of local interactions between landslide occurrences and its controlling factors\nQualitative multicriteria analysis (Abella & Western); Heuristics based on index (Ruff and Czurda)\nLimited reproducibility or comparability from one study to another due to subjectivity\n\n\n\n\n\nStatistical Modelling\n\n\nEstimate the relative spatial probability of spatial units aligning with future landslide incidents\nInformation Value (Thein, et al., 2023), Logistic Regression (Regmi et al., 2014; Sun et al., 2018), Maximum Entropy (Boussouf et al., 2023), Frequency Ratio (Wubalem, 2021; Ibrahim et al., 2021)\nReliance on numerical abstraction and statistical assumptions\n\n\nMachine Learning Modelling\n\n\nLearnt from trial-and-error without explicit programmed logic\nSupport Vector Machines (Ibrahim et al., 2021), Convolutional Neural Network (Wang et al, 2021), Random Forest (Kavzoglu & Teke, 2022), Decision Tree (Saha et al, 2021)​\nLimited interpretability and explainability due to the model complexity"
  },
  {
    "objectID": "midterm_presentation.html#research-design",
    "href": "midterm_presentation.html#research-design",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Research Design",
    "text": "Research Design"
  },
  {
    "objectID": "midterm_presentation.html#study-area",
    "href": "midterm_presentation.html#study-area",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Study Area",
    "text": "Study Area\n\n\n\nGeneral Information\n\n\nValtellina Valley, located in the Central Alps of Northern Italy\nBetween 9.24°E to 10.63°E in longitude, and 46.00°N to 46.64°N in latitude\nTotal area of 3308 square kilometers\nCharacterized by a superimposed fluvial morphology and high, steep slopes, akin to typical alpine glacial valleys\nExperienced significant damage and destruction caused by landslides such as the historic Valpola landslide and floods.\nSurge in economic activities and human settlements (wine agriculture & ski-towns)"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors",
    "href": "midterm_presentation.html#landslide-susceptibility-factors",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n\n \n\n\n\n\n\n\n\n\n\nFactor\nSource\nScale\nType\n\n\n\n\nTopographic Factors\n\n\n\n\n\n(1) Elevation\nGeoportale della Lombardia, DEM Derived (Raster)​\n15 x 15 m\nContinuous\n\n\n(2) Slope Angle\nGeoportale della Lombardia, DEM Derived (Raster)​\n15 x 15 m\nContinuous\n\n\n(3) Aspect\nGeoportale della Lombardia, DEM Derived (Raster)​\n15 x 15 m\nCategorical\n\n\n(4) Profile Curvature\nGeoportale della Lombardia, DEM Derived (Raster)​\n15 x 15 m\nContinuous\n\n\n(5) Plan Curvature\nGeoportale della Lombardia, DEM Derived (Raster)​\n15 x 15 m\nContinuous\n\n\nGeological Factors\n\n\n\n\n\n(6) Lithology\nBucci et al., 2021 (Raster)​\n15 x 15 m\nCategorical​\n\n\n(7) Distance to Fault\nGeoportale della Lombardia, DEM Derived (Raster) ​\n15 x 15 m\nContinuous​\n\n\nMeteorological Factors\n\n\n\n\n\n(8) Average Precipitation\nARPA Lombardia (Raster)\n15 x 15 m\nContinuous"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-1",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-1",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n\n \n\n\n\n\n\n\n\n\n\nFactor\nSource\nScale\nType\n\n\n\n\nHydrological Factors\n\n\n\n\n\n(9) Distance to Streams\nGeoportale della Lombardia, DEM Derived (Raster)\n15 x 15 m\nContinuous\n\n\n(10) Topographic Wetness Index\nGeoportale della Lombardia, DEM Derived (Raster)\n15 x 15 m\nContinuous\n\n\n(11) Steam Power Index\nGeoportale della Lombardia, DEM Derived (Raster)\n15 x 15 m\nCategorical\n\n\n(12) Sediment Transport Index\nGeoportale della Lombardia, DEM Derived (Raster)\n15 x 15 m\nContinuous\n\n\nAnthropogenic Factors\n\n\n\n\n\n(13) Distance to Settlements\nOpenStreetMap (Raster)\n15 x 15 m\nCategorical\n\n\n(14) Distance to Road Networks\nOpenStreetMap (Raster)\n15 x 15 m\nContinuous\n\n\n(15) Land Use Land Cover\nGeoportale della Lombardia, DEM Derived (Raster)\n15 x 15 m\nContinuous"
  },
  {
    "objectID": "midterm_presentation.html#data-pre-processing",
    "href": "midterm_presentation.html#data-pre-processing",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Data Pre-Processing",
    "text": "Data Pre-Processing\n \n\nTools and Applications Used"
  },
  {
    "objectID": "midterm_presentation.html#data-pre-processing-1",
    "href": "midterm_presentation.html#data-pre-processing-1",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Data Pre-Processing",
    "text": "Data Pre-Processing\n\n\n\n\n\nData Extraction\n\n\n\nDownload DEM and Raster Images\nClip the DEM image to confine the study area\nRun algorithms on QGIS, SAGA and ArcGIS Pro to extract topographic annd hydrological index values from DEM image\n\n\n\nData Wrangling\n\n\n\nRecategorise vector layers (lithology, landuse landcover using R)\nRaster vector layers (fault, stream, settlement) using R\nGenerate proximity maps using QGIS\nRescale and standardise the resolution of all the layers using QGIS"
  },
  {
    "objectID": "midterm_presentation.html#landslide-sampling",
    "href": "midterm_presentation.html#landslide-sampling",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Sampling",
    "text": "Landslide Sampling\n \n\n\n \n\nBody Mass Sampling\n\n\n \n\nMass Center Sampling\n\n\n \n\nRandom Point Sampling"
  },
  {
    "objectID": "midterm_presentation.html#landslide-sampling-1",
    "href": "midterm_presentation.html#landslide-sampling-1",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Sampling",
    "text": "Landslide Sampling\n\n\n\n\nMethodology\n\n\n\nGenerate a total of 5 random sampling points within each landslide and non-landslide area using QGIS \nCreate 15m by 15m grids per landslide sample point \n\n\n\n \nResultant Randomly Selected Points"
  },
  {
    "objectID": "midterm_presentation.html#data-pre-processing-2",
    "href": "midterm_presentation.html#data-pre-processing-2",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Data Pre-Processing",
    "text": "Data Pre-Processing\n \n\n\n\nZonal Statistic\n\n\n\nCalculating zonal statistics for each variable for each landslide zone on QGIS using mean value for raster layers and majority for vector layers\nCompiling all zonal statistics columns into a single dataset using R\n\n\n\nOne-Hot Encoding &  Binary Logic\n\n\n\nUse one-hot encoding to convert categorical data into numerical data to fit for model training using R\nOne resultant column from binary assignment for each categorical variable removed to avoid complete or quasi-complete separation and variance inflation"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-2",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-2",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nElevation\n\n\n \n\nSlope Degree"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-3",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-3",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nAspect\n\n\n \n\nLithology"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-4",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-4",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nProfile Curvature\n\n\n \n\nPlan Curvature"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-5",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-5",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nAverage Precipitation\n\n\n \n\nDistance to Fault"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-6",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-6",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nDistance to Stream\n\n\n \n\nTopographic Wetness Index"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-7",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-7",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nSteam Power Index\n\n\n \n\nSediment Transport Index"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-8",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-8",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nDistance to Settlement\n\n\n \n\nDistance to Road"
  },
  {
    "objectID": "midterm_presentation.html#landslide-susceptibility-factors-9",
    "href": "midterm_presentation.html#landslide-susceptibility-factors-9",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Landslide Susceptibility Factors",
    "text": "Landslide Susceptibility Factors\n \n\n\n\n \n\nLanduse Landcover"
  },
  {
    "objectID": "midterm_presentation.html#correlation-matrix",
    "href": "midterm_presentation.html#correlation-matrix",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Correlation Matrix",
    "text": "Correlation Matrix\n\n\n\n\nSlope Angle Distribution\n\n\n\n      0%      25%      50%      75%     100% \n 0.00000 18.41368 30.34639 38.54599 82.91669 \n\n\n\n\n\n\nCorrelation Matrix Code\n\n\nset.seed(123)\nggcorrmat(\n  data = sample_Q3[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10, pch.cex = 5, lab_size = 3\n  )) + \n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )\n\n\n\nCorrelation Matrix Output"
  },
  {
    "objectID": "midterm_presentation.html#variance-inflation-test",
    "href": "midterm_presentation.html#variance-inflation-test",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Variance Inflation Test",
    "text": "Variance Inflation Test\n \n\n\n\n\n\n\n\n\n\n\n\nLandslide Factors\nVIF\n TOLerance\n\n\n\n\nElevation\n2.488950\n0.401776\n\n\nSlope Angle\n1.596051\n0.626546\n\n\nAspect (N)\n1.837785\n0.544133\n\n\nAspect (NE)\n2.420200\n0.413189\n\n\nAspect (E)\n2.739139\n0.365078\n\n\nAspect (SE)\n2.914264\n0.365078\n\n\nAspect (S)\n3.200430\n0.312458\n\n\nAspect (SW)\n2.497585\n0.400387\n\n\nAspect (W)\n2.478521\n0.403466\n\n\nProfile Curvature\n1.316536\n0.759569\n\n\nPlan Curvature\n1.624930\n0.759569\n\n\nLithology (Metamorphic)\n4.437094\n0.225373\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLandslide Factors\nVIF\n TOLerance\n\n\n\n\nLithology (Sedimentary)\n3.238282\n0.308806\n\n\nLithology (Plutonic)\n1.909478\n0.523703\n\n\nLithology (Unconsolidated)\n4.437094\n0.225373\n\n\nDistance to Settlements\n1.733509\n0.576865\n\n\nDistance to Streams\n1.357373\n0.736717\n\n\nDistance to Road Networks\n1.871975\n0.534195\n\n\nDistance to Faults\n1.279720\n0.781421\n\n\nLanduse (Vegetation)\n1.580992\n0.632514\n\n\nAverage Precipitation\n1.242173\n0.805041\n\n\nTWI\n2.548388\n0.392405\n\n\nSPI\n1.182007\n0.846019\n\n\nSTI\n1.178955\n0.848209"
  },
  {
    "objectID": "midterm_presentation.html#logistic-regression",
    "href": "midterm_presentation.html#logistic-regression",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Logistic Regression",
    "text": "Logistic Regression\n\n\n\n\n\nDichotomous/binary nature of the dependent variable (presence or absence of a landslide)\nIndependent variables can be either discrete or continuous, and are not required to satisfy normal distribution\nEstimate the probability of landslide occurrences, with values ranging from 0 (absence of a landslide) to 1 (presence of a landslide)\n\n\n\n\n\nLogistic Regression Formula"
  },
  {
    "objectID": "midterm_presentation.html#geographically-weighted-regression",
    "href": "midterm_presentation.html#geographically-weighted-regression",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Geographically Weighted Regression",
    "text": "Geographically Weighted Regression\n \n\n\nExtends traditional and global regression frameworks such as OLS and LR by incorporating local parameters and spatial weights\nGWR is used to capture spatial heterogeneity of different landslide factors by generating coefficient estimates which vary based on location\nCalibrate the global LR model by assigning spatial weight to an observation determined by its proximity to location i"
  },
  {
    "objectID": "midterm_presentation.html#project-timeline",
    "href": "midterm_presentation.html#project-timeline",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Project Timeline",
    "text": "Project Timeline"
  },
  {
    "objectID": "midterm_presentation.html#hello-plot",
    "href": "midterm_presentation.html#hello-plot",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Hello Plot",
    "text": "Hello Plot"
  },
  {
    "objectID": "midterm_presentation.html#working-with-tabsets",
    "href": "midterm_presentation.html#working-with-tabsets",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Working with tabsets",
    "text": "Working with tabsets\n\nThe code chunkThe plot\n\n\n\n\npacman::p_load(tidyverse)\n\nexam_data &lt;- read_csv(\"C:/guacodemoleh/IS415-GAA/data/revealjs/Exam_data.csv\")\n\nggplot(data = exam_data,aes(x=MATHS)) +\n  geom_histogram(bins=10,\n                 boundary=100,\n                 color='black',\n                 fill=\"light blue\") +\n  ggtitle(\"Distribution of Maths Scores\")"
  },
  {
    "objectID": "midterm_presentation.html#adding-a-static-table",
    "href": "midterm_presentation.html#adding-a-static-table",
    "title": "IS Project Experience (SMT Research) ",
    "section": "Adding a Static Table",
    "text": "Adding a Static Table\n\n\n\n\n\nID\nCLASS\nGENDER\nRACE\nENGLISH\nMATHS\nSCIENCE\n\n\n\n\nStudent321\n3I\nMale\nMalay\n21\n9\n15\n\n\nStudent305\n3I\nFemale\nMalay\n24\n22\n16\n\n\nStudent289\n3H\nMale\nChinese\n26\n16\n16\n\n\nStudent227\n3F\nMale\nChinese\n27\n77\n31\n\n\nStudent318\n3I\nMale\nMalay\n27\n11\n25\n\n\nStudent306\n3I\nFemale\nMalay\n31\n16\n16\n\n\nStudent313\n3I\nMale\nChinese\n31\n21\n25\n\n\nStudent316\n3I\nMale\nMalay\n31\n18\n27"
  },
  {
    "objectID": "gwsmodelling_new.html",
    "href": "gwsmodelling_new.html",
    "title": "GWS Modelling: Parametric Testing",
    "section": "",
    "text": "To develop a landslide susceptibility methodology framework, we will explore and calibrate different statistical and machine learning models. This page focuses on statistical models first."
  },
  {
    "objectID": "gwsmodelling_new.html#logistic-regression-model-1",
    "href": "gwsmodelling_new.html#logistic-regression-model-1",
    "title": "GWS Modelling: Parametric Testing",
    "section": "4.1 Logistic Regression Model 1",
    "text": "4.1 Logistic Regression Model 1\nUnder general logistic regression, all variables are considered first.\n\nset.seed(1234)\n\nlandslide.lr &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = train_grids_v4)\n\n\nsummary(landslide.lr)\n\n\nCall:\nglm(formula = Landslide ~ Elevation + Slope_Angle + Aspect_North + \n    Aspect_NorthEast + Aspect_East + Aspect_SouthEast + Aspect_South + \n    Aspect_SouthWest + Aspect_West + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Sedimentary + Lithology_Plutonic + \n    Lithology_Unconsolidated + Proximity_Settlement + Proximity_Stream + \n    Proximity_Road + Proximity_Fault + Landuse_Vegetation + Precipitation + \n    TWI + SPI + STI, family = \"binomial\", data = train_grids_v4)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.243e+00  1.893e-01 -11.847  &lt; 2e-16 ***\nElevation                 5.790e-05  3.517e-05   1.646 0.099718 .  \nSlope_Angle               1.706e-01  1.954e-03  87.343  &lt; 2e-16 ***\nAspect_North             -3.510e-02  8.618e-02  -0.407 0.683821    \nAspect_NorthEast         -2.225e-01  7.213e-02  -3.084 0.002041 ** \nAspect_East              -1.617e-01  7.128e-02  -2.268 0.023321 *  \nAspect_SouthEast         -2.401e-01  6.917e-02  -3.472 0.000517 ***\nAspect_South             -1.812e-01  6.829e-02  -2.653 0.007975 ** \nAspect_SouthWest         -4.600e-02  6.949e-02  -0.662 0.508031    \nAspect_West              -4.762e-02  7.108e-02  -0.670 0.502869    \nProfile_Curvature        -6.228e+02  1.777e+01 -35.052  &lt; 2e-16 ***\nPlan_Curvature           -5.890e+02  2.009e+01 -29.320  &lt; 2e-16 ***\nLithology_Metamorphic     1.109e+00  9.629e-02  11.522  &lt; 2e-16 ***\nLithology_Sedimentary     1.577e+00  1.005e-01  15.687  &lt; 2e-16 ***\nLithology_Plutonic       -3.030e-02  8.847e-02  -0.343 0.731946    \nLithology_Unconsolidated  1.499e+00  9.792e-02  15.312  &lt; 2e-16 ***\nProximity_Settlement      4.360e-05  2.970e-05   1.468 0.142100    \nProximity_Stream         -6.250e-03  1.593e-03  -3.924 8.72e-05 ***\nProximity_Road           -2.343e-03  1.026e-03  -2.283 0.022445 *  \nProximity_Fault          -1.315e-04  1.615e-05  -8.146 3.77e-16 ***\nLanduse_Vegetation        6.692e-01  4.060e-02  16.483  &lt; 2e-16 ***\nPrecipitation            -3.469e+00  4.229e-01  -8.202 2.37e-16 ***\nTWI                      -1.067e-01  9.637e-03 -11.067  &lt; 2e-16 ***\nSPI                       1.191e+00  7.010e-01   1.699 0.089396 .  \nSTI                      -5.287e-04  7.677e-04  -0.689 0.491022    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 22929  on 50538  degrees of freedom\nAIC: 22979\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n100*with(summary(landslide.lr), 1 - deviance/null.deviance)\n\n[1] 50.89114\n\nconfint(landslide.lr)\n\nWaiting for profiling to be done...\n\n\n                                 2.5 %        97.5 %\n(Intercept)              -2.614798e+00 -1.872528e+00\nElevation                -1.100535e-05  1.268617e-04\nSlope_Angle               1.668213e-01  1.744792e-01\nAspect_North             -2.036349e-01  1.342130e-01\nAspect_NorthEast         -3.639457e-01 -8.116805e-02\nAspect_East              -3.014909e-01 -2.205432e-02\nAspect_SouthEast         -3.758587e-01 -1.047178e-01\nAspect_South             -3.152073e-01 -4.749895e-02\nAspect_SouthWest         -1.823284e-01  9.008984e-02\nAspect_West              -1.870295e-01  9.162142e-02\nProfile_Curvature        -6.577535e+02 -5.880979e+02\nPlan_Curvature           -6.284441e+02 -5.496984e+02\nLithology_Metamorphic     9.214128e-01  1.298931e+00\nLithology_Sedimentary     1.380869e+00  1.775060e+00\nLithology_Plutonic       -2.039839e-01  1.428812e-01\nLithology_Unconsolidated  1.308214e+00  1.692127e+00\nProximity_Settlement     -1.450154e-05  1.019138e-04\nProximity_Stream         -9.364838e-03 -3.120470e-03\nProximity_Road           -4.349682e-03 -3.261896e-04\nProximity_Fault          -1.631453e-04 -9.983405e-05\nLanduse_Vegetation        5.897524e-01  7.489057e-01\nPrecipitation            -4.298446e+00 -2.640479e+00\nTWI                      -1.256194e-01 -8.783854e-02\nSPI                      -1.375593e-01  2.613875e+00\nSTI                      -2.021054e-03  9.886275e-04\n\n\n\nvif(landslide.lr)\n\n               Elevation              Slope_Angle             Aspect_North \n                2.362748                 1.691170                 1.497475 \n        Aspect_NorthEast              Aspect_East         Aspect_SouthEast \n                1.905428                 1.954287                 2.093957 \n            Aspect_South         Aspect_SouthWest              Aspect_West \n                2.145022                 2.027933                 1.927346 \n       Profile_Curvature           Plan_Curvature    Lithology_Metamorphic \n                1.422228                 1.487571                 7.443019 \n   Lithology_Sedimentary       Lithology_Plutonic Lithology_Unconsolidated \n                5.130757                 1.910924                 7.685545 \n    Proximity_Settlement         Proximity_Stream           Proximity_Road \n                1.787204                 1.293758                 1.818813 \n         Proximity_Fault       Landuse_Vegetation            Precipitation \n                1.058314                 1.387744                 1.297600 \n                     TWI                      SPI                      STI \n                2.201753                 1.308706                 1.308264 \n\n\n\n4.1.1 Stepwise Selection\nFor the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind including not too many variables is that the model would be overfitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use blr_step_aic_both() to shortlist predictors for our model.\n\nblr_step_aic_both(landslide.lr)\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1 . Elevation \n2 . Slope_Angle \n3 . Aspect_North \n4 . Aspect_NorthEast \n5 . Aspect_East \n6 . Aspect_SouthEast \n7 . Aspect_South \n8 . Aspect_SouthWest \n9 . Aspect_West \n10 . Profile_Curvature \n11 . Plan_Curvature \n12 . Lithology_Metamorphic \n13 . Lithology_Sedimentary \n14 . Lithology_Plutonic \n15 . Lithology_Unconsolidated \n16 . Proximity_Settlement \n17 . Proximity_Stream \n18 . Proximity_Road \n19 . Proximity_Fault \n20 . Landuse_Vegetation \n21 . Precipitation \n22 . TWI \n23 . SPI \n24 . STI \n\n\nVariables Entered/Removed: \n\n- Slope_Angle added \n- Profile_Curvature added \n- Plan_Curvature added \n- Landuse_Vegetation added \n- Lithology_Plutonic added \n- Precipitation added \n- Proximity_Fault added \n- TWI added \n- Lithology_Sedimentary added \n- Lithology_Unconsolidated added \n- Lithology_Metamorphic added \n- Lithology_Plutonic removed \n- Proximity_Stream added \n- Aspect_SouthEast added \n- Aspect_NorthEast added \n- Aspect_South added \n- Aspect_East added \n- SPI added \n\nNo more variables to be added or removed.\n\n\n\n                              Stepwise Summary                               \n---------------------------------------------------------------------------\nVariable                     Method        AIC          BIC       Deviance  \n---------------------------------------------------------------------------\nSlope_Angle                 addition    27757.416    27775.078    27753.416 \nProfile_Curvature           addition    25065.141    25091.634    25059.141 \nPlan_Curvature              addition    24303.970    24339.294    24295.970 \nLanduse_Vegetation          addition    23891.260    23935.415    23881.260 \nLithology_Plutonic          addition    23677.727    23730.713    23665.727 \nPrecipitation               addition    23539.203    23601.020    23525.203 \nProximity_Fault             addition    23430.433    23501.081    23414.433 \nTWI                         addition    23337.014    23416.493    23319.014 \nLithology_Sedimentary       addition    23278.363    23366.672    23258.363 \nLithology_Unconsolidated    addition    23148.835    23245.976    23126.835 \nLithology_Metamorphic       addition    22999.689    23105.661    22975.689 \nLithology_Plutonic          removal     22997.760    23094.901    22975.760 \nProximity_Stream            addition    22989.371    23095.343    22965.371 \nAspect_SouthEast            addition    22984.054    23098.857    22958.054 \nAspect_NorthEast            addition    22979.924    23103.558    22951.924 \nAspect_South                addition    22975.790    23108.254    22945.790 \nAspect_East                 addition    22972.549    23113.844    22940.549 \nSPI                         addition    22971.964    23122.090    22937.964 \n---------------------------------------------------------------------------\n\n\n\n\n\n\n\n\nStepwise Selection Result\n\n\n\n16 explanatory variables have been selected\n\n\nPlotting the Akaike Information Criterion curve as it is the main threshold.\n\nlandslide.lr %&gt;%\n  blr_step_aic_both() %&gt;%\n  plot()\n\nStepwise Selection Method \n-------------------------\n\nCandidate Terms: \n\n1 . Elevation \n2 . Slope_Angle \n3 . Aspect_North \n4 . Aspect_NorthEast \n5 . Aspect_East \n6 . Aspect_SouthEast \n7 . Aspect_South \n8 . Aspect_SouthWest \n9 . Aspect_West \n10 . Profile_Curvature \n11 . Plan_Curvature \n12 . Lithology_Metamorphic \n13 . Lithology_Sedimentary \n14 . Lithology_Plutonic \n15 . Lithology_Unconsolidated \n16 . Proximity_Settlement \n17 . Proximity_Stream \n18 . Proximity_Road \n19 . Proximity_Fault \n20 . Landuse_Vegetation \n21 . Precipitation \n22 . TWI \n23 . SPI \n24 . STI \n\n\nVariables Entered/Removed: \n\n- Slope_Angle added \n- Profile_Curvature added \n- Plan_Curvature added \n- Landuse_Vegetation added \n- Lithology_Plutonic added \n- Precipitation added \n- Proximity_Fault added \n- TWI added \n- Lithology_Sedimentary added \n- Lithology_Unconsolidated added \n- Lithology_Metamorphic added \n- Lithology_Plutonic removed \n- Proximity_Stream added \n- Aspect_SouthEast added \n- Aspect_NorthEast added \n- Aspect_South added \n- Aspect_East added \n- SPI added \n\nNo more variables to be added or removed.\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nIn our first stepwise selection, Slope_Angle has the highest AIC value followed by Profile_Curvature.\n\n\n\n\n4.1.2 Validating Logistic Regression Model 1\n\ncm &lt;- blr_confusion_matrix(landslide.lr, cutoff = 0.5)\n\ncm\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0  6548  1292\n         1  2235 40488\n\n                Accuracy : 0.9302 \n     No Information Rate : 0.1737 \n\n                   Kappa : 0.7462 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.9691 \n             Specificity : 0.7455 \n          Pos Pred Value : 0.9477 \n          Neg Pred Value : 0.8352 \n              Prevalence : 0.8263 \n          Detection Rate : 0.8007 \n    Detection Prevalence : 0.8449 \n       Balanced Accuracy : 0.8573 \n               Precision : 0.9477 \n                  Recall : 0.9691 \n\n        'Positive' Class : 1"
  },
  {
    "objectID": "gwsmodelling_new.html#logistic-regression-model-2",
    "href": "gwsmodelling_new.html#logistic-regression-model-2",
    "title": "GWS Modelling: Parametric Testing",
    "section": "4.2 Logistic Regression Model 2",
    "text": "4.2 Logistic Regression Model 2\nHere, we recalibrate the model by updating the logistic regression with the selected variables.\n\nset.seed(1234)\n\nlandslide.lr2 &lt;- glm(Landslide ~ Slope_Angle + Aspect_SouthEast + Aspect_NorthEast + Aspect_South + Aspect_East + Profile_Curvature +Plan_Curvature +Lithology_Metamorphic+Lithology_Unconsolidated+ Lithology_Sedimentary+Proximity_Stream+Landuse_Vegetation+TWI+SPI, family = \"binomial\", data = train_grids_v4)\n\n\nsummary(landslide.lr2)\n\n\nCall:\nglm(formula = Landslide ~ Slope_Angle + Aspect_SouthEast + Aspect_NorthEast + \n    Aspect_South + Aspect_East + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Unconsolidated + Lithology_Sedimentary + \n    Proximity_Stream + Landuse_Vegetation + TWI + SPI, family = \"binomial\", \n    data = train_grids_v4)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.989e+00  1.226e-01 -24.386  &lt; 2e-16 ***\nSlope_Angle               1.699e-01  1.938e-03  87.672  &lt; 2e-16 ***\nAspect_SouthEast         -1.803e-01  5.117e-02  -3.523 0.000426 ***\nAspect_NorthEast         -2.012e-01  5.559e-02  -3.620 0.000295 ***\nAspect_South             -1.292e-01  4.982e-02  -2.593 0.009514 ** \nAspect_East              -1.277e-01  5.427e-02  -2.353 0.018603 *  \nProfile_Curvature        -6.192e+02  1.760e+01 -35.183  &lt; 2e-16 ***\nPlan_Curvature           -5.746e+02  1.953e+01 -29.417  &lt; 2e-16 ***\nLithology_Metamorphic     1.265e+00  7.068e-02  17.898  &lt; 2e-16 ***\nLithology_Unconsolidated  1.657e+00  7.387e-02  22.433  &lt; 2e-16 ***\nLithology_Sedimentary     1.797e+00  7.644e-02  23.510  &lt; 2e-16 ***\nProximity_Stream         -2.702e-03  1.486e-03  -1.818 0.069028 .  \nLanduse_Vegetation        6.586e-01  3.592e-02  18.336  &lt; 2e-16 ***\nTWI                      -1.088e-01  9.222e-03 -11.796  &lt; 2e-16 ***\nSPI                       7.985e-01  6.022e-01   1.326 0.184876    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 46691  on 50562  degrees of freedom\nResidual deviance: 23127  on 50548  degrees of freedom\nAIC: 23157\n\nNumber of Fisher Scoring iterations: 7\n\n\n\n\n\n\n\n\nObservation\n\n\n\nModel is still overfitting and AIC is very high.\n\n\n\n4.2.1 Validating Logistic Regression Model 2\n\ncm2 &lt;- blr_confusion_matrix(landslide.lr2, cutoff = 0.5)\n\ncm2\n\nConfusion Matrix and Statistics \n\n          Reference\nPrediction     0     1\n         0  6514  1274\n         1  2269 40506\n\n                Accuracy : 0.9299 \n     No Information Rate : 0.1737 \n\n                   Kappa : 0.7445 \n\nMcNemars's Test P-Value  : 0.0000 \n\n             Sensitivity : 0.9695 \n             Specificity : 0.7417 \n          Pos Pred Value : 0.9470 \n          Neg Pred Value : 0.8364 \n              Prevalence : 0.8263 \n          Detection Rate : 0.8011 \n    Detection Prevalence : 0.8460 \n       Balanced Accuracy : 0.8556 \n               Precision : 0.9470 \n                  Recall : 0.9695 \n\n        'Positive' Class : 1\n\n\n\n\n4.2.2 Comparing LR Models 1 & 2\nThe two models thus far yield similar results with small changes in accuracy, sensitivity and specificity despite a reduced number of variables from the first to the second model.\n\n\n\n4.2.3 Weight of Evidence & Information Value\nWeight of Evidence (WoE) is a variable transformation technique meant for independent variables according to Information Theory. WoE measures how good each grouped attribute or bin of a feature can predict the target variable.\nWoE is formulated as:\n\\[\nW~i^+ = ln \\frac{P\\{E~i/I\\}}{P\\{E~i/\\overline{I}\\}}\n\\]\n\\[\nW~i^- = ln \\frac{P\\{\\overline{E}~i/I\\}}{P\\{\\overline{E}~-i/\\overline{I}\\}}\n\\]\n\\[\nW~i = W~i^+ + W~i^-\n\\]\nInformation value (IV) explains the predictive power of the entirety of the feature.\n\nHere is the IV for all the predictors.\n\nlibrary(\"Information\")\n\nIV &lt;- create_infotables(data=train_grids_v4[, 5:29],\n                        valid=train_grids_v4[, 5:29],\n                        y=\"Landslide\")\nkable(IV$Summary[,1:2], row.names=FALSE)\n\n\n\n\nVariable\nIV\n\n\n\n\nSlope_Angle\n5.3574828\n\n\nTWI\n0.5119619\n\n\nElevation\n0.3270770\n\n\nProximity_Settlement\n0.2073722\n\n\nProximity_Road\n0.2060752\n\n\nProfile_Curvature\n0.1481448\n\n\nPlan_Curvature\n0.1469663\n\n\nPrecipitation\n0.1097135\n\n\nLithology_Unconsolidated\n0.1047331\n\n\nProximity_Fault\n0.0931591\n\n\nLithology_Sedimentary\n0.0770191\n\n\nLanduse_Vegetation\n0.0758787\n\n\nProximity_Stream\n0.0606072\n\n\nLithology_Metamorphic\n0.0243440\n\n\nLithology_Plutonic\n0.0184281\n\n\nAspect_East\n0.0028829\n\n\nAspect_SouthEast\n0.0025985\n\n\nAspect_South\n0.0020174\n\n\nAspect_North\n0.0019081\n\n\nAspect_West\n0.0011630\n\n\nSTI\n0.0008136\n\n\nSPI\n0.0007769\n\n\nAspect_SouthWest\n0.0000422\n\n\nAspect_NorthEast\n0.0000023\n\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nSlope_Angle indeed has the most predictive power compared to other variables.\n\n\nSlope_Angle has to be further investigated to understand why it has the greatest predictive power.\n\n\n4.2.4 Slope Distribution\nOur data points are located in various places with varying slope angles. Since our initial IV analysis flags out its influence over our model results, the slope distribution can be first viewed with a histogram.\nDistribution of Landslide Samples\n\nls_data &lt;- train_grids_v4[train_grids_v4$Landslide==1,]\n\nggplot(data=ls_data, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=100, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in landslide samples\") + \n  geom_vline(xintercept = 20, color = \"red\")\n\n\n\n\nDistribution of Non-Landslide Samples\n\nnon_ls_data &lt;- train_grids_v4[train_grids_v4$Landslide==0,]\n\nggplot(data=non_ls_data, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=100, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in non-landslide samples\") + \n  geom_vline(xintercept = 20, color = \"red\")\n\n\n\n\n\nQuasi-separation Present\nThe majority of landslide samples have slope angles larger than 20°. In similar contrast, the majority of non-landslide samples have slope angles less than 20°.\nAs such, the model currently predicts any instances with a slope angle greater than 20° to be a landslide."
  },
  {
    "objectID": "gwsmodelling_new.html#logistic-regression-model-3",
    "href": "gwsmodelling_new.html#logistic-regression-model-3",
    "title": "GWS Modelling: Parametric Testing",
    "section": "4.3 Logistic Regression Model 3",
    "text": "4.3 Logistic Regression Model 3\n\n4.3.1 Stratified Slope Sampling\nTo address the data bias with the evidence of quasi-separation, we use a 15° cut-off based on the first quantile result and slope (%) reference from the Barcelona Field Studies Centre.\n\nslope_angle &lt;- train_grids_v4$Slope_Angle\n\nquantile(slope_angle, probs = seq(0, 1, 0.25))\n\n      0%      25%      50%      75%     100% \n 0.00000 18.41368 30.34639 38.54599 82.91669 \n\n\n\n\n\nStandard Slope Descriptors (Source: Barcelona Field Studies Centre)\n\n\nDistribution of Landslide Samples\n\nls_data_15 &lt;- train_grids_v4[train_grids_v4$Landslide==1 & train_grids_v4$Slope_Angle &lt;= 15,]\n\nggplot(data=ls_data_15, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=40, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in landslide samples (15° slope cut-off)\")\n\n\n\n\nDistribution of Non-Landslide Samples\n\nnon_ls_data_15 &lt;- train_grids_v4[train_grids_v4$Landslide==0 & train_grids_v4$Slope_Angle &lt;= 15,]\n\nggplot(data=non_ls_data_15, aes(x= `Slope_Angle`)) +\n  geom_histogram(bins=40, color=\"black\", fill=\"#e9531e\") +\n  labs(title=\"Distribution of slope values in non-landslide samples (15° slope cut-off)\")\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\nAlthough the distribution for this stratified non-landslide sample is left-skewed, the data skewness has been reduced significantly.\n\n\nWe then perform the logistic regression model with the stratified sample.\n\nlandslide.lr3 &lt;- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = \"binomial\", data = data_15)\n\n\n\n4.3.2 Validating Logistic Regression Model 3\n\nsummary(landslide.lr3)\n\n\nCall:\nglm(formula = Landslide ~ Elevation + Slope_Angle + Aspect_North + \n    Aspect_NorthEast + Aspect_East + Aspect_SouthEast + Aspect_South + \n    Aspect_SouthWest + Aspect_West + Profile_Curvature + Plan_Curvature + \n    Lithology_Metamorphic + Lithology_Sedimentary + Lithology_Plutonic + \n    Lithology_Unconsolidated + Proximity_Settlement + Proximity_Stream + \n    Proximity_Road + Proximity_Fault + Landuse_Vegetation + Precipitation + \n    TWI + SPI + STI, family = \"binomial\", data = data_15)\n\nCoefficients:\n                           Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)              -2.977e+00  2.458e-01 -12.109  &lt; 2e-16 ***\nElevation                -1.718e-04  4.479e-05  -3.836 0.000125 ***\nSlope_Angle               2.387e-01  4.878e-03  48.930  &lt; 2e-16 ***\nAspect_North             -2.829e-02  1.145e-01  -0.247 0.804838    \nAspect_NorthEast         -2.502e-01  9.767e-02  -2.561 0.010425 *  \nAspect_East              -3.313e-01  9.686e-02  -3.421 0.000624 ***\nAspect_SouthEast         -4.151e-01  9.348e-02  -4.441 8.96e-06 ***\nAspect_South             -3.331e-01  9.105e-02  -3.658 0.000254 ***\nAspect_SouthWest         -2.544e-01  9.281e-02  -2.741 0.006118 ** \nAspect_West              -2.073e-01  9.327e-02  -2.223 0.026225 *  \nProfile_Curvature        -8.707e+02  2.683e+01 -32.448  &lt; 2e-16 ***\nPlan_Curvature           -7.673e+02  3.158e+01 -24.298  &lt; 2e-16 ***\nLithology_Metamorphic     7.562e-01  1.321e-01   5.723 1.05e-08 ***\nLithology_Sedimentary     1.213e+00  1.368e-01   8.868  &lt; 2e-16 ***\nLithology_Plutonic       -8.368e-01  1.261e-01  -6.636 3.22e-11 ***\nLithology_Unconsolidated  1.332e+00  1.325e-01  10.052  &lt; 2e-16 ***\nProximity_Settlement      5.663e-05  4.050e-05   1.398 0.162001    \nProximity_Stream         -5.190e-03  2.117e-03  -2.452 0.014218 *  \nProximity_Road           -4.507e-03  1.422e-03  -3.170 0.001527 ** \nProximity_Fault          -3.759e-06  2.381e-05  -0.158 0.874578    \nLanduse_Vegetation        6.319e-01  5.267e-02  11.996  &lt; 2e-16 ***\nPrecipitation            -5.781e+00  5.831e-01  -9.914  &lt; 2e-16 ***\nTWI                      -3.994e-02  1.127e-02  -3.546 0.000392 ***\nSPI                       1.336e+00  8.694e-01   1.537 0.124295    \nSTI                      -8.186e-04  1.028e-03  -0.796 0.425851    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 19171  on 14019  degrees of freedom\nResidual deviance: 11479  on 13995  degrees of freedom\nAIC: 11529\n\nNumber of Fisher Scoring iterations: 5\n\n\n\ncm3 &lt;- blr_confusion_matrix(landslide.lr3, cutoff = 0.5)\n\n\n\n       Metric      LR.1      LR.2      LR.3\n1    Accuracy 0.9302454 0.9299290 0.8210414\n2 Sensitivity 0.9690761 0.9695069 0.7718254\n3 Specificity 0.9302454 0.9299290 0.8210414\n\n\n\n\n\n\n\n\nObservation\n\n\n\nLR 3 has the best AIC at the expense of having the lowest accuracy and sensitivity rates so far. As such, the overall performance was compromised after conducting stratified sampling.\n\n\n\n\n4.3.3 Spatial Weights\nVariables are more often than not influenced by geographic factors and to name a few, topography, lithology, and slope gradient."
  },
  {
    "objectID": "gwsmodelling_new.html#geographically-weighted-logistic-regression-model-1",
    "href": "gwsmodelling_new.html#geographically-weighted-logistic-regression-model-1",
    "title": "GWS Modelling: Parametric Testing",
    "section": "4.4 Geographically Weighted Logistic Regression Model 1",
    "text": "4.4 Geographically Weighted Logistic Regression Model 1\nImposing a Geographically Weighted Logistic Regression (GWLR) Model aims to improve the model performance and more importantly, detect any spatial relationship between explanatory variables and the target variable.\nOur above LR model will be calibrated into GWLR by incorporating spatial weight-matrix, weighting function and bandwidth parameters.\n\n4.4.1 Data Sampling\nThere is a limit to the number of observations the GWModel can take. Hence only 20% of the landslide data is taken into account.\n\nls_data_sf &lt;- st_as_sf(data_15, coords = c(\"X\", \"Y\"))\nset.seed(1243)\nls_split &lt;- ls_data_sf %&gt;%\n  initial_split(prop = .2, \n                strata = Landslide)\n\ntraining_data_sf &lt;- training(ls_split)\ntesting_data_sf  &lt;- testing(ls_split)\n\ntraining_data_sp &lt;- as_Spatial(training_data_sf)\n\n\n\n4.4.2 Calculating Distance Matrix\n\ndistMAT &lt;- gw.dist(dp.locat=\n                     coordinates(training_data_sp))\n\n\n\n4.4.3 Computing Adaptive Bandwidth\n\nbw.adaptive &lt;- bw.ggwr(formula = \n                         Landslide ~ Slope_Angle, \n                       family = \"binomial\", \n                       data = training_data_sp, \n                       approach=\"CV\", \n                       kernel=\"gaussian\", \n                       adaptive= TRUE, \n                       longlat=FALSE, \n                       p=2,\n                       theta=0,\n                       dMat=distMAT)\n\n\n\n\n\n\n\nNote\n\n\n\nThe above step is computationally intensive. The resulting adaptive bandwidth value is 20.\n\n\nThe input variables for the geographically weighted logistic regression model would be the selected independent variables for the formula, the training data in SpatialPointDataFrame object, the adaptive bandwidth value 20, where kernel is set to Gaussian and family is set as binomial due to the binary nature of the data.\n\ngwlr &lt;- ggwr.basic(Landslide ~ Aspect_North + \n                     Aspect_SouthEast + Profile_Curvature + \n                     Plan_Curvature + Slope_Angle + \n                     Lithology_Sedimentary + Lithology_Plutonic +\n                     Lithology_Unconsolidated + Proximity_Stream +\n                     Landuse_Vegetation + Precipitation, \n                   data = training_data_sp, \n                   bw = 20, \n                   family = \"binomial\", \n                   kernel = \"gaussian\", \n                   adaptive = TRUE, \n                   cv = T, \n                   tol = 1e-05, \n                   maxiter = 20, \n                   p = 2, \n                   theta = 0, \n                   longlat = FALSE, \n                   dMat = distMAT)\n\n\ngwlr\n\n\n\n\n\n\n\n\n\n\nObservation\n\n\n\n\nAdjusted R-squared and AIC perform better with GWR\nSignificant improvements from using global LR to local GWR\n\n\n\n\n\n4.4.5 Correlation Matrix Using ggstats\n\n\nset.seed(123)\n## producing the correlation matrix\nggcorrmat(\n  data = train_grids_v4[, 6:29],  \n          matrix.type = \"upper\",\n  type = \"parametric\",\n  tr = 0.2,\n  partial = FALSE,\n  k = 2L,\n  sig.level = 0.05,\n  conf.level = 0.95,\n  bf.prior = 0.707,\n  ggcorrplot.args = list(\n     tl.cex = 10,\n     pch.cex = 5,\n     lab_size = 3\n  )) + ## modification outside `{ggstatsplot}` using `{ggplot2}` functions\n  ggplot2::theme(\n    axis.text.x = ggplot2::element_text(\n      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = \"cm\")\n    )\n  )"
  }
]