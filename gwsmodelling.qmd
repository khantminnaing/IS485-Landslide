---
title: "Landslide Susceptibility Model Development"
author:
  - name: Khant Min Naing
  - name: Ann Mei Yi Victoria Grace
date: 01-07-2024 
date-modified: "last-modified"
categories:
  - R
  - sf
  - gwmodel
output:
  distill::distill_article:
    code_folding: false
    toc: true
    self_contained: false
---

To develop a landslide susceptibility methodology framework, we will explore and calibrate different statistical and machine learning models.

## 1.0 Import Packages

-   `car` : Companion to Applied Regression

```{r}
pacman::p_load(sf, st, spdep, raster, spatstat, tmap, devtools,vtable,ggplot2,egg, corrplot, patchwork, ggstats, ggstatsplot, GWmodel, tidyverse, gtsummary,vtable, sjPlot, sjmisc, sjlabelled, tableHTML, olsrr, car, blorr,ISLR)
```

## 2.0 Import Data

```{r}
train_grids <- read.csv("~/IS485-Landslide/data/aspatial/train_grid.csv")
train_grids_v2 <- read.csv("~/IS485-Landslide/data/aspatial/train_grid_v2.csv")
train_grids_v3 <- read.csv("~/IS485-Landslide/data/aspatial/train_grid_v3.csv")
```

```{r}
length <- length(train_grids)
length
```

```{r}
train_grids.sf <- st_as_sf(train_grids,
                            coords = c("X", "Y"))
train_grid_v2.sf <- st_as_sf(train_grids_v2,
                            coords = c("X", "Y"))
```

## 5.0 Exploratory Spatial Data Analysis (ESDA) - V3

To calculate the summary statistics of `landslide_train` data frame, we use `st()`.

```{r}
st(train_grids_v3)
```

Next, we will create atrellis plot by using `ggarrange()` of [**ggpubr**](https://cran.r-project.org/web/packages/ggpubr/) package. In this way, we can see the distribution plots of different parameters at the same time.

```{r}
#| fig-width: 10

Elevation <- ggplot(data=train_grids_v3, aes(x= `Elevation`)) + 
  geom_histogram(bins=7, color="black", fill="#e9531e")

Slope_Angle <- ggplot(data=train_grids_v3, aes(x= `Slope_Angle`)) +
  geom_histogram(bins=7, color="black", fill="#e9531e")

Profile_Curvature <- ggplot(data=train_grids_v3, aes(x= `Profile_Curvature`)) + 
  geom_histogram(bins=7, color="black", fill="#e9531e")

Plan_Curvature <- ggplot(data=train_grids_v3, aes(x= `Plan_Curvature`)) +
  geom_histogram(bins=7, color="black", fill="#DC375E")

Proximity_Settlement  <- ggplot(data=train_grids_v3, 
                               aes(x= `Proximity_Settlement`)) +
  geom_histogram(bins=7, color="black", fill="#DC375E")

Proximity_Stream  <- ggplot(data=train_grids_v3, aes(x= `Proximity_Stream`)) +
  geom_histogram(bins=7, color="black", fill="#DC375E")

Proximity_Road <- ggplot(data=train_grids_v3, aes(x= `Proximity_Road`)) +
  geom_histogram(bins=7, color="black", fill="#c4102c")

Proximity_Fault <- ggplot(data=train_grids_v3, aes(x= `Proximity_Fault`)) +
  geom_histogram(bins=7, color="black", fill="#c4102c")

Precipitation <- ggplot(data=train_grids_v3, aes(x= `Precipitation`)) +
  geom_histogram(bins=7, color="black", fill="#c4102c")

TWI <- ggplot(data=train_grids_v3, aes(x= `TWI`)) +
  geom_histogram(bins=7, color="black", fill="#AE4285")

SPI <- ggplot(data=train_grids_v3, aes(x= `SPI`)) +
  geom_histogram(bins=7, color="black", fill="#AE4285")

STI <- ggplot(data=train_grids_v3, aes(x= `STI`)) +
  geom_histogram(bins=7, color="black", fill="#AE4285")

ggarrange(Elevation,Slope_Angle,Profile_Curvature,Plan_Curvature,Proximity_Settlement,Proximity_Stream,Proximity_Road,Proximity_Fault,Precipitation,TWI,SPI,STI,
          ncol = 4, nrow = 4)
```

### 4.1 Correlation Matrix Using Corrplot

Before building a logistic regression model, it is important to ensure that the indepdent variables used are **not highly correlated** to each other. If these highly correlated independent variables are used in building a regression model by mistake, the quality of the model will be compromised. This phenomenon is known as **multicollinearity** in statistics.

Correlation matrix is commonly used to visualise the relationships between the independent variables. In this section, the [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html) package will be used to display the correlation matrix of the independent variables in *condo_resale* data frame.

```{r}
#| fig-width: 10

corrplot(cor(train_grids_v3[, 6:29]), diag = FALSE, order = "AOE",
         col=colorRampPalette(c("#50a8b4","#e4c838","#be804f"))(10),
         tl.pos = "td", tl.cex = 0.5,tl.col = "black", number.cex = 0.5, method = "number", type = "upper")

corrplot(cor(train_grids_v3[,6:29]), diag = FALSE, order = "AOE",
         col=colorRampPalette(c("#50a8b4","#ffffdd","#be804f"))(10),
         tl.pos = "td", tl.cex = 0.5,tl.col = "black", number.cex = 0.5, method = "ellipse", type = "upper")
```

Matrix reorder is very important for mining the hiden structure and patter in the matrix. There are four methods in corrplot (parameter order), named "AOE", "FPC", "hclust", "alphabet". In the code chunk above, AOE order is used. It orders the variables by using the *angular order of the eigenvectors* method suggested by [Michael Friendly](https://www.datavis.ca/papers/corrgram.pdf).

### 4.2 Correlation Matrix Using ggstats

```{r}
#| fig-width: 10

set.seed(123)
## producing the correlation matrix
ggcorrmat(
  data = train_grids_v3[, 6:29],  
          matrix.type = "upper",
  type = "parametric",
  tr = 0.2,
  partial = FALSE,
  k = 2L,
  sig.level = 0.05,
  conf.level = 0.95,
  bf.prior = 0.707,
  ggcorrplot.args = list(
     tl.cex = 10,
     pch.cex = 5,
     lab_size = 3
  )) + ## modification outside `{ggstatsplot}` using `{ggplot2}` functions
  ggplot2::theme(
    axis.text.x = ggplot2::element_text(
      margin = ggplot2::margin(t = 0.15, r = 0.15, b = 0.15, l = 0.15, unit = "cm")
    )
  )
```

### 4.3 Multiple Logistic Regression

We will fit a logistic regression model in order to predict the probability of a customer defaulting based on the average balance carried by the customer. The `glm` function fits generalized linear models, a class of models that includes logistic regression. The syntax of the `glm` function is similar to that of `lm`, except that we must pass the argument `family = binomial` in order to tell R to run a logistic regression rather than some other type of generalized linear model.

```{r}
landslide.lr_3 <- glm(Landslide ~ Elevation + Slope_Angle + Aspect_North + Aspect_NorthEast + Aspect_East+Aspect_SouthEast+Aspect_South + Aspect_SouthWest +Aspect_West + Profile_Curvature +Plan_Curvature + Lithology_Metamorphic+Lithology_Sedimentary + Lithology_Plutonic+Lithology_Unconsolidated + Proximity_Settlement+Proximity_Stream+Proximity_Road+Proximity_Fault+Landuse_Vegetation+Precipitation+TWI+SPI+STI, family = "binomial", data = train_grids_v3)
```

```{r}
summary(landslide.lr_3)
```

```{r}
#| eval: false
tbl_regression(landslide.lr_3, intercept = TRUE) %>%
  add_glance_source_note(
  include = c(r.squared, adj.r.squared, 
                AIC, statistic,
                p.value, sigma))
```

### 4.5 Calculating Adjusted Odd Ratios and Confidence Intervals

```{r}
OR.CI_3 <- cbind("AOR" = exp(coef(landslide.lr_3)),
                       exp(confint(landslide.lr_3)))[-1,]
round(OR.CI_3, 4)
```

```{r}
OR.CI_3
```

```{r}
vif(landslide.lr_3)
```

### Stepwise Selection

For the initial/ first cut model, all the independent variables are put into the model. Our goal is to include a limited number of independent variables (5-15) which are all significant, without sacrificing too much on the model performance. The rationale behind not-including too many variables is that the model would be over fitted and would become unstable when tested on the validation sample. The variable reduction is done using forward or backward or stepwise variable selection procedures. We will use `blr_step_aic_both()` to shortlist predictors for our model.

```{r}
blr_step_aic_both(landslide.lr_3)
```

```{r}
landslide.lr_3 %>%
  blr_step_aic_both() %>%
  plot()
```

### Model Update 

```{r}
landslide.lr_3_modified <- glm(Landslide ~ Slope_Angle + Aspect_SouthWest + Aspect_South + Profile_Curvature +Plan_Curvature +Lithology_Unconsolidated+Proximity_Stream+Landuse_Vegetation+TWI, family = "binomial", data = train_grids_v3)
```

```{r}
summary(landslide.lr_3_modified)
vif(landslide.lr_3_modified)

```

## Model Fit Statistics

Model fit statistics are available to assess how well the model fits the data and to compare two different models.The output includes likelihood ratio test, AIC, BIC and a host of pseudo r-squared measures. You can read more about pseudo r-squared at <https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/>.

```{r}
blr_model_fit_stats(landslide.lr_3_modified)
```

Compared with the basic model,

```{r}
blr_model_fit_stats(landslide.lr_3)
```

## Model Validation 

```{r}
blr_confusion_matrix(landslide.lr_3_modified, cutoff = 0.5)
```

```{r}
blr_confusion_matrix(landslide.lr_3, cutoff = 0.5)
```

### Hosmer Lemeshow Test

Hosmer and Lemeshow developed a goodness-of-fit test for logistic regression models with binary responses. The test involves dividing the data into approximately ten groups of roughly equal size based on the percentiles of the estimated probabilities. The observations are sorted in increasing order of their estimated probability of having an even outcome. The discrepancies between the observed and expected number of observations in these groups are summarized by the Pearson chi-square statistic, which is then compared to chi-square distribution with t degrees of freedom, where t is the number of groups minus 2. Lower values of Goodness-of-fit are preferred.

```{r}
blr_test_hosmer_lemeshow(landslide.lr_3_modified)
```

### ROC Curve

ROC curve is a graphical representation of the validity of cut-offs for a logistic regression model. The ROC curve is plotted using the sensitivity and specificity for all possible cut-offs, i.e., all the probability scores. The graph is plotted using sensitivity on the y-axis and 1-specificity on the x-axis. Any point on the ROC curve represents a sensitivity X (1-specificity) measure corresponding to a cut-off. The area under the ROC curve is used as a validation measure for the model -- the bigger the area the better is the model.

```{r}
#| eval: false
landslide.lr_3_modified%>%
    blr_gains_table() %>%
  blr_roc_curve()
```

#### Influence Diagnostics

```{r}
blr_plot_diag_influence(landslide.lr_3_modified)
```

#### Fitted Values Diagnostics

```{r}
blr_plot_diag_fit(landslide.lr_3_modified)
```
